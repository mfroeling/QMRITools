(* ::Package:: *)

(* ::Title:: *)
(*QMRITools MuscleBidsTools*)


(* ::Subtitle:: *)
(*Written by: Martijn Froeling, PhD*)
(*m.froeling@gmail.com*)


(* ::Section:: *)
(*Begin Package*)


BeginPackage["QMRITools`MuscleBidsTools`", Join[{"Developer`"}, Complement[QMRITools`$Contexts, {"QMRITools`MuscleBidsTools`"}]]];


(* ::Section:: *)
(*Usage Notes*)


(* ::Subsection::Closed:: *)
(*Functions*)


ImportJSON::usage = 
"ImportJSON[file] imports a JSON file as rawJSON."

GetJSONPosition::usage = 
"GetJSONPosition[{json..}, {{key, value}..}] gets the position from a list of JSON association lists where keys have the given value.
GetJSONPosition[{json..}, {{key, value}..}, sortkey] same but finally sorts the positions for the value of the sortkey."

MergeJSON::usage = 
"MergeJSON[{json..}] merges a list of JSON association lists where duplicate keys with the same values are removed and duplicate keys with different values are merged."

AddToJson::usage = 
"AddToJson[json, <|key->value..|>] adds new keys and values to the JSON list where duplicate keys are either removed or joined.
AddToJson[json, \"QMRITools\"] adds the QMRITools software version to the JSON."

ExtractFromJSON::usage = 
"ExtractFromJSON[json,keys] if the keys exist they are extracted from the JSON."


SelectSubjects::usage = 
"SelectSubjects[dir] selects the subjects in the given data directory which has a config file."

ViewConfig::usage = 
"ViewConfig[config] shows a config file for Muscle Bids processing."

GetConfig::usage = 
"GetConfig[folder] imports a Muscle Bids config file from the given folder."

MergeConfig::usage =
"MergeConfig[assoc, replace] merges the replace association with the assoc association."


PartitionBidsName::usage = 
"PartitionBidsName[name] converts a Bids name to the Bids labels as an association, i.e. {\"sub\",\"ses\",\"stk\",\"rep\",\"type\",\"suf\"}."

PartitionBidsFolderName::usage = 
"PartitionBidsFolderName[fol] partitions the Bids folder and file name. It returns the bids root folder and the label parts using PartitionBidsName."

GenerateBidsName::usage = 
"GenerateBidsName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName."

GenerateBidsFolderName::usage = 
"GenerateBidsFolderName[parts] generates a Bids folder name from the Bids labels association which can be generated by PartitionBidsFolderName."

GenerateBidsFileName::usage = 
"GenerateBidsFileName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName.
GenerateBidsFileName[fol, parts] the same but with a custom root folder."

SelectBidsFolders::usage =
"SelectBidsFolders[fol, tag] selects all folders in the fol with the name tag."

SelectBidsSubjects::usage =
"SelectBidsSubjects[fol] selects all subjects in the bids folder."

SelectBidsSessions::usage =
"SelectBidsSessions[fol] selects all sessions in the bids subject folder."


BidsDcmToNii::usage =
"BidsDcmToNii[dir] converts the bids sourceFolder with dicom files to raw nii files based on the config file."

MuscleBidsConvert::usage =
"MuscleBidsConvert[dir] converts all raw nii data in the to Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsProcess::usage = 
"MuscleBidsProcess[dir] processes all Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsMerge::usage = 
"MuscleBidsMerge[dir] merges multiple stack data for all Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsSegment::usage = 
"MuscleBidsSegment[dir] segments the data of Muscle-Bids named nii based on the config file in the bids sourceFolder dir. The segmentations are generated by the function SegmentData."

MuscleBidsTractography::usage =
"MuscleBidsTractography[dir] performs tractography on the Muscle-Bids named nii based on the config file in the bids sourceFolder dir. If a segmentation is present it is used as a mask for per muscle segmentation."

MuscleBidsAnalysis::usage = 
"MuscleBidsAnalysis[dir] performs analysis on the Muscle-Bids named nii based on the config file in the bids sourceFolder dir. If a segmentation is present it is used to calculate the mean per segmentation."

CheckDataDescription::usage =
"CheckDataDescription[description] checks the data description config file used in BidsDcmToNii, MuscleBidsConvert, MuscleBidsProcess, and MuscleBidsMerge."


(* ::Subsection::Closed:: *)
(*Options*)


BidsIncludeSession::usage = 
"BidsIncludeSession is an option for BidsDcmToNii. If True session folders will be used in output even if they are not specified."

DeleteAfterConversion::usage = 
"DeleteAfterConversion is an option for MuscleBidsConvert. If set True all files that have been converted will be deleted."

BidsTractographyMethod::usage =
"BidsTractographyMethod is an option for MuscleBidsTractography and can be \"Full\", \"Tractography\" or \"Segmentation\". 
With Tractography only the tractography is performed without segmentation.
With Segmentation only the segmentation is performed without tractography. With Full both are performed."

BidsOutputImages::usage = 
"BidsOutputImages is an option for MuscleBidsAnalysis. If set True the output images are saved in the output folder."

ProcessSubjects::usage = 
"ProcessSubjects is an option for Bids functions. Can be a list of bids subject names else it is All."

VersionCheck::usage = 
"VersionCheck is an option for all Bids functions. If set True data processed with an old version is reprocessed."


(* ::Subsection::Closed:: *)
(*Error Messages*)


CheckDataDescription::key = "Datasets have duplicate names which is not allowed."

CheckDataDescription::type = "Unknown Muscle-BIDS type: `1`, using folder \"miss\"."

CheckDataDescription::class = "Unknown Muscle-BIDS Class: `1`. Must be \"Volume\", \"Stacks\", \"Repetitions\", \"Chunks\", \"Acquisitions\"."

CheckDataDescription::lab = "Invalid combination of Class and Label: `1` with `2` is not allowed."

CheckDataDescription::man = "Mandatory values \"Label\" and \"Type\" are not in the data description."

CheckDataDescription::stk = "Class \"stacks\" or \"Chunk\" is used but overlap is not defined, assuming overlap 0."

GetConfig::conf = "Could not find config file in given folder."


(* ::Section:: *)
(*Functions*)


Begin["`Private`"] 


debugBids[x___]:=If[$debugBids, Print[x]];


(* ::Subsection:: *)
(*BIDS name and select*)


(* ::Subsubsection::Closed:: *)
(*General Definitions*)


bidsTypes = <|
	(*anata types*)
	"T1w"->"anat", "T1w-FS"->"anat", "T2w"->"anat", "T2w-FS"->"anat",
	(*dixon*)
	"megre"->"dix", "mese"->"quant",
	(*quant types*)
	"T1"->"quant", "T2"->"quant", "wT2"->"quant",
	(*diff types*)
	"dwi"->"dwi",
	(*seg types*)
	"seg"->"seg"
|>;


bidsName = {"sub", "ses", "stk", "chunk", "rep", "acq" ,"part", "type", "suf"};


bidsClass = {"Volume", "Stacks", "Repetitions", "Chunks", "Acquisitions", "Mixed"};


dataToLog =If[KeyExistsQ[#, $Failed], 
	"Wrong data description: " <> #[$Failed], 
	StringJoin[ToString[#[[1]]] <> ": " <> ToString[#[[2]]] <> "; " & /@ Normal[KeyDrop[#, {"Process", "Merging", "Segment", "Tractography"}]]]
]&;


notAllowed = {"-"->"","_"->"","."->""," "->""};
stringStrip = StringReplace[#, notAllowed]&;


(* ::Subsubsection::Closed:: *)
(*PartitionBidsName*)


SyntaxInformation[PartitionBidsName] = {"ArgumentsPattern" -> {_}};

PartitionBidsName[list_?ListQ]:=PartitionBidsName/@list

PartitionBidsName[string_?StringQ]:=Block[{parts, entity, suffix, suf},
	(*first split on "_" then on "-"*)
	parts = StringSplit[#,"-"]& /@ StringSplit[string, "_"];
	(*if length is 2 its entity else it is suffix*)
	entity = Rule@@#& /@ Select[parts, Length[#]===2&];
	suf = Flatten[Select[parts, Length[#]=!=2&]];

	(*see if type is part of suffixes*)
	suf = Which[
		suf==={}, {"suf"->{}},
		MemberQ[Keys[bidsTypes], First@suf], {"type"->First@suf,"suf"->Rest@suf},
		True, {"suf"->suf}
	];

	(*give as association*)
	Association[Join[entity, suf]]
]


(* ::Subsubsection::Closed:: *)
(*PartitionBidsFolderName*)


SyntaxInformation[PartitionBidsFolderName] = {"ArgumentsPattern" -> {_}};

PartitionBidsFolderName[fol_?ListQ]:=PartitionBidsFolderName/@fol

PartitionBidsFolderName[fol_?StringQ]:={
	First@StringSplit[fol, "sub-"], PartitionBidsName@StringJoin@Riffle[Select[FileNameSplit[fol],StringContainsQ[#,"-"]&],"_"]
}


(* ::Subsubsection::Closed:: *)
(*GenerateBidsName*)


SyntaxInformation[GenerateBidsName] = {"ArgumentsPattern" -> {_}};

GenerateBidsName[list_?ListQ]:=GenerateBidsName/@list

GenerateBidsName[parts_?AssociationQ]:=StringJoin[Riffle[Select[Join[
	BidsString[parts, {"sub", "ses", "stk", "rep", "chunk", "acq", "part"}], BidsValue[parts, {"type", "suf"}
]],#=!=""&],"_"]]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFolderName*)


SyntaxInformation[GenerateBidsFolderName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFolderName[fol_?StringQ, list_?ListQ]:=GenerateBidsFolderName[fol,#]&/@list

GenerateBidsFolderName[fol_?StringQ, parts_?AssociationQ]:=FileNameJoin[Select[{
	fol, BidsString[parts, "sub"], BidsString[parts, "ses"]
},#1=!=""&]]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFileName*)


SyntaxInformation[GenerateBidsFileName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFileName[list_?ListQ]:=GenerateBidsFileName["",#]& /@ list

GenerateBidsFileName[fol_?StringQ, list_?ListQ]:=GenerateBidsFileName[fol,#]& /@ list

GenerateBidsFileName[parts_?AssociationQ]:=GenerateBidsFileName["",parts]

GenerateBidsFileName[fol_?StringQ, parts_?AssociationQ]:=FileNameJoin[Select[{
	(*folders*)
	fol, BidsString[parts, "sub"], BidsString[parts, "ses"], BidsType[parts], 
	(*filename*)
	GenerateBidsName[parts]
}, #=!=""&]]


(* ::Subsubsection::Closed:: *)
(*SelectBidsFolders*)


SyntaxInformation[SelectBidsFolders] = {"ArgumentsPattern" -> {_, _}};

SelectBidsFolders[fol_?ListQ, tag_] := Flatten[SelectBidsFolders[#, tag] & /@ fol]
SelectBidsFolders[fol_?StringQ, tag_] := Block[{folSel, done, cont},
	folSel = Select[FileNames[All, fol], (DirectoryQ[#] && (FileBaseName[#] === tag || StringTake[FileBaseName[#], 3] === "sub" || StringTake[FileBaseName[#], 3] === "ses")) &];
	done = Select[folSel, FileBaseName[#] === tag &];
	cont = Complement[folSel, done];
	Flatten[{done, If[cont =!= {}, SelectBidsFolders[cont, tag], Nothing]}]
]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSubjects*)


SyntaxInformation[SelectBidsSubjects] = {"ArgumentsPattern" -> {_}};

SelectBidsSubjects[fol_] := Select[FileNames[All, fol], (DirectoryQ[#] && StringTake[FileNameTake[#], 3] === "sub") &]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSessions*)


SyntaxInformation[SelectBidsSessions] = {"ArgumentsPattern" -> {_}};

SelectBidsSessions[fol_?ListQ]:=Flatten[SelectBidsSessions/@fol]

SelectBidsSessions[fol_?StringQ] := Select[FileNames[All, fol], (DirectoryQ[#] && StringTake[FileNameTake[#], 3] === "ses") &]


(* ::Subsubsection::Closed:: *)
(*BidsType*)


BidsType[type_?StringQ]:= bidsTypes[type] /. {Missing[___]->"miss"} 

BidsType[parts_?AssociationQ]:= bidsTypes[parts["type"]] /. {Missing[___]->"miss"} 


(* ::Subsubsection::Closed:: *)
(*BidsValue*)


BidsValue[parts_, val_?ListQ]:=Flatten[BidsValue[parts, #] &/@ val]

BidsValue[parts_, val_?StringQ]:= parts[val]  /. {Missing[___] -> ""} 


(* ::Subsubsection::Closed:: *)
(*BidsString*)


BidsString[parts_, val_?ListQ]:=BidsString[parts, #] &/@ val

BidsString[parts_, val_?StringQ]:=Block[{str},
	str = BidsValue[parts, val];
	If[str==="", "", val<>"-"<>str]
]


(* ::Subsection:: *)
(*Config*)


(* ::Subsubsection::Closed:: *)
(*ViewConfig*)


SyntaxInformation[SelectBidsSessions] = {"ArgumentsPattern" -> {_}};

ViewConfig[folder_?StringQ]:=ViewConfig[GetConfig[folder]]

ViewConfig[config_?AssociationQ]:=TabView[# -> Which[
	# === "datasets", ViewConfig[config[#]],
	# === "analysis", If[KeyExistsQ[config["analysis"], "Analysis"], MakeTable[config[#]], ViewConfig[config[#]]], 
	True, MakeTable[config[#]]
]& /@ Keys[config]]


MakeTable[association_] := Block[{value},
	Grid[{#, 
		value = association[#];
		Which[
			AssociationQ[value], MakeTable[value],
			ListQ[value] && Length[value] > 0, If[AssociationQ[First[value]],
				Column[MakeTable /@ value],
				If[ListQ[value],
					Which[
						Length[value] > 10, Grid[value],
						Length[value] > 6, Column[Row[#, ", "]&/@Partition[value, 6, 6, 1,{}]],
						VectorQ[value], Row[value, ", "], 
						True, Column[value]],
					value]
				], 
			True, value
		]
	} & /@ Keys[association], Frame -> All, Alignment -> Left, 
	Background -> {{Gray, {White}}, White}, Spacings -> {1, 0.5}]
]


(* ::Subsubsection::Closed:: *)
(*CheckConfig*)


CheckConfig[infol_?StringQ, outfol_?StringQ]:=Block[{conf, nam},
	nam = GenerateBidsName[PartitionBidsFolderName[outfol][[-1]]];
	conf = Quiet@GetConfig[infol, nam];
	debugBids[FileNameJoin[{outfol, nam<>"_config.json"}]];

	If[conf =!= $Failed,
		Export[FileNameJoin[{outfol, nam<>"_config.json"}], conf];
		{True, conf}, 
		{False, <||>}
	]
]


(* ::Subsubsection::Closed:: *)
(*GetConfig*)


GetConfig[folder_?StringQ]:=GetConfig[folder, ""]

GetConfig[folder_?StringQ, nam_?StringQ]:=Block[{file},
	(*normal config*)
	If[DirectoryQ[folder],
		(*normal config*)
		file = FileNameJoin[{folder,"config.json"}];
		If[FileExistsQ[file],
			Import[file, "RawJSON"],
			(*subject name config*)
			file = FileNameJoin[{folder, nam<>"_config.json"}];
			If[FileExistsQ[file],
				Import[file, "RawJSON"],
				Message[GetConfig::conf];
				Return[$Failed]
			]
		],
		If[FileExistsQ[folder], 
			Import[folder, "RawJSON"],
			Return[$Failed]
		]
	]
]


(* ::Subsubsection::Closed:: *)
(*MergeConfig*)


MergeConfig[assoc_?ListQ, replace_?AssociationQ] := Normal@MergeConfig[Association@assoc, replace]

MergeConfig[assoc_?AssociationQ, replace_?ListQ] := MergeConfig[assoc, Association@replace]

MergeConfig[assoc_?AssociationQ, replace_?AssociationQ] := Block[{assocNew }, 
	assocNew = Association[assoc];
	KeyValueMap[Function[{key, subAssoc},
		assocNew = If[AssociationQ[subAssoc],
			If[KeyExistsQ[assocNew, key],
				ReplacePart[assocNew, key -> MergeConfig[assocNew[key], subAssoc]],
				Append[assocNew, key -> subAssoc]],
			If[KeyExistsQ[assocNew, key],
				ReplacePart[assocNew, key -> subAssoc],
				Append[assocNew, key -> subAssoc]]
		]
	], replace];
	assocNew
]


(* ::Subsection:: *)
(*JSON*)


(* ::Subsubsection::Closed:: *)
(*ImportJSON*)


ImportJSON[file_]:=Import[file,"RawJSON"]


(* ::Subsubsection::Closed:: *)
(*GetJSONPosition*)


GetJSONPosition[json_, selection_]:=GetJSONPosition[json, selection, ""]

GetJSONPosition[json_, selection_, sort_]:=Block[{selIndex, selFunc, list, key, val, inds, pos},
	(*selection functions*)
	selIndex = StringReplace[ToLowerCase[Last[Flatten[{#1 /. #3}]]], {"wip " -> "", "wip_"->""}] === ToLowerCase[#2] &;
	selFunc = (list=#1; key=#2[[1]]; val=#2[[2]]; Select[list, selIndex[key, val, json[[#]]]&])&;

	(*get the file positions*)
	pos = Fold[selFunc, Range[Length[json]], selection];
	(*sort positions if needed*)
	If[sort==="", pos, pos[[Ordering[sort /. json[[pos]]]]]]
]


(* ::Subsubsection::Closed:: *)
(*MergeJSON*)


MergeJSON[json:{_?AssociationQ..}]:=Block[{keys},
	keys = DeleteDuplicates[Flatten[Keys /@ json]];
	Association[If[#[[2]]==={}, Nothing, #]& /@ Thread[
		keys->(If[Length[#]===1,First@#,#]& /@ ((DeleteDuplicates /@ Transpose[(# /@ keys)& /@ json]) /. Missing[___]->Nothing))
	]]
]


(* ::Subsubsection::Closed:: *)
(*ExtractFromJSON*)


ExtractFromJSON[json_, keys_] := If[KeyExistsQ[json, #], # -> json[#], Nothing]& /@ keys;


(* ::Subsubsection::Closed:: *)
(*AddToJson*)


AddToJson[json_, add_]:=MergeJSON[{json, Switch[add,
	"QMRITools", <|"ConversionSoftware"->"QMRITools.com", "ConversionSoftwareVersion"->QMRITools`$InstalledVersion|>,
	_, add
]}]


(* ::Subsection:: *)
(*BidsSupport*)


(* ::Subsubsection::Closed:: *)
(*SelectSubjects*)


SyntaxInformation[SelectSubjects] = {"ArgumentsPattern" -> {_}};

SelectSubjects[dir_?StringQ] := DynamicModule[{fol, selectedSubjects, list},
	fol = FileNameJoin[{dir, GetConfig[dir]["folders", "dicomData"]}];
	list = Sort[FileBaseName[#] & /@ Select[FileNames["*", fol], DirectoryQ]];
	selectedSubjects = {};
	Column[{
		CheckboxBar[Dynamic[selectedSubjects], list, Appearance -> "Vertical" -> {Min[{15, Length@list}], Automatic}, Method -> "Active"],
		Row[{
			Button["Select All", selectedSubjects = list],
			Button["Deselect All", selectedSubjects = {}],
			Button["Copy selected list to clipboard", CopyToClipboard[selectedSubjects]]
		}]
	}]
];


(* ::Subsubsection::Closed:: *)
(*SubNameToBids*)


Options[SubNameToBids] = {BidsIncludeSession -> True};

SubNameToBids[nameIn_?ListQ, met_, opts : OptionsPattern[]] := SubNameToBids[#, met, opts] & /@ nameIn

SubNameToBids[nameIn_?StringQ, met_, OptionsPattern[]] := Block[{ass, keys, name, ses},
	(*get the names*)
	ass = Switch[met, "Sub", PartitionBidsName, "BidsDcmToNii", PartitionBidsName[FileNameTake[#, {2, -1}]] &, _, PartitionBidsFolderName[#][[-1]] &]@nameIn;
	keys = Keys[ass];

	(*if bids take sub key else assume first suf is name*)
	name = "sub" -> If[MemberQ[keys, "sub"], ass["sub"], First[ass["suf"]]];

	(*if bids take ses key else assume last suf is session*)
	ses = "ses" -> If[MemberQ[keys, "ses"],
		(*session is present take session*)
		ass["ses"],
		(*more than one suf last is session*)
		If[Length[ass["suf"]] > 1, Last[ass["suf"]],
			(*no session,see if need to be forced*)
			If[OptionValue[BidsIncludeSession], "001", ""]]];
	Association[{name, ses, "suf" -> {}}]
]


(* ::Subsubsection::Closed:: *)
(*GetClassName*)


GetClassName[class_, nameIn_]:=Switch[class,
	"Volume", Nothing,
	"Stacks"|"Repetitions"|"Acquisitions",
	Switch[class, 
		"Stacks", "stk",
		"Repetitions", "rep", 
		"Chunks", "chunk", 
		"Acquisitions", "acq"
	] -> stringStrip[nameIn]
]


(* ::Subsubsection::Closed:: *)
(*CheckDataDescription*)


SyntaxInformation[CheckDataDescription] = {"ArgumentsPattern" -> {_, _}};

CheckDataDescription[dis_Association, met_] := Block[{duplicate, disK},
	If[!DuplicateFreeQ[Keys[dis]],
		(*datasets cannot have duplicate names*)
		Return[Message[CheckDataDescription::key];$Failed]
		,
		(*check if there are duplicated datasets, i.e. same type and suffix*)
		duplicate = !DuplicateFreeQ[{#["Type"], #["Suffix"]} & /@ Values[dis]];
		debugBids["data Descriptions duplicates: ", duplicate];

		(*If there are duplicates add the dataset name to the data Description*)
		disK = If[duplicate,
			KeySort[Join @@ #] & /@ Thread[{Values[dis], Association /@ Thread["Key" -> Keys[dis]]}],
			Values[dis]
		];
		Flatten[CheckDataDescription[Normal[#], met]& /@ disK]
	]
]

CheckDataDescription[dis:{_Rule..}, met_]:=Block[{ass, key, man, cls, typ, fail},
	(*Get the data Description keys*)
	ass = Association[dis];
	key = Keys[ass];
	(*fail output*)
	fail = Association[$Failed->ToString[Normal[ass]]];
	(*Check if mandatory keys are present*)
	man = ContainsAll[key, Switch[met,
		"MuscleBidsConvert", {"Label", "Type"},
		"MuscleBidsProcess", {"Type"},
		"MuscleBidsMerge", {"Type", "Merging"},
		"MuscleBidsSegment", {"Type"},
		"MuscleBidsTractography", {"Type"}
	]];

	If[!man,
		Return[Message[CheckDataDescription::man]; fail],

		(*Check if type is valid*)
		If[!MemberQ[Keys[bidsTypes], ass["Type"]], Message[CheckDataDescription::type, ass["Type"]]];

		(*Check if class is present*)
		If[KeyExistsQ[ass, "Class"],
			(*if present add check class is valid*)
			If[!MemberQ[bidsClass, ass["Class"]], Return[Message[CheckDataDescription::class,ass["Class"]]; fail]],
			(*add class if not present*)
			ass = Association[ass, "Class"->"Volume"]
		];

		(*check if labels match class*)
		cls = Switch[ass["Class"],
			"Volume", StringQ[ass[["Label"]]],
			"Stacks"|"Repetitions"|"Acquisitions"|"Mixed", ListQ[ass["Label"] && Length[ass]>1]
		];
		If[!cls, Return[Message[CheckDataDescription::lab, ass["Class"], ass["Label"]]; fail]];

		(*check suffic, in and out folder*)
		If[!KeyExistsQ[ass, "Suffix"], ass = Association[ass, "Suffix"->""]];
		Switch[met,
			"MuscleBidsConvert",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->"raw"]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];
			,
			"MuscleBidsProcess"|"MuscleBidsMerge"|"MuscleBidsSegment"|"MuscleBidsTractography",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->BidsType[ass["Type"]]]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];			
		];

		(*add overlap if class is stacks*)
		If[ass["Class"]==="Stacks"&&!KeyExistsQ[ass["Merging"], "Overlap"], Message[CheckDataDescription::stk]; ass = Association[ass, "Overlap"->0]];
		If[ass["Class"]==="Chunk"&&!KeyExistsQ[ass["Merging"], "Overlap"], Message[CheckDataDescription::stk]; ass = Association[ass, "Overlap"->0]];

		(*output the completed data Description*)
		{KeySort@ass}
	]
]


(* ::Subsection::Closed:: *)
(*0. BidsFolderLoop*)


Options[BidsFolderLoop] = {
	(*loop method*)
	Method->"MuscleBidsConvert", 
	(*general options*)
	ProcessSubjects->All, 
	VersionCheck->False, 
	(*method specific options*)	
	DeleteAfterConversion->True, 
	BidsTractographyMethod->"Full",
	BidsOutputImages->"All"
};

SyntaxInformation[BidsFolderLoop] = {"ArgumentsPattern" -> {_, _, OptionsPattern[]}};

BidsFolderLoop[inFol_?StringQ, outFol_?StringQ, ops:OptionsPattern[]] := BidsFolderLoop[inFol, outFol, {""}, ops]

BidsFolderLoop[inFol_?StringQ, datDis_?AssociationQ, ops:OptionsPattern[]] := BidsFolderLoop[inFol, inFol, datDis, ops]

BidsFolderLoop[inFol_?StringQ, outFol_?StringQ, datDisIn_?AssociationQ, ops:OptionsPattern[]] := Block[{
		met, datType, fols, subs, logFile, ass, nam, filesSl, jsons, versCheck, delete, tractMet,
		files, nTyp, pat, rfol, custConf, out, datDis, imOut
	},

	{met, subs, versCheck, delete, tractMet, imOut} = OptionValue[{
		Method, ProcessSubjects, VersionCheck, DeleteAfterConversion, BidsTractographyMethod, BidsOutputImages}];

	debugBids["Enter BidsFolderLoop for method: "<>met];
	debugBids[inFol];

	(*select the subjects and folders to be processed*)
	fols =Switch[met,
		"BidsDcmToNii", ResetLog[]; Select[FileNames[All, inFol], DirectoryQ],
		_, SelectBidsSessions[SelectBidsSubjects[inFol]]
	];
	subs = If[subs===All||subs==="All", fols, Select[fols, MemberQ[SubNameToBids[subs, "Sub"], SubNameToBids[#, met]]&]];

	debugBids[subs];

	(*loop over the subjects*)
	Table[
		debugBids[fol];

		(* -------------- Config and naming --------------*)

		(*get the BidsName*)
		ass = SubNameToBids[fol, met];
		nam = GenerateBidsName[ass];
		out = GenerateBidsFolderName[outFol, ass];

		debugBids[out];

		(*check for custom config - merge if config exists in input folder and copy it to output folder*)
		debugBids[datDisIn];
		Switch[met,
			"BidsDcmToNii", 
			{custConf, datDis} = CheckConfig[fol, out],
			"MuscleBidsAnalysis",
			custConf = False;
			datDis = If[KeyExistsQ[datDisIn, "Analysis"],
				{datDisIn}, 
				Map[Join[datDisIn[#], <|"Key" -> #|>] &, Keys[datDisIn]]
			],
			_,
			{custConf, datDis} = CheckConfig[fol, out];
			debugBids[{custConf, datDis}];
			datDis = CheckDataDescription[MergeConfig[datDisIn, datDis], met];
		];

		(*-------------- Logging --------------*)
		SetLogFile@Switch[met,
			"BidsDcmToNii", FileNameJoin[{outFol, "DcmToNii_"<>DateName[]<>".log"}],
			"MuscleBidsConvert", FileNameJoin[{fol, nam<>"_BIDSConvert.log"}],
			"MuscleBidsProcess", FileNameJoin[{out, nam<>"_BIDSProcess.log"}],
			"MuscleBidsMerge", FileNameJoin[{out, nam<>"_BIDSMerge.log"}],
			"MuscleBidsSegment", FileNameJoin[{out, nam<>"_BIDSSegment.log"}],
			"MuscleBidsTractography", FileNameJoin[{out, nam<>"_BIDSTractography.log"}],
			"MuscleBidsAnalysis", FileNameJoin[{out, nam<>"_BIDSAnalysis.log"}]
		];
		If[met=!= "BidsDcmToNii", ImportLog[]]; 
		ShowLog[];
		
		(*----*)AddToLog[{"Starting "<>met<>" for directory: ", fol}, True, 0];
		(*----*)If[custConf, AddToLog["**********   -----   Using custom config   -----   **********", 0]];
		If[met === "BidsDcmToNii",
			(*----*)AddToLog["Using Chris Rorden's dcm2niix.exe (https://github.com/rordenlab/dcm2niix)", 1];
		];

		(* -------------- The actual process loops -------------- *)
		Switch[met,
			"BidsDcmToNii", BidsDcmToNiiI[fol, out, datDisIn],
			"MuscleBidsAnalysis", MuscleBidsAnalysisI[fol, outFol, #, versCheck, imOut]&/@datDis
			,
			_,
			(*loop over the data Descriptions*)
			Table[
				(*check if datDis is valid*)
				If[KeyExistsQ[type, $Failed],
					(*----*)AddToLog[dataToLog@type, 2, True];
					(*----*)AddToLog["Skipping", 3],
					(*if valid perform conversion*)
					(*----*)AddToLog[dataToLog@type, 2, True];
					rfol = SelectBidsFolders[fol, type["InFolder"]];
					(*method specific scripts: loop over all folders in subject/session folder*)
					Table[
						Switch[met,
							"MuscleBidsConvert", MuscleBidsConvertI[foli, type, delete],
							"MuscleBidsProcess", MuscleBidsProcessI[foli, outFol, type, versCheck],
							"MuscleBidsMerge", MuscleBidsMergeI[foli, outFol, type, datDis, versCheck],
							"MuscleBidsSegment", MuscleBidsSegmentI[foli, outFol, type, datDis, versCheck],
							"MuscleBidsTractography", MuscleBidsTractographyI[foli, outFol, type, datDis, versCheck, tractMet]
						];(*close method switch*)
					, {foli, rfol}];(*Close sub folders loop*)		
				];(*close type check*)
			, {type, datDis}];(*close datatype loop*)
		]; (*close method switch*)

		(*clear log filename*)
		SetLogFile[];

	, {fol, subs}];(*close subject/folder loop*)
]


(* ::Subsection:: *)
(*1. BidsDcmToNii*)


(* ::Subsubsection::Closed:: *)
(*BidsDcmToNii*)


Options[BidsDcmToNii]={BidsIncludeSession->True, ProcessSubjects->All}

SyntaxInformation[BidsDcmToNii] = {"ArgumentsPattern" -> {_, _., OptionsPattern[]}};

BidsDcmToNii[folder_?StringQ, opts:OptionsPattern[]] := BidsDcmToNii[folder, GetConfig[folder], opts];


BidsDcmToNii[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir},
	debugBids["starting BidsDcmToNii"];
	dir = Directory[]; SetDirectory[folder];
	BidsDcmToNii[
		config["folders"]["dicomData"],(*the input folder of the dcm data*)
		config["folders"]["rawData"],(*the output folder for conversion*)
		Lookup[config, "conversion", <|"Version"->"23"|>],(*the conversion settings*)
		opts];
	SetDirectory[dir];
]


BidsDcmToNii[inFol_?StringQ, outFol_?StringQ, settings_, opts:OptionsPattern[]] := BidsFolderLoop[inFol, outFol, settings, Method->"BidsDcmToNii", opts]


(* ::Subsubsection::Closed:: *)
(*BidsDcmToNiiI*)


BidsDcmToNiiI[fol_, outI_, settings_]:=Block[{out},
	(*define the out folder*)
	out = FileNameJoin[{outI, "raw"}];
	(*----*)AddToLog[{"Output folder: ", out}, 1];
	Quiet[CreateDirectory[out]];

	(*perform the conversions only when output folder is empty*)
	If[EmptyDirectoryQ[out],
		(*perform conversion*)			
		(*----*)AddToLog["Starting the conversion", 1, True];
		DcmToNii[FileNameJoin[{Directory[],#}]&/@{fol,out}, MonitorCalc->False, UseVersion->settings["Version"]];
		(*----*)AddToLog["Folder was converted", 1],
		(*----*)AddToLog["Folder was skipped since output folder already exists", 1];
	];
]


(* ::Subsection:: *)
(*2. MuscleBidsConvert*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsConvert*)


Options[MuscleBidsConvert] = {DeleteAfterConversion->True, ProcessSubjects->All};

SyntaxInformation[MuscleBidsConvert] = {"ArgumentsPattern" -> {_, _., OptionsPattern[]}};

MuscleBidsConvert[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsConvert[folder, GetConfig[folder], opts];


MuscleBidsConvert[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir},
	debugBids["starting MuscleBidsConvert"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsConvert[
		config["folders"]["rawData"],(*the input and output folder for the data*)
		config["folders"]["rawData"],
		config["datasets"],(*what to process*)
		opts];
	SetDirectory[dir];
]


MuscleBidsConvert[niiFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]]:= BidsFolderLoop[niiFol, outFol, datDis, Method->"MuscleBidsConvert", opts]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsConvertI*)


MuscleBidsConvertI[foli_, datType_, del_]:=Block[{
		type, fol, parts, files, json, infoExtra, pos, posIn, info, data, vox, 
		grad, val, suffix, outFile, echo, nEch, fit, labels, class, types
	},

	debugBids["Starting MuscleBidsConvertI"];
	debugBids[foli];

	(*see if one label or session|repetition*)
	{fol, parts} = PartitionBidsFolderName[foli];
	type = datType["Type"];
	labels = Flatten[{datType["Label"]}];
	class = datType["Class"];

	(*-----*)AddToLog[{"Converting", ToString[Length[labels]], class}, 2, True];
	(*-----*)AddToLog[StringJoin@@Riffle[labels,", "], 3];

	(*loop over stac names*)
	Table[
		(*import the json belonging to name*)
		(*-----*)AddToLog[{"Converting", nameIn, "as", type,":"}, True, 3];
		files = FileNames["*"<>StringReplace[nameIn," "->"_"]<>"*.json", foli];

		debugBids[Column[files/. {}->{"!!!!!!!!! No json files found !!!!!!!!!!"}]];

		If[Length@files===0,
			(*no json files found*)
			(*-----*)AddToLog[{"No json files found with label ", nameIn , " skipping conversion"}, 4],

			(*if json files found import them*)
			json = ImportJSON/@files;

			(*see which data type is expected*)
			Switch[datType["Type"],

				(*-------------------------------------------------*)
				(*-------- DIXON conversion script megre ----------*)
				(*-------------------------------------------------*)
				"megre",

				(*if echo time exists assume 4D nii without correct echo times*)
				Switch[datType["Process", "Method"],
					"Dixon-S",

					{suffix, types}=Transpose@datType["Process", "Types"];

					infoExtra = <|
						If[class==="Repetitions"||class ==="Acquisitions", "Repetition"->nameIn, Nothing],
						If[class==="Stacks"||class=="Mixed", "Stack"->nameIn, Nothing],
						If[class==="Stacks"||class=="Mixed", "OverLap"->datType["Overlap"], Nothing]
					|>;

					Table[
						pos = GetJSONPosition[json, {{"SeriesDescription", nameIn<>"_"<>types[[i]]}}];
						If[pos=!={},
						debugBids[{"Dixon-S", nameIn<>"_"<>types[[i]], pos}];
						(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", nameIn}, 4];
						(*get the json and data*)
						info = json[[First@pos]];
						{data, vox} = ImportNii[ConvertExtension[files[[First@pos]],".nii"], NiiScaling->False];

						(*export to the correct folder*)
						outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], "suf"->Flatten@{datType["Suffix"], suffix[[i]]}|>];
						(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
						ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
						Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];

						Quiet@If[del,
							DeleteFile[ConvertExtension[files[[pos]],".nii"]];
							DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
							DeleteFile[ConvertExtension[files[[pos]],".json"]]
						];
						]
					, {i, Length@types}];

					,
					"Dixon-B",
					(*non default with data with 4D nii, where data correction is needed*)
					pos = GetJSONPosition[json, {{"ProtocolName", nameIn}}];
					debugBids["Converting Dix data, json position: ", pos];
					(*get the json and data*)
					(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", nameIn}, 4];

					(*get the json and data*)
					info = json[[First@pos]];
					{data, vox} = ImportNii[ConvertExtension[files[[First@pos]],".nii"], NiiScaling->False];
					(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

					(*assuming data has source and echos figure out the echos and slices*)
					{nSl, nEch} = Dimensions[data][[1 ;; 2]];
					nEch = (nEch - 5)/4;
					(*-----*)AddToLog[{"Slices:", nSl, "; Echos:", nEch}, 4];

					(*extract and convert the relevant data*)
					data = Partition[#, nEch] & /@ Partition[Flatten[Transpose[data], 1][[;; 4 (nSl*nEch)]], nSl nEch];
					(*mag, real, imag, phase*)
					data = {1000. data[[1]]/2047., 1000. (data[[2]] - 2047.)/2047., 1000. (data[[3]] - 2047.)/2047., Pi (data[[4]] - 2047.)/2047.};

					echo = datType["Process", "EchoTime"];
					echo = <|
						"EchoNumber" -> Range[nEch], 
						"EchoTime" -> (echo[[1]] + Range[0, nEch - 1] echo[[2]])/1000.
					|>;
					debugBids[echo];

					(*make the additional mandatory bids json values*)
					infoExtra = <|
						"ForthDimension"->"EchoTime",
						"DataClass"->class,
						If[class==="Repetitions"||class ==="Acquisitions", "Repetition"->nameIn, Nothing],
						If[class==="Stacks"||class=="Mixed", "Stack"->nameIn, Nothing],
						If[class==="Stacks"||class=="Mixed", "OverLap"->datType["Overlap"], Nothing]
					|>;

					Table[
						{i, suffix} = Switch[dixType, "Mixed", {1, ""}, "Phase", {4, "ph"}, "Real", {2, "real"}, "Imaginary", {3, "imag"}];
						(*export to the correct folder*)
						outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], "suf"->Flatten@{datType["Suffix"], suffix}|>];
						(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
						ExportNii[data[[i]], vox, ConvertExtension[outFile, ".nii"]];
						Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[AddToJson[info, "QMRITools"], infoExtra], echo]];

					, {dixType, {"Mixed", "Phase", "Real", "Imaginary"}}];

					(*Delete used files*)
					Quiet@If[del,
						DeleteFile[ConvertExtension[files[[pos]],".nii"]];
						DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
						DeleteFile[ConvertExtension[files[[pos]],".json"]]
					];
					,
					"Dixon",
					(*default script with bids standard of each echo in one file*)
					(*get the position of the files needed*)
					(*loop over dixon data types*)
					Table[
						(*get the position of the files needed*)
						pos = GetJSONPosition[json, {{"ProtocolName", nameIn}, {"ImageType", dixType}}, "EchoNumber"];

						(*-----*)AddToLog[{"Importing", Length[pos], "datasets with properties: ", {nameIn, dixType}}, 4];

						(*get the json and data*)
						info = MergeJSON[json[[pos]]];
						{data, vox} = Transpose[ImportNii[#]&/@ConvertExtension[files[[pos]], ".nii"]];
						data = Transpose[data];
						vox = First@vox;
						(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

						(*correct data for different types*)
						{data, suffix} = Switch[dixType,
							"Mixed", {1000.data/2047.,""},
							"Phase", {Pi (data-2047.)/2047,"ph"},
							"Real", {1000.(data-2047.)/2047.,"real"},
							"Imaginary", {1000.(data-2047.)/2047.,"imag"}
						];

						(*make the additional mandatory bids json values*)
						infoExtra = <|
							"ForthDimension"->"EchoTime",
							"DataClass"->class,
							If[class==="Repetitions", "Repetition"->nameIn, Nothing],
							If[class ==="Acquisitions", "Acquisition"->nameIn, Nothing],
							If[class==="Stacks"||class=="Mixed", "Stack"->nameIn, Nothing],
							If[class==="Stacks"||class=="Mixed", "OverLap"->datType["Overlap"], Nothing]
						|>;

						(*export to the correct folder*)
						outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], "suf"->Flatten@{datType["Suffix"], suffix}|>];
						(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
						ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
						Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];

						(*Delete used files*)
						Quiet@If[del,
							DeleteFile[ConvertExtension[files[[pos]],".nii"]];
							DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
							DeleteFile[ConvertExtension[files[[pos]],".json"]]
						];

					(*Close loop over dixon data types*)
					, {dixType, {"Mixed", "Phase", "Real", "Imaginary"}}]
				],

				(*-------------------------------------------*)
				(*---------- DWI conversion script ----------*)
				(*-------------------------------------------*)
				"dwi",

				(*get the position of the files needed*)
				pos = GetJSONPosition[json, {{"ProtocolName", nameIn}}];
				debugBids["Converting DWI data, json position: ", pos];

				(*get the json and data*)
				(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", nameIn}, 4];

				(*get the json and data*)
				info = json[[First@pos]];
				{data, grad, val, vox} = ImportNiiDiff[ConvertExtension[files[[First@pos]],".nii"], FlipBvec->False];
				(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

				(*make the additional mandatory bids json values*)
				infoExtra=<|
					"ForthDimension"->"Diffusion",
					"DataClass"->class,
					If[class==="Repetitions", "Repetition"->nameIn, Nothing],
					If[class ==="Acquisitions", "Acquisition"->nameIn, Nothing],
					If[class==="Stacks"||class=="Mixed", "Stack"->nameIn, Nothing],
					If[class==="Stacks"||class=="Mixed", "OverLap"->datType["Overlap"], Nothing]
				|>;

				(*export to the correct folder*)
				debugBids[{parts, type, GetClassName[class, nameIn], datType["Suffix"]}];
				outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], "suf"->{datType["Suffix"]}|>];
				(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
				ExportBval[val, ConvertExtension[outFile, ".bval"]];
				ExportBvec[grad, ConvertExtension[outFile, ".bvec"]];
				ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
				Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];

				Quiet@If[del,
					(*-----*)AddToLog[{"Deleting", Length[pos], type, "dataset with properties: ", nameIn}, 4];
					DeleteFile[ConvertExtension[files[[pos]],".nii"]];
					DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
					DeleteFile[ConvertExtension[files[[pos]],".json"]];
					DeleteFile[ConvertExtension[files[[pos]],".bval"]];
					DeleteFile[ConvertExtension[files[[pos]],".bvec"]];
				],

				(*-------------------------------------------*)
				(*----------- T2 conversion script ----------*)
				(*-------------------------------------------*)
				"mese",

				(*if echo time exists assume 4D nii without correct echo times*)
				If[KeyExistsQ[datType["Process"], "EchoTime"],
					pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}];

					(*get the json and data*)
					If[Length[pos] > 1,
						pos = pos[[{-1}]];
						AddToLog[{"!!!!!Multiple files found, taking last file"}, 4];
						debugBids["!!!!!Multiple files found, taking last file: "];
					];

					debugBids["Converting MESE data, json position: ", pos];
					(*get the json and data*)
					(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", nameIn}, 4];

					(*echo times - get the echo time from the data json if present*)
					info = json[[First@pos]];

					If[KeyExistsQ[info, "EchoTime"] && KeyExistsQ[info, "EchoTrainLength"] || info["Manufacturer"]==="Siemens",
						{data, vox} = ImportNii[ConvertExtension[files[[First@pos]],".nii"]],
						{data, fit, vox} = ImportNiiT2[ConvertExtension[files[[First@pos]],".nii"]]
					];
					(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
					echo = Lookup[info, "EchoTime", datType["Process", "EchoTime"]/1000.];
					nEch = Lookup[info, "EchoTrainLength", Length[data[[1]]]];
					info = KeyDrop[info, "EchoTime"];
					echo = <|
						"EchoNumber" -> Range[nEch], 
						"EchoTime" -> (echo + Range[0, nEch - 1] echo)
					|>;
					debugBids[echo];

					,

					(*get the position of the files needed*)
					pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}, "EchoTime"];
					(*select only echos*)
					info = MergeJSON[json[[pos]]];
					pos = pos[[;; info["EchoTrainLength"]]];
					(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", nameIn}, 4];

					(*get the json and data*)
					AssociateTo[info, "EchoNumber" -> Range@info["EchoTrainLength"]];
					{data, vox} = Transpose[ImportNii /@ ConvertExtension[files[[pos]],".nii"]];
					data = Transpose[data];
					vox = First@vox;
					(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

					echo = <||>;
				];

				(*make the additional mandatory bids json values*)
				infoExtra = Join[<|
					"ForthDimension"->"EchoTime",
					"DataClass"->class,
					If[class==="Repetitions", "Repetition"->nameIn, Nothing],
					If[class ==="Acquisitions", "Acquisition"->nameIn, Nothing],
					If[class==="Stacks"||class=="Mixed", "Stack"->nameIn, Nothing],
					If[class==="Stacks"||class=="Mixed", "OverLap"->datType["Overlap"], Nothing]
				|>, echo];

				(*export to the correct folder*)
				outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], "suf"->{datType["Suffix"]}|>];
				(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
				ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
				Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];

				(*Delete used files*)
				Quiet@If[del,
					(*-----*)AddToLog[{"Deleting", Length[posIn], type, "datasets with properties: ", nameIn},4];
					DeleteFile[ConvertExtension[files[[posIn]],".nii"]];
					DeleteFile[ConvertExtension[files[[posIn]],".nii.gz"]];
					DeleteFile[ConvertExtension[files[[posIn]],".json"]]
				]

				,

				(*-------------------------------------------*)
				(*-------- Other processing script ----------*)
				(*-------------------------------------------*)
				_,
				(*-----*)AddToLog["Unknown datatype for conversion", 4];

			(*Close Type switch*)
			];
		(*close file check*)	
		];
	(*close loop over stac names*)
	,{nameIn, labels}];
] 


(* ::Subsection:: *)
(*3. MuscleBidsProcess*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsProcess*)


Options[MuscleBidsProcess] = {ProcessSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsProcess] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsProcess[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsProcess[folder, GetConfig[folder], opts];


MuscleBidsProcess[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir},
	debugBids["starting MuscleBidsProcess"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsProcess[
		config["folders"]["rawData"],(*the input folder for the data*)
		config["folders"]["derivedData"],(*the output folder for processing*)
		config["datasets"],(*what to process*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsProcess[niiFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, ops:OptionsPattern[]]:= BidsFolderLoop[niiFol, outFol, datDis, Method->"MuscleBidsProcess", ops]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsProcessI*)


MuscleBidsProcessI[foli_, folo_, datType_, verCheck_]:=Block[{
		con, fol, parts, type, files, sets, diffFile, nfile, process, keys, dixFiles, jfile, nFiles, phbpt, dbond,
		outfile, json, echos, mag, ph, real, imag, dvox, magM, B0mask, ph0i, pos, e1, e2, hz, b0i,
		t2stari, watfr, fatfr, wat, fat , inph, outph, b0, t2star, r2star, phi, itt, res, outTypes, preProc, 
		nfilep, resi, data, grad, val, diffvox, mask, den, sig, snr, snr0, reg, valU, mean, fiti, s0i, fri, 
		adci, pD, tens, s0, out, l1, l2, l3, md, fa, rd, t2vox, t2w, t2f, b1, n, angle, ex, ref, thk, 
		phii, phbpi, phbp, ta, filt, field
	},

	debugBids["Starting MuscleBidsProcessI"];
	debugBids[foli, folo];

	(*get the context for exporting*)
	con = Context[con];

	(*get the information needed for processing, e.g. session|repetition*)
	{fol, parts} = PartitionBidsFolderName[foli];
	type = datType["Type"];
	process = datType["Process"];
	keys = {"EchoTime", "ForthDimension", "DataClass", "Stack", "OverLap", "SliceThickness", "SpacingBetweenSlices"};

	(*see what needs to be processed*)
	files = Flatten[FileNames["*"<>StringReplace[#, notAllowed]<>"*.json", foli]& /@ Flatten[{datType["Label"]}]];
	sets = If[type==="megre",
		DeleteDuplicates[(ta = #;AssociateTo[ta, "suf"->{First[ta["suf"]]}])&/@PartitionBidsName[FileBaseName/@files]],
		DeleteDuplicates[PartitionBidsName[FileBaseName/@files]]];
	(*-----*)AddToLog[{"Found", ToString[Length[sets]], datType["Class"], "that will be processed:"}, 2];

	(*loop over sets*)
	Table[
		(*-----*)AddToLog[dataToLog@set, 2];
		(*see which data type is expected*)
		Switch[type,

			"megre",
			(*-------------------------------------------*)
			(*-------- megre processing scripts ---------*)
			(*-------------------------------------------*)

			Switch[process["Method"],

				(*-------------------------------------------*)
				(*-------- Dixon processing scripts ---------*)
				(*-------------------------------------------*)

				"Dixon-S",
				{suffix, types} = Transpose@datType["Process","Types"];
				dixFiles = GenerateBidsFileName[fol, <|set, "suf"->{datType["Suffix"], #}|>]&/@suffix;
				jfile = ConvertExtension[First@dixFiles, ".json"];
				nFiles = ConvertExtension[dixFiles, ".nii"];

				(*ouput file names*)
				outfile = GenerateBidsFileName[folo, set];
				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if check file has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[First@dixFiles, 4];

					If[!AllTrue[nFiles, NiiFileExistQ],
						(*----*)AddToLog[{"Could not find all the ", First@dixFiles}, 4],
						(*----*)AddToLog["Importing the data", 4];
						{data, dvox} = Transpose[ImportNii/@nFiles];

						pos = Flatten[Position[suffix, #] & /@ {"inph", "outph", "fat", "wat"}];
						mask = If[pos=!={},
							Mask[NormalizeData[Mean[NormalizeData /@ data[[pos]]]], 15,
								MaskSmoothing -> True, MaskComponents -> 2, MaskClosing -> 2, MaskDilation -> 1],
							1
						];
						
						If[MemberQ[suffix, "inph"], inph = mask data[[Position[suffix,"inph"][[1,1]]]]];
						
						If[MemberQ[suffix, "t2star"],
							t2star = mask data[[Position[suffix,"t2star"][[1,1]]]] / 10000.;
							r2star = DivideNoZero[1, t2star];
							AppendTo[suffix, "r2star"]];
						If[MemberQ[suffix, "fatfr"],
							fatfr = mask data[[Position[suffix,"fatfr"][[1,1]]]] / 100.;
							watfr = mask - fatfr;
							AppendTo[suffix, "watfr"]];
						If[MemberQ[suffix, "wat"], wat = mask data[[Position[suffix,"wat"][[1,1]]]]];
						If[MemberQ[suffix, "fat"], fat = mask data[[Position[suffix,"fat"][[1,1]]]]];
						If[MemberQ[suffix, "inph"], inph = mask data[[Position[suffix,"inph"][[1,1]]]]];
						If[MemberQ[suffix, "outph"], outph = mask data[[Position[suffix,"outph"][[1,1]]]]];
					];

					(*export all the calculated data*)
					(*----*)AddToLog["Exporting the calculated data to:", 4];
					(*----*)AddToLog[outfile,5];
					outTypes = suffix;
					ExportNii[ToExpression[con<>#], First@dvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;

					(*export the check file*)
					MakeCheckFile[outfile, Sort@Join[
						{"Check"->"done", "Outputs" -> outTypes, "SetProperties"->set}
					]];
				];
				(*----*)AddToLog["Finished processing", 3, True];

				,
				"Dixon"|"Dixon-B",
				(*input file names*)
				dixFiles = GenerateBidsFileName[fol, <|set, "suf"->{datType["Suffix"], #}|>]&/@{"real", "imag"};
				jfile = ConvertExtension[First@dixFiles, ".json"];
				nFiles = ConvertExtension[dixFiles, ".nii"];

				(*ouput file names*)
				outfile = GenerateBidsFileName[folo, set];

				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if check file has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[First@dixFiles, 4];

					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*----*)AddToLog["Could not find the needed JSON file", 4];,
						(*Check if needed nii Exist*)
						If[!AllTrue[nFiles, NiiFileExistQ],
							(*----*)AddToLog[{"Could not find all the ", First@dixFiles}, 4],
							(*----*)AddToLog["Importing the data", 4];

							(*import the data*)
							json = ImportJSON[jfile];
							{echos, field} = json /@ {"EchoTime", "MagneticFieldStrength"};

							{{real, imag}, dvox} = Transpose[ImportNii/@nFiles];
							dvox = First@dvox;

							(*Apply background mask*)
							magM = NormalizeMeanData@Abs[real + I imag];
							B0mask = Mask[magM, 15, MaskSmoothing->True, MaskComponents->2, MaskClosing->2, MaskDilation->1];
							{real, imag} = MaskData[#, B0mask] &/@ {real, imag};

							(*----*)AddToLog["Starting denoising and SNR calculation", 4];
							{{real, imag}, sig} = PCADeNoise[{real, imag}, PCAKernel -> 5, Method -> "Patch", PCAComplex -> True];
							{mag, ph} = Through[{Abs, Arg}[real + I imag]];
							snr = SNRCalc[Mean@Transpose@mag, sig];

							{mag, ph} = Through[{Abs, Arg}[real + I imag]];

							Switch[process["Method"],
								"Dixon",

								(*see if there are dixon flips*)
								(*{{mag, ph, real, imag}, pos} = FixDixonFlips[{mag, ph, real, imag}];
								(*-----*)If[pos=!={}, AddToLog[{"Found complex flips in volumes: ", pos}, 4]];*)
								pos={};

								(*calculated field maps*)
								(*-----*)AddToLog[{"Starting field map calcualtion"}, 4];
								{{b0i, t2stari, phii, phbpi}, {e1, e2, n}} = DixonPhase[{real, imag}, echos];
								(*-----*)AddToLog[{"used echo ", ToString[e1], "(", 1000 echos[[e1]],"ms ) and", ToString[e2], "(", 1000 echos[[e2]], "ms )"}, 5];

								(*perform the IDEAL dixon fit*)
								(*-----*)AddToLog["Starting Dixon reconstruction", 4];

								(*fit with DB fat model*)
								{{watfr, fatfr}, {wat, fat, dbond}, {inph, outph}, {{b0, phbp, phi, phbpt}, {t2star, r2star}}, itt, res} = DixonReconstruct[
									{real, imag}, echos, {b0i, t2stari, phii, phbpi}, 
									DixonPhases -> {True, True, True, True, True}, 
									DixonFixT2 -> False, DixonFieldStrength -> field, 
									DixonAmplitudes -> "CallDB", DixonTolerance->1];

								pos = {"DixonFlips" -> pos, "DixonBipolar" -> True};
								outTypes = {"dbond", "phbp", "phi", "phbpt", "phii", "phbpi"};

								,
								"Dixon-B"
								,

								(*uwrap and convert B0 to hz*)
								(*-----*)AddToLog[{"Starting field map calcualtion"}, 4];
								b0i = UnwrapSplit[ph[[All, -1]] - ph[[All, 1]], mag, UnwrapDimension -> "3D", MonitorUnwrap -> False];
								b0i = b0i/(2 Pi Length[echos]  (echos[[2]] - echos[[1]]));
								(*calculate the t2 star from the two in phase images*)
								t2stari = T2Fit[mag, echos][[2]];

								debugBids[Dimensions/@{real,imag, b0i, t2stari}];
								debugBids[echos];

								(*perform the IDEAL dixon fit*)
								(*-----*)AddToLog["Starting Dixon reconstruction", 4];
								{{watfr, fatfr}, {wat, fat}, {inph, outph}, {{b0}, {t2star, r2star}}, itt, res} = DixonReconstruct[{real, imag}, echos, {b0i, t2stari}, DixonClipFraction -> True];

								outTypes = pos = {};
							];

							{wat, fat} = Abs[{wat, fat}];

							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:", 4];
							(*----*)AddToLog[outfile,5];
							outTypes = Join[{"real", "imag", "mag", "ph", "b0i", "t2stari", "b0", "t2star", "r2star", 
								"inph", "outph", "wat", "fat", "watfr", "fatfr", "itt", "res", "snr", "sig"}, outTypes];
							ExportNii[ToExpression[con<>#], dvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;

							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "EchoTimes"->echos, "Outputs" -> outTypes, "SetProperteis"->set}, pos,
								ExtractFromJSON[json, keys]
							]];
							(*----*)AddToLog["Finished processing", 3, True];
						]
					]
				(*close dixon processing*)
				],

				_,
				(*-------------------------------------------*)
				(*-------------- Unknown megre --------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];

			(*close megre processing*)
			],

			"dwi",
			(*-------------------------------------------*)
			(*--------- dwi processing script -----------*)
			(*-------------------------------------------*)

			(*input file names*)
			diffFile = GenerateBidsFileName[fol, set];
			jfile = ConvertExtension[diffFile,".json"];
			nfile = ConvertExtension[diffFile,".nii"];

			(*ouput file names*)
			outfile = GenerateBidsFileName[folo, set];

			(*-------------------------------------------*)
			(*------- dwi pre -processing script --------*)
			(*-------------------------------------------*)

			(*check if pre-processin is already done*)
			preProc = False;
			If[CheckFile[outfile<>"_prep", "done", verCheck],
				(*if checkfile has label done and version is recent skip*)
				(*----*)AddToLog["Pre-processing already done for: ", True, 3];
				(*----*)AddToLog[outfile, 4],
				(*----*)AddToLog["Starting pre-processing for data:", 3, True];
				(*----*)AddToLog[diffFile, 4];

				If[!FileExistsQ[jfile],
					(*----*)AddToLog["Could not find the needed JSON file",4],
					(*Check if needed nii Exist*)
					If[!(NiiFileExistQ[nfile]&&FileExistsQ[ConvertExtension[nfile,".bval"]]&&FileExistsQ[ConvertExtension[nfile,".bvec"]]),
						(*----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"},4],
						(*----*)AddToLog["Importing the data", 4];

						(*import the data*)
						json = ImportJSON[jfile];
						{data, grad, val, diffvox} = ImportNiiDiff[nfile, FlipBvec->False];
						{data, grad, val} = SortDiffusionData[NormalizeData[data], grad, val];

						(*Denoise and SNR*)
						(*-----*)AddToLog["Starting dwi denoising", 4];
						mask = Mask[NormalizeMeanData[data],  Lookup[process, "Masking", 5], MaskSmoothing->True, MaskComponents->2, MaskDilation->1];
						{den, sig} = PCADeNoise[data, mask, PCAOutput->False, PCATolerance->0, PCAKernel->5];
						snr = SNRCalc[den, sig];
						snr0 = Mean@Transpose@First@SelectBvalueData[{snr, val}, {0, 2}];

						(*register data - each leg seperate*)
						(*-----*)AddToLog["Starting dwi motion and eddy correction", 4];
						reg = RegisterDiffusionDataSplit[{den, mask, diffvox}, Iterations->300, NumberSamples->5000, PrintTempDirectory->False];

						(*anisotropic filtering*)
						(*-----*)AddToLog["Starting anisotrpic data smoothing", 4];
						filt = AnisoFilterData[reg, diffvox];

						(*export all the calculated data*)
						(*----*)AddToLog["Exporting the calculated data to:",4];
						(*----*)AddToLog[outfile, 5];
						outTypes = {"den", "reg", "sig", "snr0", "snr", "filt"};
						ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
						ExportBval[val, ConvertExtension[outfile <> "_"<>#, ".bval"]]&/@{"reg","filt"};
						ExportBvec[grad, ConvertExtension[outfile <> "_"<>#, ".bvec"]]&/@{"reg","filt"};

						(*export the checkfile*)
						MakeCheckFile[outfile<>"_prep", Sort@Join[
							{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, "Outputs" -> outTypes, "SetProperteis"->set},
							ExtractFromJSON[json,keys]
						]];
						(*----*)AddToLog["Finished pre-processing", 3, True];

						(*Set preproc true, overrules checkfile for processing*)
						preProc = True;
					]
				]
			(*close preprocessing*)
			];

			Switch[process["Method"],

				"DTI",
				(*-------------------------------------------*)
				(*---------- dwi processing script ----------*)
				(*-------------------------------------------*)

				(*input file for processing*)
				nfilep = ConvertExtension[GenerateBidsFileName[folo, <|set, "suf"->{datType["Suffix"], "filt"}|>],".nii"];

				(*check if processin is already done, redo is prep is done*)					
				If[If[!preProc, CheckFile[outfile, "done", verCheck], False],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[nfilep, 4];				

					If[!FileExistsQ[jfile],
						(*----*)AddToLog["Could not find the needed JSON file", 4];,

						(*Check if needed nii Exist*)
						If[!(NiiFileExistQ[nfilep]&&FileExistsQ[ConvertExtension[nfilep,".bval"]]&&FileExistsQ[ConvertExtension[nfilep,".bvec"]]),
							(*----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"}, 4],
							(*----*)AddToLog["Importing the data", 4];

							(*import the data*)
							json = ImportJSON[jfile];
							{data, grad, val, diffvox} = ImportNiiDiff[nfilep, FlipBvec->False];
							mask = Mask[NormalizeMeanData[data], Lookup[process, "Masking", 5], MaskSmoothing->True, MaskComponents->2, MaskClosing->2];
							data = MaskData[data, mask];
							(*get bvalues and mean data*)
							{mean, valU} = MeanBvalueSignal[data, val];

							(*initialize IVIM fit*)
							(*-----*)AddToLog["Starting ivim calculation", 4];
							fiti = IVIMCalc[MeanSignal[mean], valU, {1,.05,.003,.015}, IVIMFixed->True];
							(*perform IVIM correction*)
							{s0i, fri, adci, pD}= Quiet@IVIMCalc[mean, valU, fiti, IVIMConstrained->False, Parallelize->True, MonitorIVIMCalc->False, IVIMFixed->True];
							fri = Clip[fri, {0,1}, {0,1}];
							adci = 1000 adci;
							resi = Quiet@IVIMResiduals[mean, valU, {s0i, fri, adci, pD}];

							(*calculate tensor from corrected data*)
							(*-----*)AddToLog["Starting tensor calculation", 4];
							data = First@IVIMCorrectData[data, {s0i, fri, pD}, val, FilterMaps->False];
							{tens, s0, out, res} = Quiet@TensorCalc[data, grad, val, FullOutput->True, Method->"iWLLS", RobustFit->True, Parallelize->True, MonitorCalc->False];
							out = Total@Transpose@out;
							(*calculate tensor parameters*)
							{l1, l2, l3, md, fa} = ParameterCalc[tens];
							rd = Mean[{l2, l3}];
							tens = Transpose[tens];

							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:", 4];
							(*----*)AddToLog[outfile, 5];					
							outTypes = {"data", "mean", "tens", "res", "out", "s0", 
								"l1", "l2", "l3", "md",	"fa", "rd", "adci", "fri", "s0i"};
							ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
													
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[json,keys]
							]];
							(*----*)AddToLog["Finished processing", 3, True];				
						]
					]
				(*close dti processing*)
				],

				_,
				(*-------------------------------------------*)
				(*--------------- Unknown dti ---------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			],

			"mese",
			(*-------------------------------------------*)
			(*-------- mese processing scripts ----------*)
			(*-------------------------------------------*)

			Switch[process["Method"],				

				"EPGT2",
				(*-------------------------------------------*)
				(*---------- EPG processing script ----------*)
				(*-------------------------------------------*)

				(*input file names*)
				diffFile = GenerateBidsFileName[fol, set];
				jfile = ConvertExtension[diffFile,".json"];
				nfile = ConvertExtension[diffFile,".nii"];

				(*ouput file names*)
				outfile = GenerateBidsFileName[folo, set];

				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[diffFile, 4];

					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*----*)AddToLog[{"Could not find the needed JSON file of", jfile}, 4];,
						(*Check if needed nii Exist*)
						If[!NiiFileExistQ[nfile],
							(*----*)AddToLog[{"Could not find the data of", diffFile}, 4],
							(*----*)AddToLog["Importing the data", 4];

							(*import the data*)
							json = ImportJSON[jfile];
							echos = json["EchoTime"];
							{data, t2vox} = ImportNii[nfile];

							(*mask the background*)		
							mask = Mask[NormalizeMeanData[data], 2, MaskSmoothing -> True, MaskComponents -> 2, MaskClosing -> 2];
							data = MaskData[data, mask];

							(*determine the pulse profiles*)
							(*-----*)AddToLog["Calculating the slice profiles", 4];							
							{ex, ref} = datType["Process", "Settings"];
							angle = If[NumberQ[ex]&&NumberQ[ref],
								{ex, ref},							
								thk = 2 json["SliceThickness"];
								GetPulseProfile[ex, ref, SliceRange -> thk, SliceRangeSamples -> thk][[1;;2]]
							];

							(*caculate the water t2 map*)
							(*-----*)AddToLog["Starting EPG T2 calculation", 4];
							{{t2w, t2f, b1}, {wat, fat, fatfr}, res} = EPGT2Fit[data, 1000 echos, angle, 
								MonitorCalc -> False, DictT2IncludeWater -> True, DictT2fValue -> 200, DictT2fRange -> {150, 250, 5}, 
								DictB1Range -> {0.5, 1.4, 0.02}, DictT2Range -> {15, 45, 0.2}];

							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:", 4];
							(*----*)AddToLog[outfile, 5];					
							outTypes = {"data", "t2w", "t2f", "b1", "wat", "fat", "fatfr", "res"};
							ExportNii[ToExpression[con<>#], t2vox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
													
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "EchoTimes" -> echos, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[json,keys]
							]];
							(*----*)AddToLog["Finished processing", 3, True];
						]
					]
				(*close t2 processing*)
				],

				_,
				(*-------------------------------------------*)
				(*--------------- Unknown mese ---------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			],
			(*-------------------------------------------*)
			(*------------------ Other ------------------*)
			(*-------------------------------------------*)
			_,
			(*-----*)AddToLog["Unknown datatype for processing", 4];

		(*Close Type switch*)
		];

	(*close loop over sets*)
	, {set, sets}]
]


(* ::Subsection:: *)
(*4. MuscleBidsMerge*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsMerge*)


Options[MuscleBidsMerge] = {ProcessSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsMerge] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsMerge[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsMerge[folder, GetConfig[folder], opts];


MuscleBidsMerge[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir}, 
	debugBids["starting MuscleBidsMerge"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsMerge[
		config["folders"]["derivedData"],(*the input folder for the data*)
		config["folders"]["mergeData"],(*the output folder for merging*)
		config["datasets"],(*what to process*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsMerge[datFol_?StringQ, merFol_?StringQ, datDis_?AssociationQ, ops:OptionsPattern[]]:= BidsFolderLoop[datFol, merFol, datDis, Method->"MuscleBidsMerge", ops]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsMergeI*)


MuscleBidsMergeI[foli_, folo_, datType_, allType_, verCheck_]:=Block[{
		nonQuant, motion, reverse, fol, parts, merge, outfile, tarType, tarSuf, tarCon, tarFile, movType, movCon, n,
		movs, movStacs, tarStacs, overT, overM, targets, movings, mov, nStac, nCheck, nSet, target, voxt, moving, 
		voxm, files, im, func, reg, mskm, mskt, vox, sameType, metReg, pad, movp,
		multDim, movsA, movsMD, movingsA, movingsMD, movingA, movingMD, leng, lengMD
	},

	debugBids["Starting MuscleBidsMergeI"];
	debugBids[foli, folo];
	debugBids[datType];

	(*!!options!!*)
	motion = True;
	reverse = False;

	(*muscle bids that are non quantitative of multi dimensional*)
	nonQuant = {"inph", "outph", "wat", "fat", "s0"};
	multDim = {"tens"};

	(*figure out if duplicate handeling is needed.*)
	duplicate = KeyExistsQ[datType, "Key"];

	(*get the outfile names*)
	{fol, parts} = PartitionBidsFolderName[foli];
	merge = datType["Merging"];
	outfile = GenerateBidsFileName[folo, <|parts, If[duplicate, "stk"->stringStrip@datType["Key"], Nothing], "type"->datType["Type"], "suf"->datType["Suffix"]|>];

	debugBids[{parts, outfile}];

	debugBids[{duplicate, Length[merge["Target"]], duplicate && Length[merge["Target"]] ===3}];

	(*get the settings for the target data if there are duplicates the target needs to be 4 else 3*)
	If[duplicate && Length[merge["Target"]] ===3,
		(*-----*)AddToLog[{"Skipping merging since there are duplicate data and the targerts are unclear"}, 3];
		Return[]
	];

	If[duplicate,
		{tarDat, tarType, tarSuf, tarCon} = merge["Target"];
		tarFile = GenerateBidsFileName[folo, <|parts, "stk"->tarDat, "type"->tarType, "suf"->{tarSuf, tarCon}|>]<>".nii";
		tarStacs = stringStrip /@First[Select[allType, #["Key"] === tarDat &]]["Label"];
		,
		{tarType, tarSuf, tarCon} = merge["Target"];
		tarFile = GenerateBidsFileName[folo, <|parts, "type"->tarType, "suf"->{tarSuf, tarCon}|>]<>".nii";
		tarStacs = stringStrip /@ First[Select[allType, #["InFolder"] === tarSuf &]]["Label"];
	];
	(*tarStacs = StringReplace[#, {"-" -> "", "_" -> "", "." -> ""}]& /@ First[Select[allType, #["InFolder"] === tarSuf &]]["Label"];*)
	debugBids[tarStacs];

	(*check if moving is the same type as target*)
	sameType = tarType === datType["Type"] && tarSuf === datType["Suffix"];

	(*get the settings for the moving data*)
	movType = datType["InFolder"];
	movCon = merge["Moving"];
	movStacs = StringReplace[#, notAllowed]&/@datType["Label"];
	movs = Select[merge["Process"], ! MemberQ[multDim, #] &];
	movsMD = Select[merge["Process"], MemberQ[multDim, #] &];
	movsA = Join[movs, movsMD];

	(*get the settings for the merging*) 
	overT = merge["Overlap"];
	{overT, overM} = If[IntegerQ[overT], {overT, overT}, overT];
	pad = Lookup[merge, "Padding", 0];

	(*check if the target file exists*)
	debugBids[{overT, pad}];

	(*start the merging, if checkfile has label done and version is recent skip*)
	If[CheckFile[outfile, "done", verCheck],
		(*-----*)AddToLog[{"Processing already done for:"}, 3];
		(*-----*)AddToLog[{StringJoin@Riffle[movsA,", "]}, 4];
		Return[]
	];

	(*-----*)AddToLog[{"The types that will be merged are: "}, 3];
	(*-----*)AddToLog[{StringJoin@Riffle[movsA,", "]}, 4];
	If[pad > 0, 
		(*-----*)AddToLog[{"Padding overlap with: ", pad}, 5]
	];

	(*get all the moving and target data file names*)
	targets = Flatten[FileNames["*"<>#<>"*"<>tarSuf<>"*"<>tarCon<>".nii.gz", FileNameJoin[{DirectoryName[foli], tarSuf}]]&/@tarStacs];
	debugBids[targets];

	movings = (mov = #; Flatten[FileNames["*"<>#<>"*"<>mov<>".nii.gz", foli]& /@movStacs])& /@movs;
	movingsMD = (mov = #; Flatten[FileNames["*"<>#<>"*"<>mov<>".nii.gz", foli]& /@movStacs])& /@movsMD;
	movingsA = Join[movings, movingsMD];

	(*check if number of stacks are consistant*)
	nStac = Length@movStacs;
	nSet = Length[movsA];
	nCheck = AllTrue[n=Join[{Length[targets]}, Length/@movingsA], #===nStac&];

	If[!nCheck,
		(*-----*)AddToLog[{"Not all types have the same number of stacs:", StringJoin@Riffle[ToString/@n,", "]}, 3];
		Return[]
	];

	(*-----*)AddToLog[{"Start joining ", nStac, "stacs for", nSet, "dataypes"}, 3];

	(*import the Target data, import merged target if it exists else merge it*)
	(*-----*)AddToLog[{"Importing and processing the target data"}, 4];

	(*if target is same type as moving always perform joinsets, never load from disk*)
	If[NiiFileExistQ[tarFile] && !sameType,
		{target, voxt} = ImportNii[tarFile];
		(*-----*)AddToLog[{"Splitting the primary datatype that already existed"}, 4];
		target = If[nStac=!=1, SplitSets[target, nStac, overT, ReverseSets->reverse, PadOverlap->pad], {target}];
		,
		(*remake target*)
		{target, vox} = Transpose[ImportNii/@targets];
		voxt = First@vox;
		(* make data real valued*)
		target = If[RealValuedNumberQ[target[[1, 1, 1, 1]]], target, Abs[target]];

		(*-----*)AddToLog[{"Joining the primary datatype",If[motion,"with","without"],"motion correction"}, 4];
		If[nStac=!=1,
			target = JoinSets[target, overT, voxt, ReverseSets->reverse, MotionCorrectSets->motion, 
				NormalizeSets->True, NormalizeOverlap->True, MonitorCalc->False];
			target = SplitSets[target, nStac, overT, ReverseSets->reverse, PadOverlap->pad];
		];
	];

	debugBids["target dimensions: ",Dimensions/@target];

	(*-----*)AddToLog[{"Importing and processing the moving data"}, 4];
	(*import the moving data, only import multi dim if present*)
	{moving, vox} = Transpose[(files=#; Transpose[ImportNii[#]&/@files]) &/@ movings];

	(* make data real valued*)
	moving = If[RealValuedNumberQ[N@#[[1,1,1,1]]], #, Abs[#]] &/@ moving;
	leng = Length[movs];
	voxm = First@vox;
	(*check voxel sizes of moving*)
	If[!Equal@@voxm,
		(*-----*)AddToLog[{"**********  The voxel size is not the same for all stacks **********"}, 0];
		(*-----*)AddToLog[{"Voxel size per stack: ", voxm}, 4];
		(*-----*)AddToLog[{"",(Dimensions /@ First@moving) voxm}, 4];
	];

	(*import the multi dim data*)
	movingMD = If[movingsMD=!={},
		{movingMD, vox} = Transpose[(files=#;Transpose[ImportNii[#]&/@files])& /@movingsMD];
		lengMD = Length /@ movingMD[[All, 1, 1]];
		Flatten[movingMD, {1, 4}],
		{}];
	movingA = Join[moving, movingMD];

	debugBids["moving dimensions: ", Dimensions@movingA];
	debugBids["moving before registr: ", Column[Dimensions /@ # & /@ movingA]];

	(*perform motion correction after target merging*)
	(*If motion correction for joning is False and target is of same type no need for motion correction*)
	debugBids["go into registration:", {motion, sameType, !(!motion && sameType)}];
	If[!(!motion && sameType), 
		(*-----*)AddToLog[{"Performing the registration for the all the datasets"}, 4];
		im = First@First@Position[movs, movCon];
		debugBids["im: ", im];
		movingA = Table[
			debugBids["start registration: ", i];

			(*make masks*)
			debugBids[Dimensions/@{movingA[[im, i]], target[[i]]}];
			mskm = DilateMask[Mask[NormalizeData[movingA[[im, i]]], 5], 5];
			mskt = DilateMask[Mask[NormalizeData[target[[i]]], 5], 5];
			debugBids[Dimensions/@{mskm, mskt}];

			(*register the data*)
			metReg = Switch[movType, "dix", "rigid", "quant", {"rigid", "affine"}, _, {"rigid","affine","bspline"}];

			(*only register if not the same contrast and not the first stack*)
			debugBids["check for registration: ", {i===If[reverse, nStac, 1], sameType, i===If[reverse, nStac, 1]&& sameType}];
			If[i===If[reverse, nStac, 1] && sameType,
				(*just select data and do nothing*)
				debugBids["no registration: ", i];
				Transpose[movingA[[All, i]]]
				,
				(*only split if not first stack*)
				(*move the target from anatomical to native space*)
				func = If[i===If[reverse, nStac, 1], RegisterData, RegisterDataSplit];
				reg = ToPackedArray@N@Chop@func[
					{movingA[[im, i]], mskm, voxm[[i]]}, {target[[i]], voxt}, 
					Iterations->300, BsplineSpacing->40 voxt, InterpolationOrderReg->1, NumberSamples -> 10000,
					PrintTempDirectory->False, MethodReg->metReg];

				(*if padding enlarge the moving files*)
				If[pad > 0,					
					reg = ArrayPad[reg, Ceiling@{{pad, pad}/2, 0, 0}];
					movp = Transpose[ArrayPad[#, Ceiling@{{pad, pad}/2, 0, 0}]&/@movingA[[All, i]]],
					movp = Transpose[movingA[[All, i]]]
				];

				debugBids["padding reg: ", i," ", Dimensions@reg];
				debugBids["padding moving: ", i," ", Dimensions/@Transpose[movp]];

				(*register back the target from native space to anatomy and tranfrom the rest*)
				func = If[i===If[reverse, nStac, 1], RegisterDataTransform, RegisterDataTransformSplit];
				ToPackedArray@N@Chop@Last@func[
					{target[[i]], mskt, voxt}, {reg, voxm[[i]]}, {movp, voxm[[i]]},
					Iterations->300,  BsplineSpacing->40 voxt, InterpolationOrderReg->1, NumberSamples -> 10000, 
					PrintTempDirectory->False, DeleteTempDirectory->False,
					MethodReg->metReg]
			]
		, {i, 1, nStac}];

		(*extract all parameters after registration*)
		movingA = Transpose[movingA, {2, 3, 1, 4, 5}];
	];(*clolse motion moving*)

	debugBids["after dimensions: ", Dimensions@movingA];
	debugBids["after registration: ", Column[Dimensions /@ # & /@ movingA]];

	(*join the moving types*)
	(*-----*)AddToLog[{"Joining the data"}, 4];
	debugBids[movs];
	movsA = Flatten[{movs, ConstantArray[#[[1]], #[[2]]] & /@ Thread[{movsMD, lengMD}]}];
	debugBids[movsA];
	debugBids[nStac];
	movingA = If[nStac===1,
		movingA[[All, 1]],
		debugBids["joining: ", Range[Length[movsA]]];
		JoinSets[movingA[[#]], overT, voxt, MonitorCalc->False, MotionCorrectSets->False, 
			PadOverlap->pad, ReverseSets->reverse, 
			NormalizeSets->MemberQ[nonQuant, movsA[[#]]], NormalizeOverlap->MemberQ[nonQuant, movsA[[#]]]
		]&/@Range[Length[movsA]]
	];

	debugBids["after merging: ", Column[Dimensions /@ movingA]];		

	(*split in single dim and multi dim*)
	If[movingMD =!= {},
		moving = movingA[[1;;leng]];
		movingMD = movingA[[leng+1;;]];
		movingMD = Transpose[movingMD[[#[[1]];;#[[2]]]]] & /@ ({1, 0} + # & /@ Partition[Prepend[Accumulate[lengMD], 0], 2, 1]);
		movingA = Join[moving, movingMD];
	];

	(*export the joined data*)
	(*----*)AddToLog["Exporting the calculated data to:", 4];
	(*----*)AddToLog[outfile, 5];
	movsA = Join[movs, movsMD];
	ExportNii[movingA[[#]], voxt, outfile<>"_"<>movsA[[#]]<>".nii"] &/@ Range[nSet];

	(*make the checkfile*)
	MakeCheckFile[outfile, Sort@Join[{"Check"->"done"}, Normal@datType]];
	(*----*)AddToLog["Finished merging", 3, True];
]


(* ::Subsection:: *)
(*5. MuscleBidsSegment*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsSegment*)


Options[MuscleBidsSegment] = {ProcessSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsSegment] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsSegment[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsSegment[folder, GetConfig[folder], opts];


MuscleBidsSegment[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir},
	debugBids["starting MuscleBidsSegment"]; 
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsSegment[
		config["folders"]["mergeData"],(*the input folder for the data, output is in same folder*)
		config["folders"]["mergeData"],
		config["datasets"],(*what to process*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsSegment[datFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, ops:OptionsPattern[]]:= BidsFolderLoop[datFol, outFol, datDis, Method->"MuscleBidsSegment", ops]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsSegmentI*)


MuscleBidsSegmentI[foli_, folo_, datType_, allType_, verCheck_]:=Block[{
		segment, segType, segTypeLab, checkFile, fol, segLocation, device,
		parts, outfile, segfile, out, vox, seg
	},

	debugBids["Starting MuscleBidsSegmentI"];
	debugBids[foli, folo];
	debugBids[datType];

	(*get the segment data type*)
	segment = datType["Segment"];
	(*figure out if duplicate handeling is needed.*)
	duplicate = KeyExistsQ[datType, "Key"];
	key = If[duplicate, "stk"->stringStrip@datType["Key"], Nothing];

	(*no segmentation specified*)
	If[segment===Missing["KeyAbsent", "Segment"],	
		(*-----*)AddToLog[{"No Segmentations defined for this data"}, 3];
		Return[];
	];

	(*Segmentation specified*)

	(*Get the segmentation targets and its names*)
	segType = segment["Target"];
	segLocation = segment["Location"];
	If[ArrayDepth[segType]===1, segType = {segType}];
	segTypeLab = StringRiffle[#, "_"]&/@segType;

	{fol, parts} = PartitionBidsFolderName[foli];
	checkFile = GenerateBidsFileName[folo, <|parts, key, "type" -> "seg", "suf"->{"auto", datType["Type"]}|>];

	(*Check if segmentation needs to be performed*)
	If[CheckFile[checkFile, "done", verCheck],
		(*-----*)AddToLog[{"Segmentation already done for:", StringJoin@Riffle[segTypeLab,", "]}, 3];
		Return[]
	];

	(*-----*)AddToLog[{"The types that will be segmented are: ", StringJoin@Riffle[segTypeLab,", "]}, 3];

	(*Loop over the segmentation types if more are specified*)
	Table[
		(*-----*)AddToLog[{"Performing segmentation for ", StringRiffle[segi, "_"]}, 3];

		(*get the correct filenames*)
		outfile = GenerateBidsFileName[folo, <|parts, key, "type" -> "seg", "suf" -> Join[{"auto"}, segi]|>]<>".nii";
		segfile = GenerateBidsFileName[fol, <|parts, key, "type" -> First[segi], "suf" -> Rest[segi]|>]<>".nii";

		(*check if target file exists if so perform the segmentation*)
		If[!NiiFileExistQ[segfile],
			AddToLog[{"The segment file does not exist", segfile}, 4];
			,
			{out, vox} = ImportNii[segfile];
			seg = SegmentData[out, segLocation, TargetDevice -> Lookup[segment, "Device", "GPU"], Monitor -> False];
			ExportNii[seg, vox, outfile];
		];
		, {segi, segType}			
	];

	(*make the checkfile*)
	MakeCheckFile[checkFile, Sort@Join[{"Check"->"done"}, Normal@datType]];
	(*----*)AddToLog["Finished the segmentation", 3, True];
]


(* ::Subsection:: *)
(*6. MuscleBidsTractography*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsTractography*)


Options[MuscleBidsTractography] = {ProcessSubjects->All, VersionCheck->False, BidsTractographyMethod->"Full"};

SyntaxInformation[MuscleBidsTractography] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsTractography[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsTractography[folder, GetConfig[folder], opts];


MuscleBidsTractography[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir},
	debugBids["starting MuscleBidsTractography"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsTractography[
		config["folders"]["mergeData"],(*the input folder for the data, output is in same folder*)
		config["folders"]["mergeData"],
		config["datasets"],(*what to process*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsTractography[datFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, ops:OptionsPattern[]]:= BidsFolderLoop[datFol, outFol, datDis, Method->"MuscleBidsTractography", ops]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsTractographyI*)


MuscleBidsTractographyI[foli_, folo_, datType_, allType_, verCheck_, met_]:=Block[{
		tracto, tractType, tractSeg, tractStopLab, tractStopVal, tractStopLabNam, trkFile,
		tractTypeLab, fol, parts, checkFile, outfile, seed, lenS, segBone, tractSegLab,
		datfile, stopfile, tens, vox, dim, stop, ang, step, tracts, seeds, len, seg, curv,
		segfile, muscles, mlabs, mus, bones, con, leng, dens, flip, per, duplicate, key, keyS
	}, 

	debugBids["Starting MuscleBidsTractographyI"];
	debugBids[foli, folo];
	debugBids[datType];

	(*!!options!!*)
	{len, ang, step, seed} = {{15, 500}, 25, 1.5, Scaled[.3]};
	{lenS, segBone} = {{15, 500}, 100};

	(*figure out if duplicate handeling is needed.*)
	duplicate = KeyExistsQ[datType, "Key"];
	key = If[duplicate, "stk"->stringStrip@datType["Key"], Nothing];

	(* Extract tractography data *)
	tracto = datType["Tractography"]; 

	(* Check if tractography is specified *)
	If[tracto===Missing["KeyAbsent", "Tractography"],
		(*-----*)AddToLog[{"No tractography defined for this data"}, 3];
		Return[];
	];

	(* Extract flip and permutation *)
	{flip, per} = Lookup[tracto, "FlipPermute", {{1, -1, 1}, {"z", "y", "x"}}];

	(* Extract tractography target, segmentation and stopping criteria *)
	tractType = tracto["Target"];
	tractSeg = tracto["Segmentation"];
	{tractStopLab, tractStopVal} = Transpose@tracto["Stopping"];

	(* Ensure tractStopLab and tractStopVal are lists *)
	If[ArrayDepth[tractStopLab]===1, tractStopLab = {tractStopLab}];
	If[ArrayDepth[tractStopVal]===1, tractStopVal = {tractStopVal}];

	(* Generate labels for tractStopLab and tractType *)
	tractStopLabNam = StringRiffle[#, "_"]&/@tractStopLab;
	tractTypeLab = StringRiffle[tractType, "_"];
	tractSegLab = StringRiffle[tractSeg, "_"];

	(* Partition the input folder name *)
	{fol, parts} = PartitionBidsFolderName[foli];

	trkFile = GenerateBidsFileName[folo, <|parts, key, "type" -> First[tractType], "suf" -> Join[tractType[[2;;2]], {"trk"}]|>]<># &;
	checkFile = trkFile[""];

	(* If tractography and segmentation is already done, log the event *)
	If[CheckFile[checkFile, "done", verCheck],
		(*----*)AddToLog[{"Tractography and segmentation already done for:", tractTypeLab}, 3];
		Return[]
	];

	(* Check if tractography needs to be performed *)
	Which[
		CheckFile[checkFile, "track", verCheck],
		(* If tractography is already done, log the event *)
		(*----*)AddToLog[{"Tractography already done for:", tractTypeLab}, 3];
		,
		!(met === "Full" || met==="Tractography"),
		(*----*)AddToLog[{"Skipping tractography because of method:", met}, 3];
		,
		True,
		(* If tractography is not done, log the event and proceed with the process *)
		(*----*)AddToLog[{"Starting the whole volume tractography"}, 3, True];
		(*----*)AddToLog[{"The type that will be tracted is: ", tractTypeLab}, 4];

		(* Generate stop and data file names *)
		datfile = GenerateBidsFileName[fol, <|parts, key, "type" -> First[tractType], "suf" -> Rest[tractType]|>]<>".nii";
		stopfile = GenerateBidsFileName[fol, <|parts, key, "type" -> First[#], "suf" -> Rest[#]|>]<>".nii"&/@tractStopLab;

		(* Check if the tensor file and stop files exist *)
		Which[
			!NiiFileExistQ[datfile],
			(*----*)AddToLog[{"The tensor file does not exist", datfile}, 4];
			,
			!And@@(NiiFileExistQ/@stopfile),
			(*----*)AddToLog[{"Not all stop files exist not exist", stopfile}, 4];
			,
			True,
			(* If all files exist, proceed with the tractography process *)

			(*----*)AddToLog[{"Importing the needed data"}, 4];
			{tens, vox} = ImportNii[datfile];
			tens = Transpose@ToPackedArray@N@Chop@tens;
			dim = Rest@Dimensions@tens;

			(* Import stop files *)
			stop = First[ImportNii[#]]&/@stopfile;
			stop = Transpose[{stop, tractStopVal}];

			(*----*)AddToLog[{"Starting the whole volume tractography"}, 4];

			(* Perform tractography *)
			{tracts, seeds} = FiberTractography[tens, vox, stop,
				InterpolationOrder -> 0, StepSize -> step, Method -> "RK4", MaxSeedPoints -> seed, 
				FiberLengthRange -> len, FiberAngle -> ang, TractMonitor -> False,
				TensorFlips -> flip, TensorPermutations -> per, Parallelization -> True
			];

			(* Export the tractography results *)
			(*-----*)AddToLog[{"Exporting the whole volume tractography"}, 4];
			ExportTracts[trkFile[".trk"], tracts, vox, dim, seeds];

			MakeCheckFile[checkFile, Sort@Join[{"Check" -> "track"}, Normal@datType]];
			(*----*)AddToLog["Finished the tractograpy", 3, True];
		];
	];

	(* Check if segmentation needs to be performed *)
	Which[
		CheckFile[checkFile, "seg", verCheck],
		(* If segmentation of tracto is already done, log the event *)
		(*----*)AddToLog[{"Segmentation of tractography already done for:", tractSegLab}, 3];
		,
		!(met === "Full" || met==="Segmentation"),
		(*----*)AddToLog[{"Skipping tractography segmentation because of method:", met}, 3];
		,
		True,
		(* If segmentation of tracto is not done, log the event and proceed with the process *)
		(*----*)AddToLog[{"Starting the tractography segmentation"}, 3, True];
		(*----*)AddToLog[{"The tractography will be segmented using: ", tractSegLab}, 4];

		If[duplicate, keyS = "stk"->stringStrip@First[tractSeg]; tractSeg = Rest[tractSeg];, keyS = Nothing;];
		segfile = GenerateBidsFileName[fol, <|parts, keyS, "type" -> First[tractSeg], "suf" -> Rest[tractSeg]|>]<>".nii";
		debugBids[Column@{trkFile[".trk"], segfile}];

		Which[
			!NiiFileExistQ[segfile],
			(*----*)AddToLog[{"The segmentation file does not exist: ", segfile}, 4];
			,
			!FileExistsQ[trkFile[".trk"]],
			(*----*)AddToLog[{"The tracts file does not exist: ", trkFile[".trk"]}, 4];
			,
			True,

			(*----*)AddToLog[{"Importing the needed data"}, 4];
			(*import trk file if needed, if processing was done in same run this is skipped*)
			If[Dimensions[tracts] === {}, {tracts, vox, dim, seeds} = ImportTracts[trkFile[".trk"]]];
			{seg, vox} = ImportNii[segfile];

			(*----*)AddToLog[{"Analyzing the segmentation"}, 4];
			(*split the segmentations in bones and muscles*)
			{muscles, mlabs} = SplitSegmentations[SelectSegmentations[seg, Range[segBone]]];
			mus = Dilation[Normal@Total@Transpose@muscles, 3];
			bones = Unitize[SelectSegmentations[seg, Range[segBone + 1, segBone + 30]]];

			(*----*)AddToLog[{"Analyzing the tracts"}, 4];
			(*fit and segment the tracts*)
			tracts = SegmentTracts[tracts, muscles, vox, dim, FiberLengthRange -> lenS];
			tracts = FitTracts[tracts, vox, dim, FittingOrder -> 3];

			(*Calculate tract parameters*)
			seed = SeedDensityMap[seeds, vox, dim];
			dens = TractDensityMap[tracts, vox, dim];
			leng = TractLengthMap[tracts, vox, dim];
			ang = TractAngleMap[tracts, vox, dim];
			curv = TractCurvatureMap[tracts, vox, dim];

			(*----*)AddToLog[{"Exporting the results and maps"}, 4];
			(*export stuff*)
			con = Context[con];
			ExportNii[ToExpression[con<>#], vox, trkFile["_"<>#<>".nii.gz"]]& /@ {"dens", "leng", "ang", "seed","curv"};
			ExportTracts[trkFile["_seg.trk"], tracts, vox, dim, seeds];

			(*export plot scene*)
			(*----*)AddToLog[{"Exporting the scene"}, 4];
			Export[trkFile["_plot.wxf"],
				PlotSegmentedTracts[tracts, muscles, bones, dim, vox, OutputForm -> "All", Method -> "tube", MaxTracts -> 10000]
			];

			MakeCheckFile[checkFile, Sort@Join[{"Check"->"seg"}, Normal@datType]];
			(*----*)AddToLog["Finished the tractograpy segmentation", 3, True];
		];
	];

	If[CheckFile[checkFile, "seg", verCheck],
		MakeCheckFile[checkFile, Sort@Join[{"Check"->"done"}, Normal@datType]]
	];
]


(* ::Subsection:: *)
(*7. MuscleBidsAnalysis*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsAnalysis*)


Options[MuscleBidsAnalysis] = {ProcessSubjects->All, VersionCheck->False, BidsOutputImages->"All"};

SyntaxInformation[MuscleBidsAnalysis] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsAnalysis[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsAnalysis[folder, GetConfig[folder], opts];


MuscleBidsAnalysis[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]]:=Block[{dir}, 
	debugBids["starting MuscleBidsAnalysis"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsAnalysis[
		config["folders"]["mergeData"],(*the input folder for the data*)
		config["folders"]["analysis"],(*the output folder for analsys*)
		config["analysis"],(*what to process*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsAnalysis[datFol_?StringQ, anFol_?StringQ, datDis_?AssociationQ, ops:OptionsPattern[]] := Block[{data, name},
	(*loop over all folders*)
	BidsFolderLoop[datFol, anFol, datDis, Method->"MuscleBidsAnalysis", ops];

	(*processing for joining all generated datafiles*)
	data = Join @@ (Import /@ Select[FileNames["*.wxf", anFol, Infinity], 
		First[StringSplit[FileBaseName[#], "_"]] =!= "All" &]);
	name = FileNameJoin[{anFol, "All_"<>DateName[]}];

	(*export to summary data file*)
	Export[name <> ".xlsx", data];
	Export[name <> ".wxf", data];
]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsAnalysisI*)


MuscleBidsAnalysisI[foli_, folo_, datDis_, verCheck_, imOut_] := Block[{
		maskErosion, tractWeighting, anaSeg, fol, parts, segfile, fileName, partsO, fileNameO, checkFileX, checkFileI,
		n, what, seg, vox, vol, musNr, musName, sideName, sideNr, dataLabs, anaType, densLab, str,
		densFile, trType, trMask, segT,	datfile, data, scale, tract, outFile, meanType, hasKey,
		quantIm, segIm, tractIm, imRef, ref, crp, refC, size, pos, sliceData, make3DImage, make2DImage,
		cols, cFun, ran, clip, type, imFile, imDat, voxi, voxs, segPl, imTrk, trkfile, reffile,
		addLabel, img, lab
	},

	debugBids["Starting MuscleBidsAnalysisI"];
	debugBids[{foli, folo}];

	(*Options*)
	maskErosion = True;
	tractWeighting = False;

	(*----------- make the xls files -------------*)

	(*get the segmentation settings*)
	hasKey = KeyExistsQ[datDis, "Key"];
	{fol, parts} = PartitionBidsFolderName[foli];
	partsO = If[hasKey, Join[<|"stk"->stringStrip@datDis["Key"]|>, parts], parts];
	debugBids[{parts, partsO, hasKey}];

	If[hasKey,
		(*----*)AddToLog[{"Multiple analysis - starting:", datDis["Key"]}, 2, True];
	];

	(*file name functions*)
	fileName = If[hasKey,
		GenerateBidsFileName[fol, <|parts, "stk" -> stringStrip@#[[1]], "type" -> stringStrip@#[[2]], "suf" -> #[[3;;]]|>]&,
		GenerateBidsFileName[fol, <|parts, "type" -> First[#], "suf" -> Rest[#]|>]&
	];
	fileNameO = FileNameJoin[{GenerateBidsFolderName[folo, #], GenerateBidsName[#]}]&;

	(*checkfiles image and xls*)
	partsO["suf"] = {"xls"}; 
	checkFileX = fileNameO[partsO];
	partsO["suf"] = {"img"}; 
	checkFileI = fileNameO[partsO];

	anaSeg = datDis["Segmentation", "Type"];
	{n, what} = datDis["Segmentation", "Labels"];
	(*----*)AddToLog[{"Segmentation file used for analysis is:", StringRiffle[stringStrip/@anaSeg, "_"]}, 3];

	(*Perform the segmentation analysis, what are the label names and volumes*)
	debugBids[{"Segmentation to xls analysis", parts}];
	segfile = fileName[anaSeg]<>".nii";

	Which[
		(*segmentation is already done*)
		CheckFile[checkFileX, "done", verCheck],
		(*----*)AddToLog[{"Skipping: the segmentation to xls analysis is already done "}, 4],

		(*no segmentation file exists*)
		!NiiFileExistQ[segfile],
		(*----*)AddToLog[{"The segmentation file does not exist: ", segfile}, 4],

		(*segmentation file existes perform the analysis*)
		True,
		(*----*)AddToLog[{"Importing and processing the needed segmentation"}, 4];
		{seg, vox} = ImportNii[segfile];
		{seg, musNr} = SelectSegmentations[SplitSegmentations[seg], Range[n]];

		(*----*)AddToLog[{"Calculating the volume of the segmentation"}, 4];
		vol = SegmentationVolume[seg, vox];

		(*switch to the correct segmentation label*)
		Switch[what,
			"Legs",
			(*----*)AddToLog[{"Using the Legs for muscle labeling"}, 4];
			musName = MuscleLabelToName[musNr, GetAssetLocation["MusclesLegLabels"]];
			{musName, sideName} = Transpose[(str = StringSplit[#, "_"];
				If[Last[str] == "Left" || Last[str] == "Right",
					{StringRiffle[Most@str, "_"], Last@str},
					{StringRiffle[str, "_"], "Both"}
				]) & /@ musName];
			sideNr = sideName /. Thread[{"Left", "Right", "Both"} -> {1, 2, 3}];
			musNr = MuscleNameToLabel[musName, GetAssetLocation["MusclesLegAllLabels"]];
			,
			_,(*unknown label type*)
			(*----*)AddToLog[{"Unknown Label type: ", what}, 4];
		];

		(*summarize the data labels for export later*)
		dataLabs = Join[
			Thread[{"subject", "subjectID", "session", "sessionID"} -> Transpose@ConstantArray[{
				parts["sub"], ToExpression[Last@StringCases[parts["sub"], NumberString]],
				parts["ses"], ToExpression[Last@StringCases[parts["ses"], NumberString]]}, Length[musNr]
			]],
			{"muscle"->musName, "muscleID"->musNr, "side"->sideName, "sideID"->sideNr, "volume"->vol}
		];

		(*get the labels for analysis, see if and which need to be done using tract based analysis*)
		debugBids["data analysis"];
		(*labels to be analysed*)
		anaType = datDis["Analysis", "Types"];
		anaType = Flatten[Thread /@ anaType, 1];
		(*----*)AddToLog[{"Analsysis will be performed for:", StringRiffle[stringStrip/@#, "_"]&/@anaType}, 3];

		(*Figure out the tract analysis*)
		debugBids["tract mask"];
		If[KeyExistsQ[datDis["Analysis"], "TractBased"],
			densLab = {If[hasKey, stringStrip@datDis["Analysis", "TractBased"][[1,1]], Nothing], "dwi", "dti", "trk","dens"};
			densFile = fileName[densLab]<>".nii";
			trType = Flatten[Thread /@ datDis["Analysis", "TractBased"], 1];
			trType = Select[trType, MemberQ[anaType, #] &];
			(*----*)AddToLog[{"The types with tract weighting will be:", StringRiffle[stringStrip/@#, "_"]&/@trType}, 3];
			(*----*)AddToLog[{"Import tract mask:", StringRiffle[densLab, "_"]}, 4];
			trMask = ImportNii[densFile][[1]];
			trMask = If[tractWeighting, trMask, Unitize@trMask];
			,
			(*----*)AddToLog[{"No tract bases analysis given"}, 4];
			trMask = 1;
		];

		(*perform the actual data analysis *)
		(*----*)AddToLog[{"Starting the data analysis:"}, 3, True];
		debugBids[{"tract mask", Dimensions@seg, Dimensions@trMask}];
		(*make the correcet masks*)
		If[maskErosion,	seg = DilateMask[seg, -1]];
		segT = If[trMask=!=1, MaskSegmentation[seg, trMask], seg];

		(*loop over all datatypes and perform the mask analysis*)
		data = Table[
			datfile = fileName[datType]<>".nii";
			Which[
				(*data does not exist so skip*)
				!NiiFileExistQ[datfile],
				(*----*)AddToLog[{"The data does not exist: ", StringRiffle[datType, "_"]}, 4],

				(*data exists so perform the analysis*)
				True,
				debugBids[datType];
				{data, vox} = ImportNii[datfile];

				(*figure out how to handle this type *)
				tract = MemberQ[trType, datType];
				scale = Switch[datType, {"megre","dix","fatfr"}|{"mese","t2","fatfr"}, 100, {"megre","dix","t2star"}, 1000, _, 1];
				meanType = (datType==={"dwi", "dti", "trk", "seed"} || datType==={"dwi", "dti", "trk", "dens"});
				(*----*)AddToLog[{"Processing file "<>If[tract,"with","without"]<>" tract weighting:", StringRiffle[stringStrip@datType, "_"]}, 4];

				(*mask based analysis*)
				StringRiffle[datType[[-2;;]], "_"]-> scale GetMaskData[data, If[tract, segT, seg], 
					GetMaskOutput->If[meanType, "Mean", "Median"],
					GetMaskOnly -> If[meanType, True, False]
				]
			]
		, {datType, anaType}];

		(*merge the data and export*)
		partsO["suf"] = {};
		outFile = fileNameO[partsO];
		debugBids[{"exporting", outFile}];
		(*----*)AddToLog[{"Data will be exported to:", DirectoryName@outFile}, 3, True];
		data = Dataset[Association /@ Transpose[Thread[#] & /@ Join[dataLabs, data]]];
		Export[outFile<>".xlsx", data];
		Export[outFile<>".wxf", data];

		MakeCheckFile[checkFileX, Sort@Join[{"Check"->"done"}, Normal@datDis]];
	];


	(*----------- make the images -------------*)


	(*figure out which images to make based on setting*)
	{quantIm, segIm, tractIm} = Switch[imOut, 
		"All", {True, True, True},
		"Quantitative", {True, False, False},
		"Segmentation", {False, True, False},
		"Tractography", {False, False, True},
		_, {False, False, False}
	];
	debugBids[{"Image Analysis", {quantIm, segIm, tractIm}}];

	(*make images if needed*)
	Which[
		(*segmentation is already done*)
		CheckFile[checkFileI, "done", verCheck],
		(*----*)AddToLog[{"Skipping: the iamges are already done"}, 4],

		(*No images need to be made*)
		!AnyTrue[{quantIm, segIm, tractIm}, # &],
		(*----*)AddToLog[{"No images will be made since option is set to None:"}, 3],

		(*making the images*)
		True,
		(*----*)AddToLog[{"Starting making the images:"}, 3];

		(*get the reference file and figure out image slice posisions*)
		imRef = datDis["Images", "Reference"];
		(*----*)AddToLog[{"Checking the reference file for 2D images: ", StringRiffle[imRef, "_"]}, 4];
		reffile = fileName[imRef]<>".nii";
		debugBids[{reffile, NiiFileExistQ[reffile]}];

		(*quantIm and SegIm need refffile, check if there to get needed information.*)
		If[!NiiFileExistQ[reffile],
			(*----*)AddToLog[{"No reference file skipping 2D quant and seg images."}, 4]; 
			quantIm = segIm = False;
			,
			(*get the ref data for the slice posisions and background of seg images*)
			{ref, vox} = ImportNii[reffile];
			crp = FindCrop[ref, CropPadding -> 10];
			refC = ApplyCrop[ref, crp];
			size = Dimensions[refC] vox;

			pos = GetSlicePositions[GaussianFilter[refC, 15], vox, MakeCheckPlot -> False, 
				DropSlices -> {1, 1, 1}, PeakNumber -> {0, 1, 2}];
			pos[[1]] = Reverse[Range[0., 1., 1/(Ceiling[Divide @@ size[[;; 2]]] + 1)][[2 ;; -2]] size[[1]]];

			(*Function to extract slice data for 2D images*)
			sliceData = Block[{slDat},
				slDat = GetSliceData[ApplyCrop[#, crp, {vox, voxi}], pos, voxi];
				{slDat[[1]], {slDat[[3, 1]], slDat[[2, 1]], Reverse[slDat[[3, 2]], 2]}, {}}
			] &;
		];

		(*3D image function needed for segmentation and tractography*)
		make3DImage = With[{gc = #, sc = 0.75}, 
			ImageResize[ImagePad[ImageCrop@Image[Graphics3D[Table[
				Translate[Rotate[(First@gc), -i 90 Degree, {0, 0, 1}, 0.5 Options[gc, PlotRange][[1, 2, All, 2]]], 
					{sc i Options[gc, PlotRange][[1, 2, 1, 2]], 0, 0}], 
				{i, 0, 3}], Background -> Lighter@Gray, ViewPoint -> {0, -2, .1}, ##] & @@ Join[{
					BoxRatios -> {sc  4, 1, 1} Options[gc, BoxRatios][[1, 2]], 
					PlotRange -> {sc  4, 1, 1} Options[gc, PlotRange][[1, 2]], 
					Options@gc
					}], ImageSize -> {Automatic, 1200}, ImageResolution -> 300], 
			{{60, 60}, {60, 60}}, Lighter@Gray], {Automatic, 1000}]
		]&;

		(*2D image function*)
		make2DImage = With[{di = Max[ImageDimensions[#][[2]]&/@#[[2]]]/4},
		ImagePad[ImageAssemble[ImageResize[#, {Automatic, di}] & /@ Join[
			{ImageAssemble[Transpose@{ImagePad[#, -5] & /@ #[[1]]}, Spacings -> 20, Background -> White]},
			ImagePad[#, -5] & /@ #[[2]]], Spacings -> 20, Background -> White, 
			ImageResolution -> 300], 20, White
		]]&;

		addLabel = ImageAssemble[{
			{ImageCrop[#2, ImageDimensions[#2] - {0, 20}, {Left, Bottom}]}, 
			{LegendImage[#1, First[ImageDimensions@#2], #3]}}
		]&;

		(*------------ quantiatavite images ------------*)
		If[!quantIm,
			(*----*)AddToLog[{"Not making Quant images since setting is False."}, 4],
			(*----*)AddToLog[{"Start making Quant images:"}, 4]; 

			debugBids["Making quantitative map images:"];
			Table[
				(*get the color and styling function for the image*)
				cols = Rest@im;
				{cFun, ran, lab} = Switch[Length@cols,
					0, {"BlackToWhite", Automatic, None},
					1, {cols[[1]], Automatic, None},
					2, {cols[[1]], cols[[2]], None},
					3, cols];
				clip = If[cFun === "BlackToWhite", Automatic, Black];

				(*get the filenames for import and export*)
				type = First@im;				
				imFile = fileName[type]<>".nii";
				partsO["suf"] = If[hasKey, type[[2;;]], type];

				(*check if the data file exist*)				
				If[!NiiFileExistQ[imFile],
					(*----*)AddToLog[{"Cant make image for because data does not exist: ", StringRiffle[stringStrip/@type, "_"]}, 5],
					(*----*)AddToLog[{"Making image for: ", StringRiffle[type, "_"]}, 5];

					(*import data and make image and export*)
					{imDat, voxi} = ImportNii[imFile];
					img = make2DImage@MakeSliceImages[sliceData@imDat, voxi, 
							ColorFunction -> cFun, PlotRange -> ran, ClippingStyle -> clip, ImageSize -> 1200];
					img = If[lab =!= None, addLabel[cFun, img, lab], img];
					Export[fileNameO[partsO]<>".jpg", img, ImageResolution -> 300];
				]
			, {im, datDis["Images", "QuantImages"]}];
		];

		(*------------ segmentation images ------------*)

		(*check if segmentation can be done*)
		debugBids[{segfile, NiiFileExistQ[segfile]}];
		If[!NiiFileExistQ[segfile], 
			(*----*)AddToLog[{"Segmentation file does not exist."}, 4];
			segIm = False
		];

		If[!segIm,
			(*----*)AddToLog[{"Not making Segment images since setting is False."}, 4],
			(*----*)AddToLog[{"Start making segmentation images:"}, 4]; 
			debugBids["Making segment images:"];

			(*import the segmation*)
			{seg, voxi} = ImportNii[segfile];

			(*make the 2D segmentation image*)
			(*----*)AddToLog[{"Making 2D Segment image"}, 5]; 
			partsO["suf"] = If[hasKey, anaSeg[[2;;4]], anaSeg[[;;3]] ];
			Export[fileNameO[partsO]<>".jpg", 
				make2DImage@MakeSliceImages[sliceData@ref, {sliceData@seg, GetSegmentationLabels[seg]}, vox,
					ColorFunction -> {"BlackToWhite","RomaO"}, PlotRange -> Automatic, ClippingStyle -> Automatic, ImageSize -> 1200]
			, ImageResolution -> 300];

			(*make the 3D segmentation image*)
			(*----*)AddToLog[{"Making 3D Segment image"}, 5];
			partsO["suf"] = Join[partsO["suf"], {"vol"}];
			segPl = PlotSegmentations[SelectSegmentations[seg, Range[n]], SelectSegmentations[seg, Range[n+1,n+30]], 
				voxi, ContourResolution -> 2 voxi];
			Export[fileNameO[partsO]<>".jpg", make3DImage@segPl, ImageResolution -> 300];
		];

		(*------------ tractography images ------------*)

		(*check if tract image can be done*)
		imTrk = datDis["Images", "TractImages"];
		trkfile = fileName[imTrk]<>".wxf";
		debugBids[{trkfile, FileExistsQ[trkfile]}];
		If[!FileExistsQ[trkfile], 
			(*----*)AddToLog[{"Tract file does not exist."}, 4];
			tractIm = False;
		];

		If[!tractIm,
			(*----*)AddToLog[{"Not making Tract images since setting is False."}, 4],
			(*----*)AddToLog[{"Start making tractography images:"}, 4]; 

			(*import the tractography, make the image and export*)
			debugBids["Making tract images:"];
			partsO["suf"] = Join[If[hasKey, imTrk[[2;;4]], imTrk[[;;3]]], {"vol"}];
			Export[fileNameO[partsO]<>".jpg", make3DImage@Import@trkfile, ImageResolution -> 300];
		];

		(*finalize image making*)
		MakeCheckFile[checkFileI, Sort@Join[{"Check"->"done"}, Normal@datDis]];
	]
];


(* ::Section:: *)
(*End Package*)


End[]

EndPackage[]
