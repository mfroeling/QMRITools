(* ::Package:: *)

(* ::Title:: *)
(*QMRITools MuscleBidsTools*)


(* ::Subtitle:: *)
(*Written by: Martijn Froeling, PhD*)
(*m.froeling@gmail.com*)


(* ::Section:: *)
(*Begin Package*)


BeginPackage["QMRITools`MuscleBidsTools`", Join[{"Developer`"}, Complement[QMRITools`$Contexts, {"QMRITools`MuscleBidsTools`"}]]];


(* ::Section:: *)
(*Usage Notes*)


(* ::Subsection::Closed:: *)
(*Functions*)


ImportJSON::usage = 
"ImportJSON[file] imports a JSON file as rawJSON."

GetJSONPosition::usage = 
"GetJSONPosition[{json..}, {{key, value}..}] gets the position from a list of JSON association lists where keys have the given value.
GetJSONPosition[{json..}, {{key, value}..}, sortKey] same but finally sorts the positions for the value of the sortKey."

MergeJSON::usage = 
"MergeJSON[{json..}] merges a list of JSON association lists where duplicate keys with the same values are removed and duplicate keys with different values are merged."


SelectSubjects::usage = 
"SelectSubjects[dir] selects the subjects in the given data directory which has a config file."

ViewConfig::usage = 
"ViewConfig[config] shows a config file for Muscle Bids processing."

ViewProtocolNames::usage = 
"ViewProtocolNames[folder] shows the protocol names in the radData folder specified by the config file with the series number and protocol name from 
the json files in the raw folders for each subject and session."

GetProtocolNames::usage = 
"GetProtocolNames[config, subs] gets the list of protocol names in het specified subject folder."

CheckConfigLabels::usage = 
"CheckConfigLabels[dir, subs] checks for each sub in subs if the protocol names that are defined in the config file in dir are present."


GetConfig::usage = 
"GetConfig[folder] imports a Muscle Bids config file from the given folder."

MergeConfig::usage =
"MergeConfig[assoc, replace] merges the replace association with the assoc association."


PartitionBidsName::usage = 
"PartitionBidsName[name] converts a Bids name to the Bids labels as an association, i.e. {\"sub\",\"ses\",\"stk\",\"rep\",\"type\",\"suf\"}."

PartitionBidsFolderName::usage = 
"PartitionBidsFolderName[fol] partitions the Bids folder and file name. It returns the bids root folder and the label parts using PartitionBidsName."

GenerateBidsName::usage = 
"GenerateBidsName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName."

GenerateBidsFolderName::usage = 
"GenerateBidsFolderName[parts] generates a Bids folder name from the Bids labels association which can be generated by PartitionBidsFolderName."

GenerateBidsFileName::usage = 
"GenerateBidsFileName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName.
GenerateBidsFileName[fol, parts] the same but with a custom root folder."

SelectBidsFolders::usage =
"SelectBidsFolders[fol, tag] selects all folders in the fol with the name tag."

SelectBidsSubjects::usage =
"SelectBidsSubjects[fol] selects all subjects in the bids folder."

SelectBidsSessions::usage =
"SelectBidsSessions[fol] selects all sessions in the bids subject folder."


BidsDcmToNii::usage =
"BidsDcmToNii[dir] converts the bids sourceFolder with dicom files to raw nii files based on the config file."

MuscleBidsConvert::usage =
"MuscleBidsConvert[dir] converts all raw nii data in the to Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsProcess::usage = 
"MuscleBidsProcess[dir] processes all Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsMerge::usage = 
"MuscleBidsMerge[dir] merges multiple stack data for all Muscle-Bids named nii based on the config file in the bids sourceFolder dir."

MuscleBidsSegment::usage = 
"MuscleBidsSegment[dir] segments the data of Muscle-Bids named nii based on the config file in the bids sourceFolder dir. The segmentations are generated by the function SegmentData."

MuscleBidsTractography::usage =
"MuscleBidsTractography[dir] performs tractography on the Muscle-Bids named nii based on the config file in the bids sourceFolder dir. If a segmentation is present it is used as a mask for per muscle segmentation."

MuscleBidsAnalysis::usage = 
"MuscleBidsAnalysis[dir] performs analysis on the Muscle-Bids named nii based on the config file in the bids sourceFolder dir. If a segmentation is present it is used to calculate the mean per segmentation."

CheckDataDescription::usage =
"CheckDataDescription[description] checks the data description config file used in BidsDcmToNii, MuscleBidsConvert, MuscleBidsProcess, and MuscleBidsMerge."


(* ::Subsection::Closed:: *)
(*Options*)


BidsIncludeSession::usage = 
"BidsIncludeSession is an option for BidsDcmToNii. If True session folders will be used in output even if they are not specified."

DeleteAfterConversion::usage = 
"DeleteAfterConversion is an option for MuscleBidsConvert. If set True all files that have been converted will be deleted."

BidsTractographyMethod::usage =
"BidsTractographyMethod is an option for MuscleBidsTractography and can be \"Full\", \"Tractography\" or \"Segmentation\". 
With Tractography only the tractography is performed without segmentation.
With Segmentation only the segmentation is performed without tractography. With Full both are performed."

BidsOutputImages::usage = 
"BidsOutputImages is an option for MuscleBidsAnalysis. If set True the output images are saved in the output folder."

ProcessSubjects::usage = 
"ProcessSubjects is an option for Bids functions. Can be a list of bids subject names else it is All."

VersionCheck::usage = 
"VersionCheck is an option for all Bids functions. If set True data processed with an old version is reprocessed."


(* ::Subsection::Closed:: *)
(*Error Messages*)


CheckDataDescription::key = "Datasets have duplicate names which is not allowed."

CheckDataDescription::type = "Unknown Muscle-BIDS type: `1`, using folder \"miss\"."

CheckDataDescription::class = "Unknown Muscle-BIDS Class: `1`. Must be \"Volume\", \"Stacks\", \"Repetitions\", \"Chunks\", \"Acquisitions\"."

CheckDataDescription::lab = "Invalid combination of Class and Label: `1` with `2` is not allowed."

CheckDataDescription::man = "Mandatory values `1` are not in the data description."

CheckDataDescription::stk = "Class \"stacks\" or \"Chunk\" is used but overlap is not defined, assuming overlap 0."

GetConfig::conf = "Could not find config file in given folder."


(* ::Section:: *)
(*Functions*)


Begin["`Private`"] 


(* ::Subsection:: *)
(*General Definitions*)


(* ::Subsubsection::Closed:: *)
(*Debug and logging*)


debugBids[x___] := If[$debugBids, Print[x]];


dataToLog[data_] := If[KeyExistsQ[data, $Failed], 
    "Wrong data description: " <> data[$Failed], 
    StringRiffle[KeyValueMap[ToString[#1] <> ": " <> ToString[#2] &, 
        KeyDrop[data, {"Process", "Merging", "Segment", "Tractography"}]], "; "]
]


compress = ($OperatingSystem === "Windows");


(* ::Subsubsection::Closed:: *)
(*Bids Definitions*)


bidsTypes = <|
	(*anatomy types*)
	"T1w"->"anat", "T1w-FS"->"anat", "T2w"->"anat", "T2w-FS"->"anat",
	(*dixon*)
	"megre"->"dix", "tse"->"dix",
	(*quant types*)
	"mese"->"quant",
	"T1"->"quant", "T2"->"quant", "wT2"->"quant",
	(*diff types*)
	"dwi"->"dwi",
	(*seg types*)
	"seg"->"seg"
|>;


bidsName = {"sub", "ses", "vol", "stk", "chunk", "rep", "acq" ,"part", "type", "suf"};


bidsClass = {"Volume", "Volumes", "Stacks", "Repetitions", "Chunks", "Acquisitions", "Mixed"};


(* ::Subsubsection::Closed:: *)
(*Helper Functions*)


WipStrip = StringDelete[#, {"WIP ", "WIP_", "wip ", "wip_"}, IgnoreCase -> True] &;


StringStrip = StringDelete[#, {"-", "_", ".", " "}] &;


(* ::Subsubsection::Closed:: *)
(*BidsType*)


BidsType[type_?StringQ] := Lookup[bidsTypes, type, "miss"]

BidsType[parts_?AssociationQ] := Lookup[bidsTypes, parts["type"], "miss"]


(* ::Subsubsection::Closed:: *)
(*BidsValue*)


BidsValue[parts_, val_?ListQ] := Flatten[BidsValue[parts, #] &/@ val]

BidsValue[parts_, val_?StringQ] := Lookup[parts, val, Nothing]


(* ::Subsubsection::Closed:: *)
(*BidsString*)


BidsString[parts_, val_?ListQ] := BidsString[parts, #] &/@ val

BidsString[parts_, val_?StringQ] := Block[{str},
	str = BidsValue[parts, val];
	If[StringQ[str], val<>"-"<>str, str]
]


(* ::Subsubsection::Closed:: *)
(*GetClassName*)


GetClassName[class_, nameIn_] := Switch[class,
	"Volume"|"Volumes"|"Stacks"|"Repetitions"|"Acquisitions"|"Chunks",
	Switch[class, 
		"Volume"|"Volumes", "vol",
		"Stacks", "stk",
		"Chunks", "chunk", 
		"Repetitions", "rep", 
		"Acquisitions", "acq"
	] -> StringStrip[nameIn]
]


(* ::Subsubsection::Closed:: *)
(*SubNameToBids*)


Options[SubNameToBids] = {BidsIncludeSession -> True};

SubNameToBids[nameIn_?ListQ, opts : OptionsPattern[]] := SubNameToBids[#, "", opts] & /@ nameIn

SubNameToBids[nameIn_?ListQ, met_, opts : OptionsPattern[]] := SubNameToBids[#, met, opts] & /@ nameIn

SubNameToBids[nameIn_?StringQ, opts : OptionsPattern[]] := SubNameToBids[nameIn, "", opts]

SubNameToBids[nameIn_?StringQ, met_, OptionsPattern[]] := Block[{ass, keys, name, ses},
	(*get the names*)
	ass = Switch[met, 
		"Sub", PartitionBidsName, 
		"BidsDcmToNii", PartitionBidsName[FileNameTake[#, {2, -1}]]&, 
		_, PartitionBidsFolderName[#][[-1]]&
	]@nameIn;
	keys = Keys[ass];

	(*if bids take sub key else assume first suf is name*)
	name = "sub" -> If[MemberQ[keys, "sub"], ass["sub"], First[ass["suf"]]];

	(*if bids take ses key else assume last suf is session*)
	ses = "ses" -> If[MemberQ[keys, "ses"],
		(*session is present take session*)
		ass["ses"],
		(*more than one suf last is session*)
		If[Length[ass["suf"]] > 1, Last[ass["suf"]],
			(*no session,see if need to be forced*)
			If[OptionValue[BidsIncludeSession], "001", ""]]];
	Association[{name, ses, "suf" -> {}}]
]


(* ::Subsection:: *)
(*BIDS name and select*)


(* ::Subsubsection::Closed:: *)
(*PartitionBidsName*)


SyntaxInformation[PartitionBidsName] = {"ArgumentsPattern" -> {_}};

PartitionBidsName[list:{_?StringQ ..}] := PartitionBidsName/@list

PartitionBidsName[string_?StringQ] := Block[{parts, entity, suffix, suf},
	(*split entities and suffixes*)
	parts = StringSplit[string, "_"];
	entity = StringCases[#, k__ ~~ "-" ~~ v__ :> k -> v] & /@ parts;
	suf = Select[parts, ! StringContainsQ[#, Flatten@Keys@entity] &];

	(*see if type is part of suffixes*)
	suf = Which[
		suf==={}, {"parts"->{}},
		MemberQ[Keys[bidsTypes], First@suf], {"type"->First@suf,"suf"->Rest@suf},
		True, {"suf"->suf}
	];

	(*give as association*)
	Association[Join[entity, suf]]
]


(* ::Subsubsection::Closed:: *)
(*PartitionBidsFolderName*)


SyntaxInformation[PartitionBidsFolderName] = {"ArgumentsPattern" -> {_}};

PartitionBidsFolderName[fol:{_?StringQ ..}] := PartitionBidsFolderName/@fol

PartitionBidsFolderName[fol_?StringQ] := {
	First@StringSplit[fol, "sub-"], 
	PartitionBidsName@StringJoin@Riffle[Select[FileNameSplit[fol],StringContainsQ[#,"-"]&],"_"]
}


(* ::Subsubsection::Closed:: *)
(*GenerateBidsName*)


SyntaxInformation[GenerateBidsName] = {"ArgumentsPattern" -> {_}};

GenerateBidsName[list:{_?AssociationQ ..}] := GenerateBidsName/@list

GenerateBidsName[parts_?AssociationQ] := StringRiffle[Join[
	BidsString[parts, {"sub", "ses", "vol", "stk", "rep", "chunk", "acq", "part"}], 
	BidsValue[parts, {"type", "suf"}]
], "_"]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFolderName*)


SyntaxInformation[GenerateBidsFolderName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFolderName[parts_?AssociationQ]:=GenerateBidsFolderName["", parts]

GenerateBidsFolderName[fol_?StringQ, list:{_?AssociationQ ..}] := GenerateBidsFolderName[fol,#]& /@ list

GenerateBidsFolderName[{fol_?StringQ, parts_?AssociationQ}] := GenerateBidsFolderName[fol, parts]

GenerateBidsFolderName[fol_?StringQ, parts_?AssociationQ] := FileNameJoin[{
	fol, BidsString[parts, "sub"], BidsString[parts, "ses"]
}]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFileName*)


SyntaxInformation[GenerateBidsFileName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFileName[list:{_?AssociationQ ..}] := GenerateBidsFileName["", #]& /@ list

GenerateBidsFileName[fol_?StringQ, list:{_?AssociationQ ..}] := GenerateBidsFileName[fol, #]& /@ list

GenerateBidsFileName[parts_?AssociationQ] := GenerateBidsFileName["", parts]

GenerateBidsFileName[{fol_?StringQ, parts_?AssociationQ}] := GenerateBidsFileName[fol, parts]

GenerateBidsFileName[fol_?StringQ, parts_?AssociationQ] := FileNameJoin[{
	GenerateBidsFolderName[fol, parts], BidsType[parts], GenerateBidsName[parts]
}]


(* ::Subsection:: *)
(*SelectBids*)


(* ::Subsubsection::Closed:: *)
(*SelectBids*)


SelectBids[folder_?ListQ, entity_?StringQ] := Catenate[SelectBids[#, entity]& /@ folder]

SelectBids[folder_?StringQ, entity_?StringQ] := Block[{
		baseName, start, end, what
	},
	baseName = StringStartsQ[FileNameTake[folder], #]&;
	
	start = Which[baseName["ses-"], 3, baseName["sub-"], 2, True, 1];
	end = Switch[entity, "sub", 1, "ses", 2, _, 3];
	what = {"sub-", "ses-", entity}[[start;;end]];

	Select[Catenate[{Fold[FileNames[#2 <> "*", #1, {1}] &, folder, what]}], DirectoryQ]
]


(* ::Subsubsection::Closed:: *)
(*SelectBidsFolders*)


SyntaxInformation[SelectBidsFolders] = {"ArgumentsPattern" -> {_, _}};

SelectBidsFolders[fol_, tag_] := SelectBids[fol, tag]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSubjects*)


SyntaxInformation[SelectBidsSubjects] = {"ArgumentsPattern" -> {_}};

SelectBidsSubjects[fol_] := SelectBids[fol, "sub"]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSessions*)


SyntaxInformation[SelectBidsSessions] = {"ArgumentsPattern" -> {_}};

SelectBidsSessions[fol_] := SelectBids[fol, "ses"]


(* ::Subsection:: *)
(*Config*)


(* ::Subsubsection::Closed:: *)
(*Default config values*)


defaultConfig = <|
	"folders" -> <|
		"dicomData" -> "01_sourcedata", 
		"rawData" -> "02_rawdata", 
		"derivedData" -> "03_derivatives",
		"mergeData" -> "04_merged", 
		"analysis" -> "05_analysis"
	|>,
	"conversion"-> <|
		"Version"->1
	|>,
	"Process" -> <|
		"Masking" -> 5,
		"FlipPermute" -> {{1, 1, 1}, {"x", "y", "z"}},
		"SplitRegistration" -> False,
		"RegistrationDimension" -> "3D",
		"IVIMCorrection" -> True,
		"GradientCorrection" -> False,
		"FasciculationDetection" -> False
	|>,
	"Merging" -> <|
		"Overlap" -> 0,
		"Padding" -> 0,
		"Motion" -> True,
		"Reverse" -> False,
		"SplitRegistration" -> True
	|>,
	"Segment" -> <|
		"Device" -> "GPU",
		"VoxSize" -> Automatic,
		"Dimensions" -> "3D",
		"Method" -> Automatic
	|>,
	"Tractography" -><|
		"FlipPermute" -> {{1, 1, 1}, {"x", "y", "z"}},
		"TractLength"-> {15, 500},
		"TractAngle" -> 25,
		"TractSeed" -> 0.66,
		"TractStep" -> "Automatic",
		"SegmentLength" -> {15, 500},
		"BoneLabel" -> 100,
		"HarmonicDenoise" -> False
	|>,
	"Options" -> <|
		"MaskErosion" -> True,
		"TractWeighting" -> False
	|>
|>;


(* ::Subsubsection::Closed:: *)
(*ConfigLookup*)


ConfigLookup[config_?StringQ, key_?StringQ] := ConfigLookup[GetConfig[config], key]

ConfigLookup[config_?AssociationQ, key_?StringQ] := Lookup[config, key, defaultConfig[key]]

ConfigLookup[config_?StringQ, key_?StringQ, def_?StringQ] := ConfigLookup[GetConfig[config], key, def]

ConfigLookup[config_?AssociationQ, key_?StringQ, def_?StringQ] := Lookup[ConfigLookup[config, key], def, defaultConfig[key, def]];


(* ::Subsubsection::Closed:: *)
(*CheckConfig*)


CheckConfig[inFol_?StringQ, outFol_?StringQ] := Block[{conf, nam, path},
	nam = GenerateBidsName[Last@PartitionBidsFolderName[outFol]];
	path = FileNameJoin[{outFol, nam<>"_config.json"}];
	conf = Quiet@GetConfig[inFol, nam];
	
	debugBids[path];

	If[conf =!= $Failed,
		Export[path, conf];	{True, conf}, 
		{False, <||>}
	]
]


(* ::Subsubsection::Closed:: *)
(*GetConfig*)


GetConfig[folder_?StringQ] := GetConfig[folder, ""]

GetConfig[folder_?StringQ, name_?StringQ] := Block[{file},
	file = SelectFirst[{
		folder,
		FileNameJoin[{folder, "config.json"}],
		FileNameJoin[{folder, name <> "_config.json"}]
    }, FileExistsQ[#] && ! DirectoryQ[#] &];
	If[!MissingQ[file], 
		Import[file, "RawJSON"],
		Message[GetConfig::conf]; $Failed
	]
]


(* ::Subsubsection::Closed:: *)
(*MergeConfig*)


MergeConfig[assoc_?ListQ, replace_?AssociationQ] := Normal@MergeConfig[Association@assoc, replace]

MergeConfig[assoc_?AssociationQ, replace_?ListQ] := MergeConfig[assoc, Association@replace]

MergeConfig[assoc_?AssociationQ, replace_?AssociationQ] := Merge[{assoc, replace}, 
	Replace[{
		(*Both are Association, go deeper*)
		{b_Association, p_Association} :> MergeConfig[b, p],
		(*Overwrite with patch if not both Associations*)
		{_, p_} :> p,
		(*Key exists in only one Association*)
		{v_} :> v 
	}]
]


(* ::Subsubsection::Closed:: *)
(*BuildBidsNameFromConfig*)


BuildBidsNameFromConfig[{fol_, parts_}, datType_] := BuildBidsNameFromConfig[{fol, parts}, datType, ""]

BuildBidsNameFromConfig[{fol_, parts_}, datType_, con_] := Block[{key, movStacks},
	(*Filename for the dataType it self*)
	
	If[con ==="",
		(*If no contrast generate generic output file name*)
		key = If[!datType["HasDuplicate"], Nothing,
			If[datType["Class"] === "Stacks", "stk", "chunk"] -> StringStrip@datType["Key"]];
		GenerateBidsFileName[fol, <|
			parts, key, "type" -> datType["Type"], "suf" -> datType["Suffix"]
		|>],

		(*if contrast specified generate the input file stack*)
		movStacks = StringStrip /@ Flatten[{datType["Label"]}];
		If[datType["Class"] === "Volumes", movStacks = movStacks[[{1}]]];
		(*output the stack file names*)
		GenerateBidsFileName[fol, <|parts, 
			GetClassName[datType["Class"], StringStrip[#]], 
			"type" -> datType["Type"], "suf" -> {datType["Suffix"], con}|>
		] <> ".nii" & /@ movStacks
	]
]


BuildBidsNameFromConfig[{folOut_, parts_}, {datType_, all_}, target_?ListQ] := BuildBidsNameFromConfig[{folOut, "", parts}, {datType, all}, target]

BuildBidsNameFromConfig[{folOut_, folIn_, parts_}, {datType_, all_}, tar_?ListQ] := Block[{
		target, isKey, key, type, suf, datTar, needKey, keyOut, tarType
	},
	(*Filename for remote target specified as list*)
	target = DeleteDuplicates[tar];

	(*see if target description has key and split target*)
	isKey = MemberQ[all[[All, "Key"]], First[target]];
	{key, type} = If[isKey, {First[target], Rest[target]}, {datType["Key"], target}];
	{type, suf} = {First[type], Rest[type]};

	(*make correct output key, quits if key is needed but not present*)
	keyOut = If[!datType["HasDuplicate"], Nothing,
		If[datType["Class"] === "Stacks", "stk", "chunk"] -> StringStrip@key];

	(*If folder in is not specified only the output file is needed*)
	If[folIn === "", Return[GenerateBidsFileName[folOut, 
		<|parts, keyOut, "type" -> type, "suf" -> suf|>]<>".nii"]];

	(*if folIn is defined look for input stack file names*)
	tarType = First@If[isKey,
		Select[all, #["Key"] === key &],
		Select[all, #["InFolder"] === First[suf] &]
	];

	(*output the stack file names*)
	GenerateBidsFileName[folIn, <|parts, 
		GetClassName[tarType["Class"], StringStrip[#]], "type" -> type, "suf" -> suf|>
	] <> ".nii" & /@ Flatten[{tarType["Label"]}]
]


(* ::Subsection:: *)
(*JSON*)


(* ::Subsubsection::Closed:: *)
(*ImportJSON*)


ImportJSON[file_] := Import[file, "RawJSON"]


(* ::Subsubsection::Closed:: *)
(*GetJSONPosition*)


GetJSONPosition[json_, selection_] := GetJSONPosition[json, selection, ""]

GetJSONPosition[json_, selection_, sort_] := Block[{selIndex, selFunc, list, key, val, pos},
	(*selection functions*)
	selIndex = WipStrip[ToLowerCase[Last[Flatten[{#1 /. #3}]]]] === ToLowerCase[#2] &;
	selFunc = (list=#1; key=#2[[1]]; val=#2[[2]]; Select[list, selIndex[key, val, json[[#]]]&])&;

	(*get the file positions*)
	pos = Fold[selFunc, Range[Length[json]], selection];
	(*if sort is empty return the positions or if pos is empty return {}*)
	pos = If[sort===""||pos==={}, pos, pos[[Ordering[sort /. json[[pos]]]]]]
]


(* ::Subsubsection::Closed:: *)
(*MergeJSON*)


MergeJSON[json:{_?AssociationQ..}] := Block[{keys},
	keys = DeleteDuplicates[Flatten[Keys /@ json]];
	Association[If[#[[2]]==={}, Nothing, #]& /@ Thread[
		keys->(If[Length[#]===1,First@#,#]& /@ ((DeleteDuplicates /@ Transpose[(# /@ keys)& /@ json]) /. Missing[___]->Nothing))
	]]
]


(* ::Subsection:: *)
(*Bids Support Functions*)


(* ::Subsubsection::Closed:: *)
(*ViewConfig*)


SyntaxInformation[ViewConfig] = {"ArgumentsPattern" -> {_}};

ViewConfig["default"] := ViewConfig[defaultConfig]

ViewConfig[folder_?StringQ] := ViewConfig[Join[GetConfig[folder], <|"default"->defaultConfig|>]]

ViewConfig[config_?AssociationQ] := If[Length[config]>10, MenuView, TabView][# -> Which[
	# === "datasets"||# === "default", ViewConfig[config[#]],
	# === "analysis", If[KeyExistsQ[config["analysis"], "Analysis"], MakeTable[config[#]], ViewConfig[config[#]]], 
	True, MakeTable[config[#]]
]& /@ Keys[config], ControlPlacement -> Left]


MakeTable[association_] := Block[{key, value, bCol},
	bCol = LightDarkV[White, Darker@Gray];
	Grid[KeyValueMap[{
		Style[key = #1,Bold], 
		value = #2;
		Which[
			AssociationQ[value], MakeTable[value],
			ListQ[value] && Length[value] > 0, Which[
				AssociationQ[First[value]], Column[MakeTable /@ value],
				MatchQ[value, {__String}] && Length[value] > 6, Column[Row[#, ", "]&/@Partition[value, 6, 6, 1,{}]],
				VectorQ[value], Row[value, ", "], 
				key==="QuantImages", TabView[#[[1]] -> MakeTable[Association[#[[2]]]] & /@ ProcessImage[value], ControlPlacement -> Left],
				True, Column@value
			], 
			True, value
		]
	} &, association], 
	Frame -> All, Alignment -> Left, Background -> {{Gray, {bCol}}, bCol}, Spacings -> {1, 0.5}]
]


ProcessImage[an_] := Normal[GroupBy[an, Most[#[[1]]] &, <|#[[1, -1]] -> <|
	"Color map [Range]" -> StringRiffle@Flatten@{If[Length[#] >= 2, #[[2]], "Automatic"], "[", If[Length[#] >= 3, #[[3]], "Automatic"], "]"},
	"Label" -> StringRiffle@Flatten@If[Length[#] >= 4, {#[[4, 1]], "  ",#[[4, -1]], "  ", #[[4, 2]]}, {"Automatic"}]|>
|> & /@ # &]]


(* ::Subsubsection::Closed:: *)
(*ViewProtocolNames*)


Options[ViewProtocolNames] = {
	ProcessSubjects->All
}

SyntaxInformation[ViewProtocolNames] = {"ArgumentsPattern" -> {_, OptionsPattern[]}};

ViewProtocolNames[folder_?StringQ, opts:OptionsPattern[]] := ViewProtocolNames[GetConfig[folder], opts]

ViewProtocolNames[config_?AssociationQ, OptionsPattern[]] := Block[{
		subs, dataFols, fold, list, duplicates, json
	},

	subs = OptionValue[ProcessSubjects];
	dataFols = SelectBids[ConfigLookup[config, "folders", "rawData"], "ses"];

	subs = If[subs===All||subs==="All", dataFols, 
		Select[dataFols, MemberQ[SubNameToBids[subs, "Sub"], SubNameToBids[#]]&]
	];

	MenuView[(
		list = GetProtocolNames[fold = #];
		duplicates = Keys[Select[Counts[list[[All, 2]]], # > 1 &]];
		list = If[MemberQ[duplicates, #[[2]]], {#[[1]], Style[#[[2]], Bold, Red]}, #] & /@ list;
		(*make output*)
		fold -> Grid[list, Alignment -> Left, Frame -> All, Spacings -> {1, 1.2}]
	) & /@ subs, ControlPlacement -> Top]
]


(* ::Subsubsection::Closed:: *)
(*GetProtocolNames*)


GetProtocolNames[fold_?ListQ] := GetProtocolNames /@ fold

GetProtocolNames[fold_?StringQ] := Block[{list, json, name},
	list = Sort@DeleteDuplicates[(
		Quiet[json = ImportJSON[#]];
		{
			json["SeriesNumber"], 
			name = json["ProtocolName"]; 
			If[StringQ[name], StringTrim[WipStrip@name], name]
		}
	) & /@ FileNames["*.json", fold, 2]]; 
	
	Select[list, 
		Head[#[[1]]] =!= Missing && Head[#[[1]]] =!= $Failed && 
		!StringContainsQ[#[[2]], RegularExpression["_\\d{6}\\.\\d{3}"]] &
	]
]


GetProtocolNames[dir_, sub_] := Block[{config, dataFols, subs},
	config = If[AssociationQ[dir], dir, GetConfig[dir]];
	dataFols = SelectBids[ConfigLookup[config, "folders", "rawData"], "ses"];
	subs = If[sub === All || sub === "All",	dataFols,
		Select[dataFols, MemberQ[SubNameToBids[Flatten[{sub}], "Sub"], SubNameToBids[#]] &]];
	GetProtocolNames[subs][[If[StringQ[sub], 1, All]]]
]


(* ::Subsubsection::Closed:: *)
(*SelectSubjects*)


SyntaxInformation[SelectSubjects] = {"ArgumentsPattern" -> {_}};

SelectSubjects[dir_?StringQ] := DynamicModule[{fol, selectedSubjects, list},
	fol = FileNameJoin[{dir, ConfigLookup[dir, "folders", "dicomData"]}];
	list = Sort[FileBaseName/@ Select[FileNames["*", fol], DirectoryQ]];
	selectedSubjects = {};
	Column[{
		CheckboxBar[Dynamic[selectedSubjects], list, Appearance -> "Vertical" -> {Min[{15, Length@list}], Automatic}, Method -> "Active"],
		Row[{
			Button["Select All", selectedSubjects = list],
			Button["Deselect All", selectedSubjects = {}],
			Button["Copy selected list to clipboard", CopyToClipboard[selectedSubjects]]
		}]
	}]
];


(* ::Subsubsection::Closed:: *)
(*CheckConfigLabels*)


CheckConfigLabels[dir_, All] := Block[{fol},
	fol = FileNameJoin[{dir, ConfigLookup[dir, "folders", "dicomData"]}];
	CheckConfigLabels[dir, Sort[FileBaseName/@ Select[FileNames["*", fol], DirectoryQ]]] 
]

CheckConfigLabels[dir_, sub_?ListQ] := Column[CheckConfigLabels[dir, #] & /@ sub]


CheckConfigLabels[dir_, sub_?StringQ] := Block[{names, config, labels, custom, lab},
	names = GetProtocolNames[dir, sub][[All, 2]];
	config = GetConfig[dir];
	custom = Quiet@GetConfig[FileNameJoin[{dir, ConfigLookup[dir, "folders", "dicomData"], sub}]];
	config = If[custom =!= $Failed, MergeConfig[config["datasets"], custom], config["datasets"]];
	labels = Flatten[#["Label"] & /@ Values[config]];
	sub -> Select[labels, ! MemberQ[names, #] &]
]


(* ::Subsubsection::Closed:: *)
(*CheckDataDescription*)


SyntaxInformation[CheckDataDescription] = {"ArgumentsPattern" -> {_, _}};

CheckDataDescription[disIn_Association, met_] := Block[{
		dis, val, vals, keys, duplicate, disOut
	},

	(*all data names should be unique*)
	If[!DuplicateFreeQ[Keys[disIn]],
		(*datasets cannot have duplicate names*)
		Return[Message[CheckDataDescription::key]; $Failed]
		,
		dis = If[met === "MuscleBidsAnalysis",
        	(* If nested like, grab all sub-keys; if flat, use the block directly *)
			If[KeyExistsQ[disIn, "Analysis"], {disIn}, disIn], 
			disIn
		];
		keys = Keys[dis];
		vals = Values[dis];
		(*check if there are duplicated datasets, i.e. same type and suffix*)
		duplicate = !DuplicateFreeQ[{#["Type"], #["Suffix"]} & /@ vals];
		debugBids["data Descriptions duplicates: ", duplicate];

		(*Add the data key and if it has duplicates*)
		disOut = MapThread[Join[#1, <|"Key" -> StringStrip[#2], "HasDuplicate" -> duplicate|>] &
			, {vals, keys}];

		Flatten[CheckDataDescription[Normal[#], met]& /@ disOut]
	]
]

CheckDataDescription[dis:{_Rule..}, met_] := Block[{
		manLab, ass, key, man, cls, typ, fail
	},

	(*Get the data Description keys*)
	ass = Association[dis];
	key = Keys[ass];
	(*fail output*)
	fail = Association[$Failed->ToString[Normal[ass]]];

	manLab = Switch[met,
		"MuscleBidsConvert", {"Label", "Type"},
		"MuscleBidsProcess", {"Type"},
		"MuscleBidsMerge", {"Type", "Merging"},
		"MuscleBidsSegment", {"Type"},
		"MuscleBidsTractography", {"Type"}
	];

	(*Check if mandatory keys are present*)
	man = ContainsAll[key, manLab];

	If[!man,
		Return[Message[CheckDataDescription::man, manLab]; fail],

		(*Check if type is valid*)
		If[!MemberQ[Keys[bidsTypes], ass["Type"]], Message[CheckDataDescription::type, ass["Type"]]];

		(*Check if class is present*)
		If[KeyExistsQ[ass, "Class"],
			(*if present add check class is valid*)
			If[!MemberQ[bidsClass, ass["Class"]], Return[Message[CheckDataDescription::class,ass["Class"]]; fail]],
			(*add class if not present*)
			ass = Association[ass, "Class"->"Volume"]
		];

		(*check if labels match class*)
		cls = Switch[ass["Class"],
			"Volume", StringQ[ass[["Label"]]],
			"Stacks"|"Volumes"|"Repetitions"|"Acquisitions"|"Mixed", ListQ[ass["Label"] && Length[ass]>1]
		];
		If[!cls, Return[Message[CheckDataDescription::lab, ass["Class"], ass["Label"]]; fail]];

		(*check suffix, in and out folder*)
		If[!KeyExistsQ[ass, "Suffix"], ass = Association[ass, "Suffix"->""]];
		Switch[met,
			"MuscleBidsConvert",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->"raw"]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];
			,
			"MuscleBidsProcess"|"MuscleBidsMerge"|"MuscleBidsSegment"|"MuscleBidsTractography",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->BidsType[ass["Type"]]]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];			
		];

		(*output the completed data Description*)
		{KeySort@ass}
	]
]


(* ::Subsection::Closed:: *)
(*0. BidsFolderLoop*)


Options[BidsFolderLoop] = {
	(*loop method*)
	Method->"MuscleBidsConvert", 
	(*general options*)
	ProcessSubjects->All, 
	VersionCheck->False, 
	(*method specific options*)	
	DeleteAfterConversion->True, 
	BidsTractographyMethod->"Full",
	BidsOutputImages->"All"
};

SyntaxInformation[BidsFolderLoop] = {"ArgumentsPattern" -> {_, _, OptionsPattern[]}};

BidsFolderLoop[inFol_?StringQ, outFol_?StringQ, opts:OptionsPattern[]] := BidsFolderLoop[inFol, outFol, {""}, opts]

BidsFolderLoop[inFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]] := BidsFolderLoop[inFol, inFol, datDis, opts]

BidsFolderLoop[inFol_?StringQ, outFol_?StringQ, datDisIn_?AssociationQ, OptionsPattern[]] := Block[{
		met, datType, fols, subs, logFile, ass, nam, filesSl, jsons, versCheck, delete, tractMet,
		files, nTyp, pat, inFols, custConf, out, datDis, imOut
	},

	{met, subs, versCheck, delete, tractMet, imOut} = OptionValue[{
		Method, ProcessSubjects, VersionCheck, DeleteAfterConversion, BidsTractographyMethod, BidsOutputImages}];

	debugBids["Enter BidsFolderLoop for method: "<>met];
	debugBids[inFol];

	(*select the subjects and folders to be processed*)
	fols =Switch[met,
		"BidsDcmToNii", ResetLog[]; Select[FileNames[All, inFol], DirectoryQ],
		_, SelectBids[inFol, "ses"]
	];

	subs = If[subs===All||subs==="All", fols, 
		Select[fols, MemberQ[SubNameToBids[subs, "Sub"], SubNameToBids[#, met]]&]
	];

	debugBids[Column@subs];

	(*loop over the subjects*)
	Table[
		debugBids["input folder:", fol];

		(* -------------- Config and naming --------------*)

		(*get the BidsName*)
		ass = SubNameToBids[fol, met];
		nam = GenerateBidsName[ass];
		out = GenerateBidsFolderName[outFol, ass];

		debugBids["output folder:", out];

		(*check for custom config - merge if config exists in input folder and copy it to output folder*)
		debugBids[datDisIn];
		(* Load config: use local/subject config for all but Analysis *)
		{custConf, datDis} = If[met === "MuscleBidsAnalysis", 
			{False, datDisIn}, 
			CheckConfig[fol, out]
		];
		debugBids[{custConf, datDis}];

		(* Merge global/local and inject Keys/Duplicate logic*)
		datDis = CheckDataDescription[
			If[met === "MuscleBidsAnalysis", datDis, MergeConfig[datDisIn, datDis]], 
			met
		];

		(*-------------- Logging --------------*)
		debugBids[{"starting logging: ", met}];
		SetLogFile@Switch[met,
			"BidsDcmToNii", FileNameJoin[{outFol, "DcmToNii_"<>DateName[]<>".log"}],
			"MuscleBidsConvert", FileNameJoin[{fol, nam<>"_BIDSConvert.log"}],
			"MuscleBidsProcess", FileNameJoin[{out, nam<>"_BIDSProcess.log"}],
			"MuscleBidsMerge", FileNameJoin[{out, nam<>"_BIDSMerge.log"}],
			"MuscleBidsSegment", FileNameJoin[{out, nam<>"_BIDSSegment.log"}],
			"MuscleBidsTractography", FileNameJoin[{out, nam<>"_BIDSTractography.log"}],
			"MuscleBidsAnalysis", FileNameJoin[{out, nam<>"_BIDSAnalysis.log"}]
		];
		If[met=!= "BidsDcmToNii", ImportLog[]]; 
		ShowLog[];
		
		(*-----*)AddToLog[{"Starting "<>met<>" for directory: ", fol}, True, 0];
		(*-----*)If[custConf, AddToLog["********** ----- Using custom config ----- **********", 0]];
		If[met === "BidsDcmToNii",
			(*-----*)AddToLog["Using Chris Rorden's dcm2niix.exe (https://github.com/rordenlab/dcm2niix)", 1];
		];

		(* -------------- The actual processing loops -------------- *)
		debugBids[{"starting method: ", met}];
		Switch[met,
			"BidsDcmToNii", BidsDcmToNiiI[fol, out, datDisIn],
			"MuscleBidsAnalysis", MuscleBidsAnalysisI[fol, outFol, #, versCheck, imOut]&/@datDis
			,
			_,
			(*loop over the data Descriptions*)
			Table[
				(*check if datDis is valid*)
				If[KeyExistsQ[type, $Failed],
					(*-----*)AddToLog[dataToLog@type, 2, True];
					(*-----*)AddToLog["Skipping", 3],
					(*if valid perform conversion*)
					(*-----*)AddToLog[dataToLog@type, 2, True];
					inFols = SelectBids[fol, type["InFolder"]];
					(*method specific scripts: loop over all folders in subject/session folder*)
					Table[
						(*loop needs feedback to show where bugs are.*)
						Echo[DateString[], folIn<>" - "<>type["Key"]<>":"];
						Switch[met,
							"MuscleBidsConvert", MuscleBidsConvertI[folIn, type, delete],
							"MuscleBidsProcess", MuscleBidsProcessI[{folIn, outFol}, type, versCheck],
							"MuscleBidsMerge", MuscleBidsMergeI[{folIn, outFol}, {type, datDis}, versCheck],
							"MuscleBidsSegment", MuscleBidsSegmentI[{folIn, outFol}, {type, datDis}, versCheck],
							"MuscleBidsTractography", MuscleBidsTractographyI[{folIn, outFol}, {type, datDis}, versCheck, tractMet]
						];(*close method switch*)
					, {folIn, inFols}];(*Close sub folders loop*)		
				];(*close type check*)
			, {type, datDis}];(*close datatype loop*)
		]; (*close method switch*)

		(*clear log filename*)
		SetLogFile[];

	, {fol, subs}];(*close subject/ses folder loop*)
]


(* ::Subsection:: *)
(*1. BidsDcmToNii*)


(* ::Subsubsection::Closed:: *)
(*BidsDcmToNii*)


Options[BidsDcmToNii]={BidsIncludeSession->True, ProcessSubjects->All}

SyntaxInformation[BidsDcmToNii] = {"ArgumentsPattern" -> {_, _., OptionsPattern[]}};

BidsDcmToNii[folder_?StringQ, opts:OptionsPattern[]] := BidsDcmToNii[folder, GetConfig[folder], opts];


BidsDcmToNii[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir},
	debugBids["starting BidsDcmToNii"];
	dir = Directory[]; SetDirectory[folder];
	BidsDcmToNii[
		ConfigLookup[config, "folders", "dicomData"],(*the input folder of the dcm data*)
		ConfigLookup[config, "folders", "rawData"],(*the output folder for conversion*)
		ConfigLookup[config, "conversion"],(*the conversion settings*)
		opts];
	SetDirectory[dir];
]


BidsDcmToNii[inFol_?StringQ, outFol_?StringQ, settings_, opts:OptionsPattern[]] := BidsFolderLoop[inFol, outFol, settings, Method->"BidsDcmToNii", opts]


(* ::Subsubsection::Closed:: *)
(*BidsDcmToNiiI*)


BidsDcmToNiiI[fol_, outI_, settings_] := Block[{out},
	(*define the out folder*)
	out = FileNameJoin[{outI, "raw"}];
	(*-----*)AddToLog[{"Output folder: ", out}, 1];
	Quiet[CreateDirectory[out]];

	(*perform the conversions only when output folder is empty*)
	If[EmptyDirectoryQ[out],
		(*perform conversion*)			
		(*-----*)AddToLog["Starting the conversion", 1, True];
		DcmToNii[FileNameJoin[{Directory[],#}]&/@{fol,out}, 
			MonitorCalc->False, UseVersion->settings["Version"]];
		(*-----*)AddToLog["Folder was converted", 1],
		(*-----*)AddToLog["Folder was skipped since output folder already exists", 1];
	];
]


(* ::Subsection:: *)
(*2. MuscleBidsConvert*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsConvert*)


Options[MuscleBidsConvert] = {DeleteAfterConversion->True, ProcessSubjects->All};

SyntaxInformation[MuscleBidsConvert] = {"ArgumentsPattern" -> {_, _., OptionsPattern[]}};

MuscleBidsConvert[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsConvert[folder, GetConfig[folder], opts];


MuscleBidsConvert[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir},
	debugBids["starting MuscleBidsConvert"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsConvert[
		ConfigLookup[config, "folders", "rawData"],(*the input and output folder for the data*)
		ConfigLookup[config, "folders", "rawData"],
		config["datasets"],(*what data for conversion*)
		opts];
	SetDirectory[dir];
]


MuscleBidsConvert[niiFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]] := BidsFolderLoop[niiFol, outFol, datDis, Method->"MuscleBidsConvert", opts]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsConvertI*)


MuscleBidsConvertI[folIn_, datType_, del_] := Block[{
		type, fol, parts, files, json, infoExtra, pos, posIn, info, data, vox, 
		grad, val, suffix, outFile, echo, nEch, fit, labels, class, types,
		vx, vy, vz, dx, dy, dz, sx, sy, sz, off, dfile, hasb, hdr, nSl, len,
		labs, noFiles
	},

	debugBids["Starting MuscleBidsConvertI"];
	debugBids[folIn];

	(*see if one label or session|repetition*)
	{fol, parts} = PartitionBidsFolderName[folIn];

	(*user defined data description*)
	labels = Flatten[{datType["Label"]}];
	type = datType["Type"];
	class = datType["Class"];
	
	(*for joining dti data*)
	labels = If[class === "Volumes", {labels}, labels];

	(*-----*)AddToLog[{"Converting", ToString[Length[labels]], class}, 2, True];
	(*-----*)AddToLog[StringJoin@@Riffle[labels,", "], 3];

	(*loop over stack names*)
	Table[
		(*import the json belonging to name*)
		(*-----*)AddToLog[{"Converting", nameIn, "as", type,":"}, True, 3];
		files = Flatten@If[class === "Volumes",
			FileNames["*"<>StringReplace[#," "->"_"]<>"*.json", folIn]& /@ nameIn,
			FileNames["*"<>StringReplace[nameIn," "->"_"]<>"*.json", folIn]
		];

		(*add settings to output json*)
		infoExtra = <|
			"ConversionSoftware"->"QMRITools.com", 
			"ConversionSoftwareVersion"->QMRITools`$InstalledVersion,
			If[class==="Volume", "Volume"->nameIn, Nothing],
			If[class==="Volumes", "Volumes"->nameIn, Nothing],
			If[class==="Repetitions", "Repetition"->nameIn, Nothing],
			If[class ==="Acquisitions", "Acquisition"->nameIn, Nothing],
			If[class==="Stacks" || class==="Chunks" || class==="Mixed", "Stack"->nameIn, Nothing],
			If[class==="Stacks" || class==="Chunks" || class==="Mixed", "OverLap"->datType["Overlap"], Nothing]
		|>;

		(*check if there are files to do something with*)
		If[Length@Flatten[files]===0,
			(*no json files found*)
			debugBids["!!!!!!!!! No json files found !!!!!!!!!!"];
			(*-----*)AddToLog[{"No json files found with label ", nameIn , " skipping conversion"}, 4],

			(*if json files found import them*)
			debugBids[files];
			json = ImportJSON/@files;

			(*see which data type is expected*)
			debugBids["Converting ",datType["Type"], " as ", datType["Process", "Method"]];
			Switch[datType["Type"],

				(*-------------------------------------------------*)
				(*-------- DIXON conversion script megre ----------*)
				(*-------------------------------------------------*)
				"megre"|"tse",

				Switch[datType["Process", "Method"],
					"Dixon-P",
					(*philips data with online recon*)
					suffix = datType["Process", "Types"];
					debugBids[suffix];

					If[ListQ[suffix]&&!MatrixQ[suffix],
						(*data is a 4D dataset and the order is in types*)

						pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}];
						debugBids["Converting Dix data, json position: ", pos];

						If[pos=!={},
							pos = CheckPos[pos];
							
							(*get the json and data*)
							(*-----*)AddToLog[{"Importing dataset with properties: ", nameIn}, 4];
							info = json[[pos]];
							{data, vox} = ImportNii[ConvertExtension[files[[pos]],".nii"], NiiScaling->False];
							(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

							(*loop over types and export them*)
							Table[(*export to the correct folder*)
								outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], 
									"suf"->Flatten@{datType["Suffix"], suffix[[i]]}|>];
								(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
								ExportNii[data[[All, i]], vox, ConvertExtension[outFile, ".nii"], CompressNii -> compress];
								Export[ConvertExtension[outFile, ".json"], MergeJSON[{info, infoExtra}]];
							,{i, 1, Length[suffix]}];

							(*export used files*)
							DelFiles[files[[posIn]], del];
						];
					];

					If[ListQ[suffix]&&MatrixQ[suffix],
						(*data is multiple files and the order and extension is in types*)
						{suffix, types} = Transpose[suffix];
						
						pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}];
						debugBids["Converting Dix data, json position: ", pos];
						(*get the json and data*)
						(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", nameIn}, 4];

						labs = Last[StringSplit[FileBaseName[#], "_"]] & /@files;
						debugBids["File labels: ", labs];

						(*loop over types and export them*)
						Table[(*export to the correct folder*)
							pos = Flatten[Position[labs, types[[i]]]];

							If[pos=!={},
								pos = CheckPos[pos];
								outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], 
									"suf"->Flatten@{datType["Suffix"], suffix[[i]]}|>];
								(*-----*)AddToLog[{"Importing:", files[[pos]]}, 4];
								info = json[[pos]];
								{data, vox} = ImportNii[ConvertExtension[files[[pos]],".nii"], NiiScaling->False];
								(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
								ExportNii[data, vox, ConvertExtension[outFile, ".nii"], CompressNii -> compress];
								Export[ConvertExtension[outFile, ".json"], MergeJSON[{info, infoExtra}]];
								(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
							]
						, {i, 1, Length[suffix]}];

						(*export used files*)
						DelFiles[files[[posIn]], del];
					];

					,
					"Dixon-S",
					(*siemens data with online recon*)

					{suffix, types} = Transpose@datType["Process", "Types"];

					Table[
						pos = posIn = GetJSONPosition[json, {{"SeriesDescription", nameIn<>"_"<>types[[i]]}}];
						If[pos=!={},
							debugBids[{"Dixon-S", nameIn<>"_"<>types[[i]], pos}];
							(*-----*)AddToLog[{"Importing dataset with properties: ", {nameIn, i}}, 4];
							(*get the json and data*)
							pos = CheckPos[pos];
							info = json[[pos]];
							{data, vox} = ImportNii[ConvertExtension[files[[pos]],".nii"], NiiScaling->False];

							(*export to the correct folder*)
							outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], 
								"suf"->Flatten@{datType["Suffix"], suffix[[i]]}|>];
							debugBids[{outFile, GetClassName[class, nameIn]}];
							(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
							ExportNii[data, vox, ConvertExtension[outFile, ".nii"], CompressNii -> compress];
							Export[ConvertExtension[outFile, ".json"], MergeJSON[{info, infoExtra}]];
							
							(*export used files*)
							DelFiles[files[[posIn]], del];
						]
					, {i, Length@types}];

					,
					"Dixon-B",

					(*non default with data with 4D nii, where data correction is needed*)
					pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}];
					debugBids["Converting Dix data, json position: ", pos];
					(*get the json and data*)
					(*-----*)AddToLog[{"Importing dataset with properties: ", nameIn}, 4];

					(*get the json and data*)
					pos = CheckPos[pos];
					info = json[[pos]];
					{data, vox} = ImportNii[ConvertExtension[files[[pos]],".nii"], NiiScaling->False];
					(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

					(*assuming data has source and echos figure out the echos and slices*)
					{nSl, nEch} = Dimensions[data][[1 ;; 2]];
					nEch = (nEch - 5)/4;
					(*-----*)AddToLog[{"Slices:", nSl, "; Echos:", nEch}, 4];

					(*extract and convert the relevant data*)
					data = Partition[#, nEch] & /@ Partition[Flatten[Transpose[data], 1][[;; 4 (nSl*nEch)]], nSl nEch];
					(*mag, real, imag, phase*)
					data = {1000. data[[1]]/2047., 1000. (data[[2]] - 2047.)/2047., 1000. (data[[3]] - 2047.)/2047., Pi (data[[4]] - 2047.)/2047.};

					echo = datType["Process", "EchoTime"];
					infoExtra = Join[infoExtra, <|
						"EchoNumber" -> Range[nEch], 
						"EchoTime" -> (echo[[1]] + Range[0, nEch - 1] echo[[2]])/1000.,
						"ForthDimension"->"EchoTime",
						"DataClass"->class
					|>];

					Table[
						{i, suffix} = Switch[dixType, "Mixed", {1, ""}, "Phase", {4, "ph"}, "Real", {2, "real"}, "Imaginary", {3, "imag"}];
						(*export to the correct folder*)
						outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], 
							"suf"->Flatten@{datType["Suffix"], suffix}|>];
						(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
						ExportNii[data[[i]], vox, ConvertExtension[outFile, ".nii"], CompressNii -> compress];
						Export[ConvertExtension[outFile, ".json"], MergeJSON[{info, infoExtra}]];

					, {dixType, {"Mixed", "Phase", "Real", "Imaginary"}}];

					(*Delete used files*)
					DelFiles[files[[posIn]], del];
					,
					"Dixon",
					(*default script with bids standard of each echo in one file*)
					(*get the position of the files needed*)
					(*loop over dixon data types*)
					Table[
						(*get the position of the files needed*)
						pos = GetJSONPosition[json, {{"ProtocolName", nameIn}, {"ImageType", dixType}}, "EchoNumber"];

						(*-----*)AddToLog[{"Importing", Length[pos], "datasets with properties: ", {nameIn, dixType}}, 4];
						debugBids["Converting Dix data of type ", dixType, ", json position: ", pos];
						
						If[pos==={},
							(*-----*)AddToLog[{"No json files found with label ", nameIn , " and type ", dixType, " skipping conversion"}, 4],
							(*if json files found import them*)
							info = MergeJSON[json[[pos]]];
							{data, vox} = Transpose[ImportNii[#]&/@ConvertExtension[files[[pos]], ".nii"]];
							data = Transpose[data];
							vox = First@vox;
							(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

							(*correct data for different types*)
							{data, suffix} = Switch[dixType,
								"Mixed", {1000.data/2047.,""},
								"Phase", {Pi (data-2047.)/2047,"ph"},
								"Real", {1000.(data-2047.)/2047.,"real"},
								"Imaginary", {1000.(data-2047.)/2047.,"imag"}
							];

							(*make the additional mandatory bids json values*)
							infoExtra = Join[infoExtra, <|
								"ForthDimension"->"EchoTime",
								"DataClass"->class
							|>];

							(*export to the correct folder*)
							outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], 
								"suf"->Flatten@{datType["Suffix"], suffix}|>];
							(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
							ExportNii[data, vox, ConvertExtension[outFile, ".nii"], CompressNii -> compress];
							Export[ConvertExtension[outFile, ".json"], MergeJSON[{info, infoExtra}]];

							(*Delete used files*)
							DelFiles[files[[pos]], del];
						]
					(*Close loop over dixon data types*)
					, {dixType, {"Mixed", "Phase", "Real", "Imaginary"}}]
				],

				(*-------------------------------------------*)
				(*---------- DWI conversion script ----------*)
				(*-------------------------------------------*)
				"dwi",

				noFiles = False; 

				Switch[class,
					"Volumes",
					(*if volumes get the position of the files needed*)
					pos = posIn = GetJSONPosition[json, {{"ProtocolName", #}}] & /@ nameIn;
					debugBids["Converting DWI data ", nameIn, ", json position: ", pos];
					
					If[Flatten[pos]==={}, 
						noFiles = True;
						(*-----*)AddToLog[{"No json files found with label ", nameIn , " skipping conversion"}, 4],

						(*get the json and data*)
						(*-----*)AddToLog[{"Importing datasets with properties: ", nameIn}, 4];
						posIn = Flatten[posIn];
						pos = CheckPos/@pos;
						info = json[[First@pos]];
						dfile = ConvertExtension[files[[#]],".nii"]&/@pos;
						hdr = Last@ImportNii[First@dfile, NiiMethod -> "header"];

						hasb = (FileExistsQ[ConvertExtension[#,".bval"]]&&FileExistsQ[ConvertExtension[#,".bvec"]])&/@dfile;
						hasb = AllTrue[hasb, # === True &];

						If[hasb, 
							{data, grad, val, vox} = Transpose[ImportNiiDiff[#, FlipBvec->False]&/@ dfile];
							{data, grad, val, vox} = ConcatenateDiffusionData[data, grad, val, vox];
							,
							(*-----*)AddToLog[{"!!!!!!!!!!!!!!! WARNING NO BVAL OR BVEC FILE !!!!!!!!!!!!!!!!!!!"}, 4];
						]
					];

					,_ ,
					(*get the position of the files needed*)
					pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}];
					debugBids["Converting DWI data ", nameIn, ", json position: ", pos];

					If[pos==={}, 
						noFiles = True;
						(*-----*)AddToLog[{"No json files found with label ", nameIn , " skipping conversion"}, 4],

						(*get the json and data*)
						(*-----*)AddToLog[{"Importing dataset with properties: ", nameIn}, 4];
						pos = CheckPos[pos];
						info = json[[pos]];
						dfile = ConvertExtension[files[[pos]],".nii"];
						hdr = Last@ImportNii[dfile, NiiMethod -> "header"];
						
						hasb = FileExistsQ[ConvertExtension[dfile,".bval"]]&&FileExistsQ[ConvertExtension[dfile,".bvec"]];

						If[hasb, 
							{data, grad, val, vox} = ImportNiiDiff[dfile, FlipBvec->False],
							(*-----*)AddToLog[{"!!!!!!!!!!!!!!! WARNING NO BVAL OR BVEC FILE !!!!!!!!!!!!!!!!!!!"}, 4];
						];
						(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
					]
				];

				If[!noFiles,
					(*get the offset to add to header*)
					{vz, vy, vx} = vox;
					{sz, sy, sx} = vox Dimensions@data[[All, 1]];
					{dz, dy, dx} = {"qOffsetZ", "qOffsetY", "qOffsetX"} /. hdr;
					off = -{(sz - vz)/2, (dy + sy) - vy, dx};

					(*make the additional mandatory bids json values*)
					infoExtra = Join[infoExtra, <|
						"Offset"->off,
						"ForthDimension"->"Diffusion",
						"DataClass"->class
					|>];

					If[class==="Volumes",
						files = Flatten[files];
						pos = Flatten[pos];
						nameIn = First@nameIn;
					];

					(*export to the correct folder*)
					debugBids[{parts, type, GetClassName[class, nameIn], datType["Suffix"]}];
					outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], 
						"suf"->{datType["Suffix"]}|>];
					(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
					If[hasb,
						ExportBval[val, ConvertExtension[outFile, ".bval"]];
						ExportBvec[grad, ConvertExtension[outFile, ".bvec"]];
					];
					ExportNii[data, vox, ConvertExtension[outFile, ".nii"], CompressNii -> compress];
					Export[ConvertExtension[outFile, ".json"], MergeJSON[{info, infoExtra}]];

					(*Delete used files*)
					DelFiles[files[[posIn]], del];
				],

				(*-------------------------------------------*)
				(*----------- T2 conversion script ----------*)
				(*-------------------------------------------*)
				"mese",

				Which[
(*TODO
I have to properly implement the logic that figures out if its siemens of Philips and if its individual files of 4D and if the correct 
echo time is in the json. and then spit out warnings and skip when things are going wrong
*)
					(*if echo time exists assume 4D nii without correct echo times*)
					KeyExistsQ[Lookup[datType, "Process", <||>], "EchoTime"],

					pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}];
					debugBids["Converting MESE data, json position: ", pos];

					(*get the json and data*)
					(*-----*)AddToLog[{"Importing dataset with properties: ", nameIn}, 4];
					pos = CheckPos[pos];
					(*echo times - get the echo time from the data json if present*)
					info = json[[pos]];

					If[KeyExistsQ[info, "EchoTime"] && KeyExistsQ[info, "EchoTrainLength"] || info["Manufacturer"]==="Siemens",
						{data, vox} = ImportNii[ConvertExtension[files[[pos]],".nii"]];
						,
						{data, fit, vox} = ImportNiiT2[ConvertExtension[files[[pos]],".nii"]];
					];
					(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
					echo = Lookup[info, "EchoTime", datType["Process", "EchoTime"]/1000.];
					nEch = Lookup[info, "EchoTrainLength", Length[data[[1]]]];
					info = KeyDrop[info, "EchoTime"];
					echo = <|
						"EchoNumber" -> Range[nEch], 
						"EchoTime" -> (echo + Range[0, nEch - 1] echo)
					|>;
					debugBids[echo];

					,
					(*Else its a list of single echo nii files*)
					True,

					(*get the position of the files needed*)
					pos = posIn = GetJSONPosition[json, {{"ProtocolName", nameIn}}, "EchoTime"];
					debugBids["Converting MESE data ", nameIn, ", json position: ", pos];
					info = MergeJSON[json[[pos]]];

					(*select only echos*)
					len = info["AcquisitionNumber"];
					len = If[ListQ[len], Max[len], Lookup[info, "EchoTrainLength", Length[pos]]];
					pos = pos[[;; len]];
					info = MergeJSON[json[[pos]]];

					(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", nameIn}, 4];

					(*get the json and data*)
					AssociateTo[info, "EchoNumber" -> Range@len];
					{data, vox} = Transpose[ImportNii /@ ConvertExtension[files[[pos]],".nii"]];
					data = Transpose[data];
					vox = First@vox;
					(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];

					echo = <||>;
				];

				(*make the additional mandatory bids json values*)
				infoExtra = Join[infoExtra, echo, <|
					"ForthDimension"->"EchoTime",
					"DataClass"->class
				|>];

				(*export to the correct folder*)
				outFile = GenerateBidsFileName[fol, <|parts, "type"->type, GetClassName[class, nameIn], 
					"suf"->{datType["Suffix"]}|>];
				(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
				ExportNii[data, vox, ConvertExtension[outFile, ".nii"], CompressNii -> compress];
				Export[ConvertExtension[outFile, ".json"], MergeJSON[{info, infoExtra}]];

				(*Delete used files*)
				DelFiles[files[[posIn]], del];

				,

				(*-------------------------------------------*)
				(*-------- Other processing script ----------*)
				(*-------------------------------------------*)
				_,
				(*-----*)AddToLog["Unknown datatype for conversion", 4];

			(*Close Type switch*)
			];
		(*close file check*)	
		];
	(*close loop over stack names*)
	,{nameIn, labels}];

	(*compress the nii files if compression during ExportNii -> False*)
	If[!compress, CompressNiiFiles[fol]];
]


CheckPos[pos_] := Block[{posOut},
	posOut = Last[pos];
	If[Length[pos] > 1,
		(*-----*)AddToLog[{"!!!!!!!!!!!!!!! More than one file found using last !!!!!!!!!!!!!!!!!!!"}, 4];
		debugBids["!!!!!!!!!!!!!!! More than one file found using last: ", posOut];
	];
	posOut
]


DelFiles[files_, del_]:=Quiet@If[del, 
	DeleteFile[ConvertExtension[files,#]]&/@{".nii", ".nii.gz", ".json", ".bval", ".bvec"}
];


(* ::Subsection:: *)
(*3. MuscleBidsProcess*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsProcess*)


Options[MuscleBidsProcess] = {ProcessSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsProcess] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsProcess[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsProcess[folder, GetConfig[folder], opts];


MuscleBidsProcess[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir},
	debugBids["starting MuscleBidsProcess"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsProcess[
		ConfigLookup[config, "folders", "rawData"],(*the input folder for the data*)
		ConfigLookup[config, "folders", "derivedData"],(*the output folder for processing*)
		config["datasets"],(*what data for processing*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsProcess[niiFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]] := BidsFolderLoop[niiFol, outFol, datDis, Method->"MuscleBidsProcess", opts]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsProcessI*)


MuscleBidsProcessI[{folIn_, folOut_}, datType_, verCheck_] := Block[{
		con, fol, parts, type, files, sets, diffFile, nfile, keys, dixFiles, jfile, nFiles, phbpt, dbond,
		outfile, json, echos, mag, ph, real, imag, dvox, magM, B0mask, ph0i, pos, e1, e2, hz, b0i,
		t2stari, watfr, fatfr, wat, fat, inph, outph, b0, t2star, r2star, phi, itt, res, outTypes, preProc, 
		nfilep, jfilep, resi, data, grad, val, diffvox, mask, den, sig, snr, snr0, reg, valU, mean, 
		fiti, s0i, fri, adci, pD, tens, s0, out, l1, l2, l3, md, fa, rd, t2vox, t2w, t2f, b1, n, 
		angle, ex, ref, thk, phii, phbpi, phbp, ta, filt, field, settingPre, settingPro, regF, coil, off, 
		int, dint, suffix, types, flip, per, bmat, magph, split, ivim, shift, t2, gradField, 
		meanV, coor, valV, fasc, fascm, sel, norm, rdim
	},

	debugBids["Starting MuscleBidsProcessI"];
	debugBids[{folIn, folOut}];

	(*get the context for exporting*)
	con = Context[con];
	outTypes = {};

	(*get the information needed for processing, e.g. session|repetition*)
	{fol, parts} = PartitionBidsFolderName[folIn];
	type = datType["Type"];
	keys = {"EchoTime", "ForthDimension", "DataClass", "Stack", 
		"OverLap", "SliceThickness", "SpacingBetweenSlices"};

	(*see what needs to be processed*)
	files = Flatten[FileNames["*"<>StringStrip[#]<>"*.json", folIn]& /@ Flatten[{datType["Label"]}]];
	sets = If[type==="megre"||type==="tse",
		DeleteDuplicates[(ta = #;AssociateTo[ta, "suf"->{First[ta["suf"]]}])&/@PartitionBidsName[FileBaseName/@files]],
		DeleteDuplicates[PartitionBidsName[FileBaseName/@files]]];
	(*-----*)AddToLog[{"Found", ToString[Length[sets]], datType["Class"], "that will be processed:"}, 2];

	debugBids[Column@files];
	debugBids[Column@sets];

	(*loop over sets*)
	Table[
		(*-----*)AddToLog[dataToLog@set, 2];
		debugBids[{set, type, datType["Process", "Method"]}];
		(*see which data type is expected*)
		Switch[type,

			"megre" | "tse",
			(*-------------------------------------------*)
			(*-------- megre processing scripts ---------*)
			(*-------------------------------------------*)

			Switch[datType["Process", "Method"],

				(*-------------------------------------------*)
				(*-------- Dixon processing scripts ---------*)
				(*-------------------------------------------*)

				"Dixon-S" | "Dixon-P",
				(*siemens data with online reconstruction*)
				suffix = datType["Process", "Types"];
				If[MatrixQ[suffix], {suffix, types} = Transpose@suffix];

				dixFiles = GenerateBidsFileName[fol, <|set, "suf"->{datType["Suffix"], #}|>]&/@suffix;
				jfile = ConvertExtension[First@dixFiles, ".json"];
				nFiles = ConvertExtension[dixFiles, ".nii"];

				(*output file names*)
				outfile = GenerateBidsFileName[folOut, set];
				debugBids[outfile];

				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if check file has label done and version is recent skip*)
					(*-----*)AddToLog["Processing already done for: ", True, 3];
					(*-----*)AddToLog[outfile, 4],
					(*-----*)AddToLog["Starting processing for data:", 3, True];
					(*-----*)AddToLog[First@dixFiles, 4];

					If[!AllTrue[nFiles, NiiFileExistQ],
						(*-----*)AddToLog[{"Could not find all the ", First@dixFiles}, 4],
						(*-----*)AddToLog["Importing the data", 4];
						{data, dvox} = Transpose[ImportNii/@nFiles];
						json = ImportJSON[ConvertExtension[First[nFiles], ".json"]];

						pos = Flatten[Position[suffix, #] & /@ {"inph", "outph", "fat", "wat"}];
						debugBids[pos];
						mask = If[pos==={}, 1, 
							Mask[NormalizeMeanData[Transpose[NormalizeData /@ data[[pos]]]], 15,
								MaskSmoothing -> True, MaskComponents -> 2, MaskClosing -> 2, MaskDilation -> 1]
						];
						debugBids[{Dimensions@mask, Dimensions@data}];

						If[MemberQ[suffix, "wat"], wat = mask data[[Position[suffix,"wat"][[1,1]]]]];
						If[MemberQ[suffix, "fat"], fat = mask data[[Position[suffix,"fat"][[1,1]]]]];
						If[MemberQ[suffix, "inph"], inph = mask data[[Position[suffix,"inph"][[1,1]]]]];
						If[MemberQ[suffix, "outph"], outph = mask data[[Position[suffix,"outph"][[1,1]]]]];

						If[MemberQ[suffix, "t2star"],
							t2star = mask data[[Position[suffix,"t2star"][[1,1]]]] / 10000.;
							r2star = DivideNoZero[1, t2star];
							AppendTo[suffix, "r2star"]];
						If[MemberQ[suffix, "fatfr"],
							fatfr = mask data[[Position[suffix, "fatfr"][[1,1]]]] / 1000.;
							If[!MemberQ[suffix, "watfr"], watfr = mask - fatfr; AppendTo[suffix, "watfr"]];
						];

						If[!MemberQ[suffix, "fatfr"] && MemberQ[suffix, "wat"] && MemberQ[suffix, "fat"],
							{watfr, fatfr} = MaskData[DixonToPercent[wat, fat], mask];
							AppendTo[suffix, "fatfr"];
							If[!MemberQ[suffix, "watfr"], AppendTo[suffix, "watfr"]];
						]
					];

					(*export all the calculated data*)
					(*-----*)AddToLog["Exporting the calculated data to:", 4];
					(*-----*)AddToLog[outfile,5];
					outTypes = suffix;
					(
						ExportNii[ToExpression[con<>#], First@dvox, outfile<>"_"<>#<>".nii", CompressNii -> compress];
						Export[ConvertExtension[outfile <> "_"<>#, ".json"], json]
					)&/@ outTypes;
					

					(*export the check file*)
					MakeCheckFile[outfile, Sort@Join[
						{"Check"->"done", "Outputs" -> outTypes, "SetProperties"->set}
					]];

					(*compress the nii files if compression during ExportNii -> False*)
					If[!compress, CompressNiiFiles[DirectoryName[outfile]]];
				];
				(*-----*)AddToLog["Finished processing", 3, True];

				,
				"Dixon" | "Dixon-B",
				(*philips data with offline reconstruction*)

				(*output file names*)
				outfile = GenerateBidsFileName[folOut, set];
				debugBids[outfile];

				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if check file has label done and version is recent skip*)
					(*-----*)AddToLog["Processing already done for: ", True, 3];
					(*-----*)AddToLog[outfile, 4],

					(*input file names*)
					dixFiles = GenerateBidsFileName[fol, <|set, "suf"->{datType["Suffix"], #}|>]&/@{"real", "imag"};
					jfile = ConvertExtension[First@dixFiles, ".json"];
					nFiles = ConvertExtension[dixFiles, ".nii"];
					magph = False;

					(*if not real imag check for mag phase*)
					If[!FileExistsQ[jfile],
						dixFiles = GenerateBidsFileName[fol, <|set, "suf"->{datType["Suffix"], #}|>]&/@{"", "ph"};
						jfile = ConvertExtension[First@dixFiles, ".json"];
						nFiles = ConvertExtension[dixFiles, ".nii"];
						magph = True;
					];

					(*-----*)AddToLog["Starting processing for data:", 3, True];
					(*-----*)AddToLog[First@dixFiles, 4];

					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*-----*)AddToLog["Could not find the needed JSON file", 4];,
						(*Check if needed nii Exist*)
						If[!AllTrue[nFiles, NiiFileExistQ],
							(*-----*)AddToLog[{"Could not find all the ", First@dixFiles}, 4],
							(*-----*)AddToLog["Importing the data", 4];

							(*import the data*)
							json = ImportJSON[jfile];
							{echos, field} = json /@ {"EchoTime", "MagneticFieldStrength"};

							If[magph,
								{{mag, ph}, dvox} = Transpose[ImportNii/@nFiles];
								real = mag Cos[ph];
								imag = mag Sin[ph];
								,
								{{real, imag}, dvox} = Transpose[ImportNii/@nFiles];
								{mag, ph} = Through[{Abs, Arg}[real + I imag]];
							];
							dvox = First@dvox;

							(*Apply background mask*)
							magM = NormalizeMeanData@mag;
							B0mask = Mask[magM, 15, MaskSmoothing->True, MaskComponents->2, MaskClosing->2, MaskDilation->1];
							{real, imag} = MaskData[#, B0mask] &/@ {real, imag};

							(*-----*)AddToLog["Starting denoising and SNR calculation", 4];
							{{real, imag}, sig} = PCADeNoise[{real, imag}, PCAKernel -> 5, Method -> "Patch", PCAComplex -> True];
							{mag, ph} = Through[{Abs, Arg}[real + I imag]];
							snr = SNRCalc[Mean@Transpose@mag, sig];

							Switch[datType["Process", "Method"],
								(*Dixon processing scrip for multi echo gradient echo complex data as used in motion study*)
								"Dixon",

								(*see if there are dixon flips*)
								(*{{mag, ph, real, imag}, pos} = FixDixonFlips[{mag, ph, real, imag}];
								(*-----*)If[pos=!={}, AddToLog[{"Found complex flips in volumes: ", pos}, 4]];*)
								pos={};

								(*calculated field maps*)
								(*-----*)AddToLog[{"Starting field map calculation"}, 4];
								{{b0i, t2stari, phii, phbpi}, {e1, e2, n}} = DixonPhase[{real, imag}, echos];
								(*-----*)AddToLog[{"used echo ", ToString[e1], "(", 1000 echos[[e1]],"ms ) and", ToString[e2], "(", 1000 echos[[e2]], "ms )"}, 5];

								(*perform the IDEAL dixon fit*)
								(*-----*)AddToLog["Starting Dixon reconstruction", 4];

								If[Length[echos] > 6,
									(*fit with DB fat model*)
									{{watfr, fatfr}, {wat, fat, dbond}, {inph, outph}, 
										{{b0, phbp, phi, phbpt}, {t2star, r2star}}, itt, res} = DixonReconstruct[
											{real, imag}, echos, {b0i, t2stari, phii, phbpi}, 
											DixonPhases -> {True, True, True, True, True}, 
											DixonFixT2 -> False, DixonFieldStrength -> field, 
											DixonAmplitudes -> "CallDB", DixonTolerance->1
										];
									pos = {"DixonFlips" -> pos, "DixonBipolar" -> True, "DioxonDoubleBonds"->True};
									outTypes = {"dbond", "phbp", "phi", "phbpt", "phii", "phbpi"};
									,
									(*fit with fixed fat model*)
									{{watfr, fatfr}, {wat, fat}, {inph, outph}, 
										{{b0, phbp, phi, phbpt}, {t2star, r2star}}, itt, res} = DixonReconstruct[
											{real, imag}, echos, {b0i, t2stari, phii, phbpi}, 
											DixonPhases -> {True, True, True, True, True}, 
											DixonFixT2 -> False, DixonFieldStrength -> field, 
											DixonAmplitudes -> "Fixed", DixonTolerance->1
										];
									pos = {"DixonFlips" -> pos, "DixonBipolar" -> True, "DioxonDoubleBonds"->False};
									outTypes = {"phbp", "phi", "phbpt", "phii", "phbpi"};
								];

								,
								(*Dixon processing scrip for multi echo gradient echo complex data as used in Bochum cohort*)
								"Dixon-B"
								,

								(*uwrap and convert B0 to hz*)
								(*-----*)AddToLog[{"Starting field map calcualtion"}, 4];
								b0i = UnwrapSplit[ph[[All, -1]] - ph[[All, 1]], mag, UnwrapDimension -> "3D", MonitorUnwrap -> False];
								b0i = b0i/(2 Pi Length[echos] (echos[[2]] - echos[[1]]));
								(*calculate the t2 star from the two in phase images*)
								t2stari = T2Fit[mag, echos][[2]];

								debugBids[Dimensions/@{real,imag, b0i, t2stari}];
								debugBids[echos];

								(*perform the IDEAL dixon fit*)
								(*-----*)AddToLog["Starting Dixon reconstruction", 4];
								{{watfr, fatfr}, {wat, fat}, {inph, outph}, 
									{{b0}, {t2star, r2star}}, itt, res} = DixonReconstruct[
										{real, imag}, echos, {b0i, t2stari}, DixonClipFraction -> True];
							];

							{wat, fat} = Abs[{wat, fat}];

							(*export all the calculated data*)
							(*-----*)AddToLog["Exporting the calculated data to:", 4];
							(*-----*)AddToLog[outfile,5];
							outTypes = Join[{"real", "imag", "mag", "ph", "b0i", "t2stari", "b0", "t2star", "r2star", 
								"inph", "outph", "wat", "fat", "watfr", "fatfr", "itt", "res", "snr", "sig"}, outTypes];

							ExportNii[ToExpression[con<>#], dvox, outfile<>"_"<>#<>".nii", CompressNii -> compress] &/@ outTypes;
							Export[ConvertExtension[outfile <> "_"<>#, ".json"], json]&/@ outTypes;

							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "EchoTimes"->echos, "Outputs" -> outTypes, "SetProperties"->set}, 
								pos, Normal@KeyTake[json, keys]
							]];

							(*compress the nii files if compression during ExportNii -> False*)
							If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

							(*-----*)AddToLog["Finished processing", 3, True];
						]
					]
				(*close dixon processing*)
				],

				_,
				(*-------------------------------------------*)
				(*-------------- Unknown megre --------------*)
				(*-------------------------------------------*)
				(*-----*)AddToLog[{"Unknown processing ", datType["Process"], "for datatype", type}, True, 3];

			(*close megre processing*)
			],

			"dwi",
			(*-------------------------------------------*)
			(*--------- dwi processing script -----------*)
			(*-------------------------------------------*)

			(*input file names*)
			diffFile = GenerateBidsFileName[fol, set];
			jfile = ConvertExtension[diffFile, ".json"];
			nfile = ConvertExtension[diffFile, ".nii"];

			(*ouput file names*)
			outfile = GenerateBidsFileName[folOut, set];
			debugBids[outfile];

			(*default settings*)
			settingPre = settingPro = <||>;

			(*-------------------------------------------*)
			(*------- dwi pre -processing script --------*)
			(*-------------------------------------------*)

			(*check if pre-processin is already done*)
			preProc = False;
			If[CheckFile[outfile<>"_prep", "done", verCheck],
				(*if checkfile has label done and version is recent skip*)
				(*-----*)AddToLog["Pre-processing already done for: ", True, 3];
				(*-----*)AddToLog[outfile, 4],
				(*-----*)AddToLog["Starting pre-processing for data:", 3, True];
				(*-----*)AddToLog[diffFile, 4];

				If[!FileExistsQ[jfile],
					(*-----*)AddToLog["Could not find the needed JSON file",4],
					(*Check if needed nii Exist*)
					If[!(NiiFileExistQ[nfile] && FileExistsQ[ConvertExtension[nfile,".bval"]] && 
						FileExistsQ[ConvertExtension[nfile,".bvec"]]),
						(*-----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"}, 4],
						(*-----*)AddToLog["Importing the data", 4];

						(*import the data*)
						json = ImportJSON[jfile];
						{data, grad, val, diffvox} = ImportNiiDiff[nfile, FlipBvec->False];
						{data, grad, val} = SortDiffusionData[NormalizeData[data], grad, val];
						debugBids[{"Raw data dimensions", Dimensions[data]}];

						(*gradient flip correction*)
						{flip, per} = ConfigLookup[datType, "Process", "FlipPermute"];
						settingPre = MergeConfig[settingPre, <| "FlipPermute" -> {flip, per} |>];
						(*-----*)AddToLog[{"Gradient flips used: ", flip, per}, 4];
						grad = FlipGradientOrientation[grad, flip, per];

						(*Denoise and SNR*)
						(*-----*)AddToLog["Starting dwi denoising", 4];
						mask = Mask[NormalizeMeanData[data], ConfigLookup[datType, "Process", "Masking"], 
							MaskSmoothing->True, MaskComponents->2, MaskDilation->1];
						{den, sig} = PCADeNoise[data, mask, PCAOutput->False, PCATolerance->0, PCAKernel->5];
						snr = SNRCalc[den, sig];
						snr0 = Mean@Transpose@First@SelectBvalueData[{snr, val}, {0, Max[{2, Min[val]}]}];
						debugBids[{"denoised data dimensions", Dimensions[den]}];

						(*register data - 2D or 3D - each side seperate*)
						(*-----*)AddToLog["Starting dwi motion and eddy correction", 4];
						rdim = ConfigLookup[datType, "Process", "RegistrationDimension"];
						settingPre = MergeConfig[settingPre, <|"RegistrationDimension" -> rdim|>];
						split = ConfigLookup[datType, "Process", "SplitRegistration"];
						regF = If[rdim==="2D", split = False; RegisterCardiacData, 
							If[split, RegisterDiffusionDataSplit, RegisterDiffusionData]];
						settingPre = MergeConfig[settingPre, <|"RegistrationDimension" -> rdim|>];

						debugBids[{"Registration function", regF}];
						reg = regF[{den, mask, diffvox}, Iterations->300, NumberSamples->5000, 
							PrintTempDirectory->False, MethodReg -> "bspline", InterpolationOrderReg ->1, 
							BsplineSpacing -> {30, 30, 30}, BsplineDirections -> {0.5, 1, 1}
						];

						(*anisotropic filtering*)
						(*-----*)AddToLog["Starting anisotropic data smoothing", 4];
						filt = Unitize[reg] P2SDenoise[reg, mask];

						(*export all the calculated data*)
						(*-----*)AddToLog["Exporting the calculated data to:", 4];
						(*-----*)AddToLog[outfile, 5];
						outTypes = {"den", "reg", "sig", "snr0", "snr", "filt"};

						(
							ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii", CompressNii -> compress];
							Export[ConvertExtension[outfile<>"_"<>#, ".json"], MergeJSON[{json, settingPre}]];
						)& /@ outTypes;
						ExportBvalvec[{val, grad}, outfile <> "_"<>#]& /@ {"reg", "filt"};

						(*export the checkfile*)
						MakeCheckFile[outfile<>"_prep", Sort@Join[
							{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, 
							"Outputs" -> outTypes, "SetProperties"->set},
							Normal@KeyTake[json, keys]
						]];

						(*compress the nii files if compression during ExportNii -> False*)
						If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

						(*-----*)AddToLog["Finished pre-processing", 3, True];

						(*Set preproc true, overrules checkfile for processing*)
						preProc = True;
					]
				]
			(*close preprocessing*)
			];

			Switch[datType["Process", "Method"],

				"DTI",
				(*-------------------------------------------*)
				(*---------- dwi processing script ----------*)
				(*-------------------------------------------*)

				(*input file for processing*)
				nfilep = ConvertExtension[GenerateBidsFileName[folOut, <|set, "suf"->{datType["Suffix"], "filt"}|>],".nii"];
				jfilep = ConvertExtension[nfilep, ".json"];

				(*check if processin is already done, redo is prep is done*)					
				If[If[!preProc, CheckFile[outfile, "done", verCheck], False],
					(*if checkfile has label done and version is recent skip*)
					(*-----*)AddToLog["Processing already done for: ", True, 3];
					(*-----*)AddToLog[outfile, 4],
					(*-----*)AddToLog["Starting processing for data:", 3, True];
					(*-----*)AddToLog[nfilep, 4];				

					If[!FileExistsQ[jfilep],
						(*-----*)AddToLog["Could not find the needed JSON file", 4];,

						(*Check if the needed nii files exist*)
						If[!(NiiFileExistQ[nfilep]&&FileExistsQ[ConvertExtension[nfilep,".bval"]]&&FileExistsQ[ConvertExtension[nfilep,".bvec"]]),
							(*-----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"}, 4],
							(*-----*)AddToLog["Importing the data", 4];

							(*import the data*)
							json = ImportJSON[jfilep];
							{data, grad, val, diffvox} = ImportNiiDiff[nfilep, FlipBvec->False];
							mask = Mask[NormalizeMeanData[data], ConfigLookup[datType, "Process", "Masking"], 
								MaskSmoothing->True, MaskComponents->2, MaskClosing->2];
							data = MaskData[data, mask];

							(*perform gradient nonlinearity correction*)
							coil = ConfigLookup[datType, "Process", "GradientCorrection"];
							settingPro = Join[settingPro, <|"GradientCorrection"->coil|>];
							off = Lookup[json, "Offset", False];
							coilpar = {};
							If[!StringQ[coil], coil = False,
								(*-----*)AddToLog[{"Using Gradient correction: ", coil}, 4];
								If[!VectorQ[off], coil = False;
									(*-----*)AddToLog["No offset defined in json, skipping grad correction" , 5],
									{int, dint} = MakeGradientDerivatives[diffvox, coil];
									coil = {diffvox, off, dint};
									outTypes = Join[{"field"}, outTypes];
								];
							];

							(*perform ivim correction*)
							ivim = ConfigLookup[datType, "Process", "IVIMCorrection"];
							settingPro = Join[settingPro, <|"IVIMCorrection"->ivim|>];
							{mean, valU} = MeanBvalueSignal[data, val];
							If[ivim,
								(*-----*)AddToLog["Starting ivim calculation", 4];
								{s0i, fri, adci, pD} = If[coil === False,
									(*use normal b-value*)
									IVIMCalc[mean, valU, {1, .05, .003, .015}, 
										IVIMConstrained->False, Parallelize->True, IVIMFixed->True],
									(*use gradient field corrected b-value*)
									IVIMCalc[data, {val, grad}, {1, .05, .003, .015}, coil,
										IVIMConstrained -> False, Parallelize -> True, IVIMFixed -> True]
								];
								data = First@IVIMCorrectData[data, {s0i, fri, pD}, val, FilterMaps->False];
								adci = 1000 adci;
								outTypes = Join[{"adci", "fri", "s0i"}, outTypes];
							];

							(*perform the actual tensor calculation*)
							(*-----*)AddToLog["Starting tensor calculation", 4];
							{tens, s0, out} = Quiet@TensorCalc[data, grad, val, coil, FullOutput->True, 
								Method->"iWLLS", RobustFit->True, Parallelize->True, MonitorCalc->False];
							If[coil === False, {out, res} = out, {out, res, field} = out];
							out = Total@Transpose@out;
							(*calculate tensor parameters*)
							{l1, l2, l3, md, fa} = ParameterCalc[tens];
							rd = Mean[{l2, l3}];

							(*perform fasciculation analysis*)
							fasc = ConfigLookup[datType, "Process", "FasciculationDetection"];
							settingPro = Join[settingPro, <|"FasciculationDetection"->fasc|>];
							If[fasc,
								(*-----*)AddToLog["Starting faciculation analysis", 4];
								(*normalize the diffusion data based on the tensor and select b>200*)
								reg = First@ImportNii[StringReplace[nfilep, "filt" -> "reg"]];
								sel = First@SelectBvalueData[reg, val, 1];
								norm = NormalizeFasciculationData[sel, mask, {tens, grad, val}];
								(*perform activation analysis*)
								fasc = First@FindActivations[norm, IgnoreSlices -> {0, 0}, 
									ActivationThreshold -> {3., .65}, ActivationOutput -> All, MaskDilation -> 2, 
									ActivationIterations -> 10, ActivationBackground -> 10];
								{fasc, fascm} = SelectActivations[fasc];
								outTypes = Join[{"fasc", "fascm", "norm"}, outTypes];
							];

							(*export all the calculated data*)
							(*-----*)AddToLog["Exporting the calculated data to:", 4];
							(*-----*)AddToLog[outfile, 5];
							debugBids[Column[{json, settingPro}]];
							
							tens = Transpose[tens];
							outTypes = Join[{"data", "mean", "tens", "res", "out", "s0", 
								"l1", "l2", "l3", "md", "fa", "rd"}, outTypes];

							(
								ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii", CompressNii -> compress];
								Export[ConvertExtension[outfile<>"_"<>#, ".json"], MergeJSON[{json, settingPro}]];
							) &/@ outTypes;

							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, 
									"Outputs" -> outTypes, "SetProperties"->set},
								Normal@KeyTake[json, keys]
							]];

							(*compress the nii files if compression during ExportNii -> False*)
							If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

							(*-----*)AddToLog["Finished processing", 3, True];				
						]
					]
				(*close dti processing*)
				],

				_,
				(*-------------------------------------------*)
				(*--------------- Unknown dti ---------------*)
				(*-------------------------------------------*)
				(*-----*)AddToLog[{"Unkonwn processing ", datType["Process"], "for datatype", type}, True, 3];
			],

			"mese",
			(*-------------------------------------------*)
			(*-------- mese processing scripts ----------*)
			(*-------------------------------------------*)

			Switch[datType["Process", "Method"],				

				"EPGT2"|"Exp",
				(*-------------------------------------------*)
				(*---------- EPG processing script ----------*)
				(*-------------------------------------------*)

				(*input file names*)
				diffFile = GenerateBidsFileName[fol, set];
				jfile = ConvertExtension[diffFile, ".json"];
				nfile = ConvertExtension[diffFile, ".nii"];

				(*ouput file names*)
				outfile = GenerateBidsFileName[folOut, set];

				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if checkfile has label done and version is recent skip*)
					(*-----*)AddToLog["Processing already done for: ", True, 3];
					(*-----*)AddToLog[outfile, 4],
					(*-----*)AddToLog["Starting processing for data:", 3, True];
					(*-----*)AddToLog[diffFile, 4];

					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*-----*)AddToLog[{"Could not find the needed JSON file of", jfile}, 4];,
						(*Check if needed nii Exist*)
						If[!NiiFileExistQ[nfile],
							(*-----*)AddToLog[{"Could not find the data of", diffFile}, 4],
							(*-----*)AddToLog["Importing the data", 4];

							(*import the data*)
							json = ImportJSON[jfile];
							echos = json["EchoTime"];
							debugBids["importing: ", nfile];
							{data, t2vox} = ImportNii[nfile];

							If[ArrayDepth[data]=!=4,
								(*-----*)AddToLog["!!!!!!!!!!!!!!! SKIPPING - WRONG DATA DIMENSIONS !!!!!!!!!!!!!!!!!!!", 4];	
								debugBids["!!!!!!!!!!!!! Wrong data dimensions: ", Dimensions@data];
								,

								(*mask the background*)		
								mask = Mask[NormalizeMeanData[data], ConfigLookup[datType, "Process", "Masking"], MaskSmoothing -> True, MaskComponents -> 2, MaskClosing -> 2];
								data = NormalizeData@MaskData[data, mask];

								Switch[datType["Process", "Method"],

									"EPGT2",

									(*determine the pulse profiles*)
									(*-----*)AddToLog["Calculating the slice profiles", 4];	
									{ex, ref} = ConfigLookup[datType, "Process", "Settings"];
									debugBids[{ex, ref, echos}];
									(*check if the profiles are given as numbers or as files*)
									angle = If[NumberQ[ex] && NumberQ[ref],
										shift = 0.;
										{ex, ref},
										thk = json["SliceThickness"];
										angle = GetPulseProfile[ex, ref, SliceRange -> 3 thk, SliceRangeSamples -> 6 thk][[1;;2]];
										shift = ConfigLookup[datType, "Process", "Shift"];
										shift = If[shift=!=True, 0.,
											shift = (1/ref[[3, 1]] - 1/ex[[3, 1]]) (3(*filed times ppm*) 3.4);
											(*-----*)AddToLog[{"Shifting fat profile with: ", shift}, 4];
											Round[shift/((3 thk/2)/(6 thk))]
										];
										angle
									];

									debugBids[Dimensions/@{data, t2vox}];

									(*caculate the water t2 map*)
									(*-----*)AddToLog["Starting EPG T2 calculation", 4];
									{{t2w, t2f, b1}, {wat, fat, fatfr}, res} = EPGT2Fit[data, 1000 echos, angle, 
										MonitorCalc -> False, DictT2IncludeWater -> True, 
										EPGFitFat -> False, EPGCalibrate -> True, EPGFatShift -> shift,
										DictT2fValue -> 150, DictT2fRange -> {150, 250, 5}, 
										DictB1Range -> {0.5, 1.4, 0.02}, DictT2Range -> {15, 45, 0.2}];

									outTypes = {"data", "t2w", "t2f", "b1", "wat", "fat", "fatfr", "res"};

									,
									"Exp",

									(*-----*)AddToLog["Starting exponential T2 fitting", 4];
									{s0, t2} = T2Fit[data, 1000 echos];

									outTypes = {"data", "t2", "s0"};
								];

								(*export all the calculated data*)
								(*-----*)AddToLog["Exporting the calculated data to:", 4];
								(*-----*)AddToLog[outfile, 5];		

								(
									ExportNii[ToExpression[con<>#], t2vox, outfile<>"_"<>#<>".nii", CompressNii -> compress];
									Export[ConvertExtension[outfile<>"_"<>#, ".json"], json];
								) &/@ outTypes;

								(*export the checkfile*)
								MakeCheckFile[outfile, Sort@Join[
									{"Check"->"done", "EchoTimes" -> echos, "Outputs" -> outTypes, "SetProperties"->set},
									Normal@KeyTake[json, keys]
								]];

								(*compress the nii files if compression during ExportNii -> False*)
								If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

								(*-----*)AddToLog["Finished processing", 3, True];
							]
						]
					]
				(*close t2 processing*)
				],

				_,
				(*-------------------------------------------*)
				(*--------------- Unknown mese ---------------*)
				(*-------------------------------------------*)
				(*-----*)AddToLog[{"Unkonwn processing ", datType["Process"], "for datatype", type}, True, 3];
			],
			(*-------------------------------------------*)
			(*------------------ Other ------------------*)
			(*-------------------------------------------*)
			_,
			(*-----*)AddToLog["Unknown datatype for processing", 4];

		(*Close Type switch*)
		];

	(*close loop over sets*)
	, {set, sets}]
]


(* ::Subsection:: *)
(*4. MuscleBidsMerge*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsMerge*)


Options[MuscleBidsMerge] = {ProcessSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsMerge] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsMerge[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsMerge[folder, GetConfig[folder], opts];


MuscleBidsMerge[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir}, 
	debugBids["starting MuscleBidsMerge"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsMerge[
		ConfigLookup[config, "folders", "derivedData"],(*the input folder for the data*)
		ConfigLookup[config, "folders", "mergeData"],(*the output folder for merging*)
		config["datasets"],(*what data merging*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsMerge[datFol_?StringQ, merFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]] := BidsFolderLoop[datFol, merFol, datDis, Method->"MuscleBidsMerge", opts]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsMergeI*)


MuscleBidsMergeI[{folIn_, folOut_}, {datType_, allType_}, verCheck_] := Block[{
		nonQuant, multDim, native, fol, parts, merge, fileCheck, 
		outfile, tarFile, tarStack, movStack, nStack, files, sameType,
		process, processMD, processAll, nSet, processStacs,
		overT, overM, pad, motion, reverse, split, metReg, settings,
		target, vox, voxt, moving, movingMD, leng, lengMD, voxm, names,
		posAll, posNat, posScale, voxtR, voxF, json, 
		im, targetR, mskm, mskt, msktR, func, reg, movp
	},

	(*get the input settings*)
	debugBids["Starting MuscleBidsMergeI"];
	debugBids[{folIn, folOut}];
	debugBids[datType];

	(*muscle bids that are non quantitative of multi dimensional and or have to stay native*)
	nonQuant = {"inph", "outph", "wat", "fat", "s0", "mean"};
	multDim = {"tens", "data", "filt", "fasc", "data", "reg"};
	native = {"tens", "fasc"};

	(*get the outfile names*)
	{fol, parts} = PartitionBidsFolderName[folIn];
	merge = datType["Merging"];

	(*------------------ figure out the file names and check them ------------------*)

	outfile = BuildBidsNameFromConfig[{folOut, parts}, datType];
	debugBids[{parts, outfile}];

	(*target out file and input stack*)
	tarFile = BuildBidsNameFromConfig[{folOut, parts}, {datType, allType}, merge["Target"]];
	tarStack = BuildBidsNameFromConfig[{folOut, fol, parts}, {datType, allType}, merge["Target"]];
	fileCheck = AllTrue[NiiFileExistQ /@ tarStack, # &];
	debugBids[{datType["Class"], tarFile}];
	debugBids["target stack: ", Column@tarStack];
	debugBids[fileCheck];

	If[!fileCheck,
		(*-----*)AddToLog[{"Skipping merging since the target files could not be found"}, 3];
		Return[]];

	(*moving input stack*)
	movStack = BuildBidsNameFromConfig[{fol, parts}, datType, merge["Moving"]];
	fileCheck = AllTrue[NiiFileExistQ /@ tarStack, # &];
	nStack = Length @ movStack;
	debugBids["moving stack: ", Column@movStack];

	If[!fileCheck,
		(*-----*)AddToLog[{"Skipping merging since the moving files could not be found"}, 3];
		Return[]];

	(*process stack*)
	process = Select[merge["Process"], !MemberQ[multDim, #] &];
	processMD = Select[merge["Process"], MemberQ[multDim, #] &];
	leng = Length @ process;
	processAll = Join[process, processMD];
	nSet = Length[processAll];
	processStacs = BuildBidsNameFromConfig[{fol, parts}, datType, #]& /@ processAll;
	fileCheck = (files = #; AllTrue[NiiFileExistQ /@ files, # &])& /@ processStacs;
	debugBids["process stack: ", Column[Column/@processStacs]];
	debugBids[fileCheck];

	(*check if number of stacks are consistant*)
	If[!AllTrue[fileCheck, #&],
		(*-----*)AddToLog[{"Not all process files exist:", StringRiffle[ToString/@fileCheck, ", "]}, 3];
		Return[]
	];

	(*start the merging, if checkfile has label done and version is recent skip*)
	(*-----*)AddToLog[{"Start joining ", nStack, "stacs for", nSet, "dataypes"}, 3];
	(*-----*)AddToLog[{"The types that will be merged are: "}, 3];
	(*-----*)AddToLog[{StringJoin@Riffle[processAll,", "]}, 4];
	If[CheckFile[outfile, "done", verCheck],
		(*-----*)AddToLog[{"Processing already done."}, 3];
		Return[]];

	(*------------------ figure out settings ------------------*)

	(*get the settings for the merging*) 
	overT = ConfigLookup[datType, "Merging", "Overlap"];
	pad = ConfigLookup[datType, "Merging", "Padding"];
	motion = ConfigLookup[datType, "Merging", "Motion"];
	reverse = ConfigLookup[datType, "Merging", "Reverse"];
	split = ConfigLookup[datType, "Merging", "SplitRegistration"];

	If[pad > 0, 
		(*-----*)AddToLog[{"Padding overlap with: ", pad}, 5]];

	{overT, overM} = If[IntegerQ[overT], {overT, overT}, overT];
	If[overT === 0, pad = 0; motion = False];

	(*Registation settings*)
	metReg = Switch[datType["InFolder"], 
		"dix", "rigid", 
		"quant", {"rigid", "affine"}, 
		_, {"rigid","affine","bspline"}
	];

	settings = <|
		"Merge Overlap" -> {overT, overM},
		"Merge Padding" -> pad,
		"Merge Motion" -> motion,
		"Merge Reverse" -> reverse,
		"Merge Split" -> split,
		"Merge Method" -> metReg
	|>;

	debugBids["overlap and split: ", {overT, pad, split}];

	(*------------------ Importing off all data after checks ------------------*)

	(*import the Target data, import merged target if it exists else merge it*)
	(*-----*)AddToLog[{"Importing and processing the target data"}, 4];

	(*if target is same as moving never load target from disk*)
	sameType = tarStack === movStack;
	If[NiiFileExistQ[tarFile] && !sameType,
		{target, voxt} = ImportNii[tarFile];
		(*-----*)AddToLog[{"Splitting the primary datatype that already existed"}, 4];
		If[nStack=!=1, 
			target = SplitSets[target, nStack, overT, ReverseSets->reverse, PadOverlap->pad], 
			target = {target}
		];
		,
		(*remake target*)
		{target, vox} = Transpose[ImportNii /@ tarStack];
		voxt = First@vox;
		debugBids["voxel size per stack: ", {vox, voxt}];
		(* make data real valued*)
		target = If[RealValuedNumberQ[target[[1, 1, 1, 1]]], target, Abs[target]];

		(*-----*)AddToLog[{"Joining the primary datatype", If[motion,"with","without"], "motion correction"}, 4];
		If[nStack=!=1,
			target = JoinSets[target, overT, voxt, ReverseSets->reverse, MotionCorrectSets->motion, 
				NormalizeSets->True, NormalizeOverlap->True, MonitorCalc->False];
			debugBids["target dimensions: ", Dimensions@target];
			target = SplitSets[target, nStack, overT, ReverseSets->reverse, PadOverlap->pad];
		];
	];
	debugBids["target dimensions: ", Dimensions/@target];

	(*import the Moving data, import the mulit dimm seperately*)
	(*-----*)AddToLog[{"Importing and processing the moving data"}, 4];

	(*import the 3D moving data *)
	{moving, vox} = Transpose[(files=#; Transpose[ImportNii /@ files]) &/@ processStacs];
	voxm = First@vox; (*voxel size per stack*)
	(*check voxel sizes of moving*)
	If[!Equal@@voxm,
		(*-----*)AddToLog[{"********** The voxel size is not the same for all stacks **********"}, 0];
		(*-----*)AddToLog[{"Voxel size per stack: ", voxm}, 4];
		(*-----*)AddToLog[{"", (Dimensions /@ First@moving) voxm}, 4];
	];

	(*multi dim data has to be flattened*)
	movingMD = If[processMD==={}, lengMD=0; {},	
		movingMD = moving[[leng+1;;]];
		lengMD = Length /@ movingMD[[All, 1, 1]]; (*4th dimensions of the mulit dims*)
		Flatten[movingMD, {1, 4}]
	];
	names = Flatten[{process, ConstantArray[#[[1]], #[[2]]] & /@ Thread[{processMD, lengMD}]}];

	(*redifine moving - make data real valued to prevent errors*)
	moving = Join[moving[[;;leng]], movingMD];
	moving = If[RealValuedNumberQ[N@#[[1,1,1,1]]], #, Abs[#]] &/@ moving;

	debugBids["moving dimensions: ", Dimensions/@{moving, moving[[;;leng]], movingMD}];
	debugBids["number of sets: ", {leng, lengMD}];
	debugBids["names: ", names];

	(*figure out the scaling of each contrast*)
	posAll = Range[Length[names]];
	posNat = Flatten[Position[names, _?(MemberQ[native, #] &), {1}]];
	posScale = Complement[posAll, posNat];
	voxtR = First@voxm;
	voxF = If[MemberQ[native, names[[#]]], voxtR, voxt]&;

	debugBids["moving before registr: ", Column[Dimensions /@ # & /@ moving]];
	debugBids["positions: ", {posScale, posNat}];

	(*import the json information*)
	json = (files=#; MergeJSON[ImportJSON[ConvertExtension[#, ".json"]]&/@files]) &/@ processStacs;
	debugBids["json dimensions: ", Dimensions@json];

	(*------------------ performing registration to target for all constrasts ------------------*)

	(*perform motion correction after target merging*)
	(*If motion correction for joning is False and target is of same type no need for motion correction*)
	debugBids["go into registration: ", {motion, sameType, !(!motion && sameType)}];

	If[!(!motion && sameType), 
		(*-----*)AddToLog[{"Performing the registration for the all the datasets"}, 4];
		im = First@FirstPosition[names, merge["Moving"]];
		debugBids["location moving contrast: ", im];

		moving = Table[
			(*-----*)AddToLog[{"Stack: ", i}, 5];
			debugBids["start registration: ", i];

			(*make target in native space*)
			targetR = RescaleData[target[[i]], {voxt, voxtR}];
			debugBids[Dimensions/@{moving[[im, i]], target[[i]], targetR}];

			(*make masks*)
			mskm = DilateMask[Mask[NormalizeData[moving[[im, i]]], 5], 5];
			mskt = DilateMask[Mask[NormalizeData[target[[i]]], 5], 5];
			msktR = DilateMask[Mask[NormalizeData[targetR], 5], 5];

			(*only register if not the same contrast and not the first stack*)
			debugBids["check for registration: ", {i===If[reverse, nStack, 1], sameType, i===If[reverse, nStack, 1]&& sameType}];
			
			If[i===If[reverse, nStack, 1] && sameType,
				(*just select data and do nothing*)
				debugBids["no registration: ", i];
				moving[[All, i]]
				,
				(*move the target from anatomical to native space*)
				func = If[i===If[reverse, nStack, 1] || split===False, 
					RegisterData, RegisterDataSplit];
				reg = ToPackedArray@N@Chop@func[
					{moving[[im, i]], mskm, voxm[[i]]}, {target[[i]], voxt}, 
					Iterations->300, BsplineSpacing->20 voxt, InterpolationOrderReg->1, NumberSamples -> 20000,
					PrintTempDirectory->False, MethodReg->metReg, HistogramBins -> 128];

				(*if padding enlarge the moving files*)
				If[pad > 0,					
					reg = ArrayPad[reg, Ceiling@{{pad, pad}/2, 0, 0}];
					movp = Transpose[ArrayPad[#, Ceiling@{{pad, pad}/2, 0, 0}]&/@moving[[All, i]]],
					movp = Transpose[moving[[All, i]]]
				];
				debugBids["Dimension before registration: ", Dimensions@movp, Dimensions/@Transpose[movp]];

				(*register back the target from native space to anatomy and tranfrom the rest*)
				func = If[i===If[reverse, nStack, 1] || split===False, 
					RegisterDataTransform, RegisterDataTransformSplit];
				movp = Flatten[(
					debugBids["registering: ", #[[1]]];
					If[#[[1]]==={}, {},
						Transpose@ToPackedArray@N@Chop@Last@func[
							#[[2]], {reg, voxm[[i]]}, {movp[[All, #[[1]]]], voxm[[i]]},
							Iterations->300, BsplineSpacing->30 voxt, InterpolationOrderReg->1, 
							NumberSamples -> 20000, PrintTempDirectory->False, DeleteTempDirectory->True, 
							MethodReg->metReg, BsplineDirections -> {1, 1, 0}, HistogramBins -> 128
						]
					])& /@ {{posScale, {target[[i]], mskt, voxt}}, {posNat, {targetR, msktR, voxtR}}}
				, 1][[Ordering[Join[posScale, posNat]]]];
				debugBids["Dimensions after registraion: ", Dimensions@movp, Dimensions/@movp];
				movp
			]
		, {i, 1, nStack}];

		(*extract all parameters after registration*)
		debugBids["after dimensions befor transpose: ", Dimensions/@moving];
		moving = Transpose[moving];
	];(*clolse motion moving*)

	(*------------------ actually join the data and reorder for multi dim ------------------*)

	debugBids["after dimensions: ", Dimensions@moving];
	debugBids["after registration: ", Column[Dimensions /@ # & /@ moving]];

	(*join the moving types*)
	(*-----*)AddToLog[{"Joining the data"}, 4];
	moving = If[nStack===1,
		moving[[All, 1]],
		debugBids["joining: ", posAll];
		JoinSets[moving[[#]], If[MemberQ[posNat, #], overM, overT], voxF[#], 
			MonitorCalc->False, MotionCorrectSets->False, 
			PadOverlap->pad, ReverseSets->reverse, 
			NormalizeSets->MemberQ[nonQuant, names[[#]]], 
			NormalizeOverlap->MemberQ[nonQuant, names[[#]]]
		]&/@posAll
	];

	debugBids["after merging: ", Column[Dimensions /@ moving]];		

	(*collect the multi dim data and unflatten them*)
	If[movingMD =!= {},
		movingMD = moving[[leng+1;;]];
		movingMD = Transpose[movingMD[[#[[1]];;#[[2]]]]] & /@ (
			{1, 0} + # & /@ Partition[Prepend[Accumulate[lengMD], 0], 2, 1]);
		moving = Join[moving[[1;;leng]], movingMD];
	];

	(*------------------ exporting the data ------------------*)

	(*export the joined data with the merged json*)
	(*-----*)AddToLog["Exporting the calculated data to:", 4];
	(*-----*)AddToLog[outfile, 5];
	(
		debugBids["Exporting: ", {processAll[[#]], voxF[#]}];
		ExportNii[moving[[#]], voxF[#], outfile<>"_"<>processAll[[#]]<>".nii", CompressNii -> compress];
		Export[outfile<>"_"<>processAll[[#]]<>".json", MergeJSON[{json[[#]], settings}]];
	)&/@ Range[nSet];

	(*make the checkfile*)
	MakeCheckFile[outfile, Sort@Join[{"Check"->"done"}, Normal@datType]];

	(*compress the nii files if compression during ExportNii -> False*)
	If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

	(*-----*)AddToLog["Finished merging", 3, True];
]


(* ::Subsection:: *)
(*5. MuscleBidsSegment*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsSegment*)


Options[MuscleBidsSegment] = {ProcessSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsSegment] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsSegment[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsSegment[folder, GetConfig[folder], opts];


MuscleBidsSegment[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir},
	debugBids["starting MuscleBidsSegment"]; 
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsSegment[
		ConfigLookup[config, "folders", "mergeData"],(*the input folder for the data, output is in same folder*)
		ConfigLookup[config, "folders", "mergeData"],
		config["datasets"],(*what data for segmentation*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsSegment[datFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]] := BidsFolderLoop[datFol, outFol, datDis, Method->"MuscleBidsSegment", opts]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsSegmentI*)


MuscleBidsSegmentI[{folIn_, folOut_}, {datType_, allType_}, verCheck_] := Block[{
		segment, segType, segTypeLab, checkFile, fol, segLocation, device,
		parts, outfile, segfile, out, vox, seg, status, 
		voxS, tari, movi, segi, tar, mov, dim, voxt, voxm, voxs, mask
	},

	status = "done";

	debugBids["Starting MuscleBidsSegmentI"];
	debugBids[datType];
	{fol, parts} = PartitionBidsFolderName[folIn];
	debugBids[folIn, folOut];
	debugBids[{fol, parts}];

	(*get the segment data type*)
	segment = datType["Segment"];
	debugBids[segment];
	If[segment === Missing["KeyAbsent", "Segment"],	
		(*-----*)AddToLog[{"No Segmentations defined for this data"}, 3];
		Return[]
	];

	(*Check if segmentation needs to be performed*)
	checkFile = ConvertExtension@BuildBidsNameFromConfig[{folOut, parts}, {datType, allType}, 
		{datType["Key"], "seg", "auto", datType["Type"]}];
	debugBids[checkFile];
	If[CheckFile[checkFile, "done", verCheck],
		(*-----*)AddToLog[{"Segmentation already done for:", datType["key"]}, 3];
		Return[]
	];

	(*Get the segmentation targets and its names*)
	segType = segment["Target"];	
	If[ArrayDepth[segType]===1, segType = {segType}];
	Switch[ConfigLookup[datType, "Segment", "Method"],

		(*Automatic segmentations using NN*)
		Automatic,

		(*Loop over the segmentation types if more are specified*)
		Table[
			(*-----*)AddToLog[{"Performing segmentation for ", StringRiffle[segi, "_"]}, 3];

			(*get the correct filenames*)
			outfile = BuildBidsNameFromConfig[{folOut, parts}, {datType, allType},
				Join[{datType["Key"], "seg", "auto"}, segi]];
			segfile = BuildBidsNameFromConfig[{fol, parts}, {datType, allType}, segi];

			(*check if target file exists if so perform the segmentation*)
			If[!NiiFileExistQ[segfile],
				AddToLog[{"The segmentation file does not exist: ", segfile}, 4];
				status = "error"
				,
				segLocation = segment["Location"];
				{out, vox} = ImportNii[segfile];
				voxS = ConfigLookup[datType, "Segment", "VoxSize"];

				If[voxS =!= Automatic, 
					AddToLog[{"Using specified reduced voxel size: ", voxS}, 4];
					dim = Dimensions[out]; 
					out = RescaleData[out, {vox, voxS}];
					debugBids[{{vox, dim}, {voxS, Dimensions@out}}];
				];
				segDim = ConfigLookup[datType, "Segment", "Dimensions"];
				If[segDim=!="2D"||segDim=!="3D", segDim="3D";];
				AddToLog[{"Segmenting data using nework dimensions: ", voxS}, 4];
				seg = SegmentData[out, segLocation, 
					TargetDevice -> ConfigLookup[datType, "Segment", "Device"], 
					Monitor -> False, SegmentationDimension -> segDim];
				If[voxS =!= Automatic, 
					seg = RescaleSegmentation[seg, dim]
				];

				ExportNii[seg, vox, outfile, CompressNii -> compress];
			];
			, {segi, segType}			
		],

		(*Register existing segmentation*)
		"Registration",

		(*figure out if duplicate handeling is needed.*)
		outfile = BuildBidsNameFromConfig[{folOut, parts}, {datType, allType},
				Join[{datType["Key"], "seg", "reg"}, segment["Target"]]];
		tar = BuildBidsNameFromConfig[{fol, parts}, {datType, allType}, segment["Target"]];
		mov = BuildBidsNameFromConfig[{fol, parts}, {datType, allType}, segment["Moving"]];
		seg = BuildBidsNameFromConfig[{fol, parts}, {datType, allType}, segment["Segmentation"]];
		debugBids[Column[{outfile, seg, tar, mov}]];

		(*Import and prepare the data*)
		{tar, voxt} = ImportNii[tar];
		tar = NormalizeData[Clip[tar, {0, Infinity}]];
		{mov, voxm} = ImportNii[mov];
		mov = NormalizeData[Clip[mov, {0, Infinity}]];
		{seg, voxs} = ImportNii[seg];
		mask = Mask[NormalizeData[tar], 5, MaskSmoothing -> True, MaskDilation -> 5];
		voxS = ConfigLookup[datType, "Segment", "VoxSize"];
		If[voxS =!= Automatic, mov = RescaleData[mov, {voxm, voxS}]; voxm = voxS;];
		debugBids[Column[Dimensions/@{seg, tar, mov}]];

		(*perform the segmentation registration*)
		seg = Table[RegisterDataTransform[
			{tar[[{i}]], mask[[{i}]], voxt}, {mov, voxm}, {seg, voxs},
			MethodReg -> {"rigid", "affine"}, NumberSamples -> 50000, HistogramBins->128, 
			PrintTempDirectory->False, DeleteTempDirectory -> True, 
			Resolutions -> 1, Iterations -> 200, TransformMethod -> "Segmentation"
		][[2]], {i, 1, 3}];

		ExportNii[seg, voxt, outfile, CompressNii -> compress];
	];

	(*make the checkfile*)
	MakeCheckFile[checkFile, Sort@Join[{"Check" -> status}, Normal@datType]];

	(*compress the nii files if compression during ExportNii -> False*)
	If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

	(*-----*)AddToLog["Finished the segmentation", 3, True];
]


(* ::Subsection:: *)
(*6. MuscleBidsTractography*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsTractography*)


Options[MuscleBidsTractography] = {ProcessSubjects->All, VersionCheck->False, BidsTractographyMethod->"Full"};

SyntaxInformation[MuscleBidsTractography] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsTractography[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsTractography[folder, GetConfig[folder], opts];


MuscleBidsTractography[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir},
	debugBids["starting MuscleBidsTractography"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsTractography[
		ConfigLookup[config, "folders", "mergeData"],(*the input folder for the data, output is in same folder*)
		ConfigLookup[config, "folders", "mergeData"],
		config["datasets"],(*what data for tractography*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsTractography[datFol_?StringQ, outFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]] := BidsFolderLoop[datFol, outFol, datDis, Method->"MuscleBidsTractography", opts]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsTractographyI*)


MuscleBidsTractographyI[{folIn_, folOut_}, {datType_, allType_}, verCheck_, met_] := Block[{
		tracto, tractType, tractSeg, tractStopLab, tractStopVal, outFile,
		tractTypeLab, fol, parts, checkFile, outfile, seed, lenS, segBone, tractSegLab,
		datfile, stopfile, tens, vox, dim, stop, ang, step, tracts, seeds, len, seg, curv,
		segfile, muscles, mlabs, mus, bones, context, leng, dens, flip, per, 
		voxs, dims, harm, tensh, con, amp, trkFileF
	}, 

	debugBids["Starting MuscleBidsTractographyI"];
	debugBids[datType];
	{fol, parts} = PartitionBidsFolderName[folIn];
	debugBids[{folIn, folOut}];
	debugBids[{fol, parts}];

	(* Extract tractography settings*)
	tracto = datType["Tractography"]; 
	If[tracto===Missing["KeyAbsent", "Tractography"],
		(*-----*)AddToLog[{"No tractography defined for this data"}, 3];
		Return[];
	];

	(* Extract tractography settings*)
	{flip, per} = ConfigLookup[datType, "Tractography", "FlipPermute"];
	len = ConfigLookup[datType, "Tractography", "TractLength"];
	ang = ConfigLookup[datType, "Tractography", "TractAngle"];
	step = ConfigLookup[datType, "Tractography", "TractStep"];
	seed = ConfigLookup[datType, "Tractography", "TractSeed"];
	lenS = ConfigLookup[datType, "Tractography", "SegmentLength"];
	segBone = ConfigLookup[datType, "Tractography", "BoneLabel"];
	harm = ConfigLookup[datType, "Tractography", "HarmonicDenoise"];

	(*tract files and nii*)
	tractType = tracto["Target"];
	tractTypeLab = StringRiffle[tractType, "_"];

	checkFile = outFile = ConvertExtension@BuildBidsNameFromConfig[{folOut, parts}, 
		{datType, allType},	Join[tractType[[;;-2]], {"trk"}]];
	datfile = BuildBidsNameFromConfig[{folOut, parts}, {datType, allType}, tractType];

	(* stopping, ensure tractStopLab and tractStopVal are lists *)
	{tractStopLab, tractStopVal} = Transpose@tracto["Stopping"];
	If[ArrayDepth[tractStopLab]===1, tractStopLab = {tractStopLab}];
	If[ArrayDepth[tractStopVal]===1, tractStopVal = {tractStopVal}];
	stopfile = BuildBidsNameFromConfig[{folOut, parts}, {datType, allType}, #]& /@ tractStopLab;

	(*optional segmentation file*)
	tractSeg = tracto["Segmentation"];
	segfile = If[!ListQ[tractSeg], "No Seg File",
		tractSegLab = StringRiffle[tractSeg, "_"];
		BuildBidsNameFromConfig[{folOut, parts}, {datType, allType}, tractSeg]];

	(* If tractography and segmentation is already done, log the event *)
	debugBids[Column@{outFile, datfile, Column@stopfile, segfile}];
	If[CheckFile[checkFile, "done", verCheck],
		(*-----*)AddToLog[{"Tractography and segmentation already done for:", tractTypeLab}, 3];
		Return[]];

	(* Check if tractography needs to be performed *)
	Which[
		CheckFile[checkFile, "track", verCheck],
		(* If tractography is already done, log the event *)
		(*-----*)AddToLog[{"Tractography already done for:", tractTypeLab}, 3];
		,
		!(met === "Full" || met==="Tractography"),
		(*-----*)AddToLog[{"Skipping tractography because of method:", met}, 3];
		,
		True,
		(* If tractography is not done, log the event and proceed with the processing*)
		(*-----*)AddToLog[{"Starting the whole volume tractography"}, 3, True];
		(*-----*)AddToLog[{"The type that will be tracted is: ", tractTypeLab}, 4];

		(* Check if the tensor file and stop files exist *)
		Which[
			!NiiFileExistQ[datfile],
			(*-----*)AddToLog[{"The tensor file does not exist", datfile}, 4];
			,
			!And@@(NiiFileExistQ/@stopfile),
			(*-----*)AddToLog[{"Not all stop files exist not exist", stopfile}, 4];
			,
			True,
			(* If all files exist, proceed with the tractography processing*)
			(*-----*)AddToLog[{"Importing the needed data"}, 4];
			{tens, vox} = ImportNii[datfile];
			tens = Transpose@ToPackedArray@N@tens;
			dim = Rest@Dimensions@tens;

			(* Import stop files *)
			stop = (
				{stop, voxs} = ImportNii[#];
				debugBids["Voxel sizes: ", {voxs, vox , Dimensions@stop}];
				If[voxs===vox, stop, PadToDimensions[RescaleData[stop, {voxs, vox}], dim]]
			)& /@ stopfile;
			debugBids["Data dimensions: ", Dimensions/@Join[stop, {tens}]];
			stop = Transpose[{stop, tractStopVal}];
			

			(* Perform tractography *)
			(*-----*)AddToLog[{"Starting the whole volume tractography"}, 4];
			{tracts, seeds} = FiberTractography[tens, vox, stop,
				InterpolationOrder -> 0, StepSize -> step, Method -> "RK4", 
				MaxSeedPoints -> If[seed<1, Scaled[seed], seed], 
				FiberLengthRange -> len, FiberAngle -> ang, TractMonitor -> False,
				TensorFlips -> flip, TensorPermutations -> per, Parallelization -> True
			];

			(* Export the tractography results *)
			(*-----*)AddToLog[{"Exporting the whole volume tractography"}, 4];
			ExportTracts[outFile<>".trk", tracts, vox, dim, seeds];

			(*perform harmonic denoising if needed*)
			Which[
				!NiiFileExistQ[segfile] && harm,
				(*-----*)AddToLog[{"The segmentation file does not exist which is needed for harmonic denoise: ", segfile}, 4];
				,
				harm,
				(*-----*)AddToLog[{"Performing harmonic tensor denoising"}, 4];
				(* get the segmentation data *)			
				{seg, voxs} = ImportNii[segfile];
				seg = RescaleSegmentation[seg, {voxs, vox}];

				{muscles, mlabs} = SelectSegmentations[seg, Range[segBone], False];
				{tensh, con, amp} = HarmonicDenoiseTensor[tens, seg, vox, mlabs, 
					MaxIterations -> 250, GradientStepSize -> {2, 1}, Monitor -> False, 
					RadialBasisKernel -> 12, Parallelize -> True,
					TensorFlips -> flip, TensorPermutations -> per
				];

				(*-----*)AddToLog[{"Starting the whole volume tractography on harmonic denoised data"}, 4];
				stop = {{Dilation[Normal@Total@Transpose@muscles, 1], {0.9, 1.1}}};
				{tracts, seeds} = FiberTractography[tensh, vox, stop,
					InterpolationOrder -> 0, StepSize -> step, Method -> "RK4", 
					MaxSeedPoints -> If[seed<1, Scaled[seed], seed], Parallelization -> True,
					FiberLengthRange -> len, FiberAngle -> ang, TractMonitor -> False
				];

				(* Export the tractography results *)
				(*-----*)AddToLog[{"Exporting the whole volume tractography"}, 4];
				(*export stuff*)
				context = Context[context];
				tensh = Transpose@tensh;
				ExportNii[ToExpression[context<>#], vox, 
					outFile<>"_"<>#<>".nii.gz", CompressNii -> compress]& /@ {"con", "amp", "tensh"};
				ExportTracts[outFile<>"_har.trk", tracts, vox, dim, seeds];
			];

			MakeCheckFile[checkFile, Sort@Join[{"Check" -> "track"}, Normal@datType]];

			(*compress the nii files if compression during ExportNii -> False*)
			If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

			(*-----*)AddToLog["Finished the tractograpy", 3, True];
		];
	];

	(* Check if segmentation needs to be performed *)
	trkFileF = If[harm, outFile<>"_har.trk", outFile<>".trk"];
	Which[
		CheckFile[checkFile, "seg", verCheck],
		(* If segmentation or tractography is already done, log the event *)
		(*-----*)AddToLog[{"Segmentation of tractography already done for:", tractSegLab}, 3];
		,
		!(met === "Full" || met==="Segmentation"),
		(*-----*)AddToLog[{"Skipping tractography segmentation because of method:", met}, 3];
		,
		True,
		(* If segmentation or tractography is not done, log the event and proceed with the processing *)
		(*-----*)AddToLog[{"Starting the tractography segmentation"}, 3, True];
		(*-----*)AddToLog[{"The tractography will be segmented using: ", tractSegLab}, 4];

		Which[
			!NiiFileExistQ[segfile],
			(*-----*)AddToLog[{"The segmentation file does not exist: ", segfile}, 4];
			,
			!FileExistsQ[trkFileF],
			(*-----*)AddToLog[{"The tracts file does not exist: ", trkFileF}, 4];
			,
			True,

			(*-----*)AddToLog[{"Importing the needed data"}, 4];
			(*import trk file if needed, if processing was done in same run this is skipped*)
			If[Dimensions[tracts] === {}, {tracts, vox, dim, seeds} = ImportTracts[trkFileF]];
			(* get the segmentation data *)			
			{seg, voxs} = ImportNii[segfile];
			{muscles, mlabs} = SelectSegmentations[seg, Range[segBone], False];
			bones = Unitize[SelectSegmentations[seg, Range[segBone + 1, segBone + 30]]];
			dims = Dimensions@seg;

			debugBids[{{dims,voxs, dims voxs}, {dim, vox, dim vox}}];

			(*-----*)AddToLog[{"Segmenting the tracts"}, 4];
			(*perform fitting and segmentations of the tracts*)
			tracts = SegmentTracts[tracts, muscles, voxs, dims, 
				FiberLengthRange -> lenS, FitTractSegments->True];

			(*-----*)AddToLog[{"Annalyzing the tracts"}, 4];
			(*Calculate tract parameters*)
			seed = SeedDensityMap[seeds, voxs, dims];
			dens = TractDensityMap[tracts, voxs, dims];
			leng = TractLengthMap[tracts, voxs, dims];
			ang = TractAngleMap[tracts, voxs, dims];
			curv = TractCurvatureMap[tracts, voxs, dims];

			(*-----*)AddToLog[{"Exporting the results and maps"}, 4];
			(*export stuff*)
			context = Context[context];
			ExportNii[ToExpression[context<>#], voxs, 
				outFile<>"_"<>#<>".nii.gz", CompressNii -> compress]& /@ {"dens", "leng", "ang", "seed","curv"};
			ExportTracts[outFile<>"_seg.trk", tracts, voxs, dims, seeds];

			(*export plot scene*)
			(*-----*)AddToLog[{"Exporting the scene"}, 4];
			Export[outFile<>"_plot.wxf",
				PlotSegmentedTracts[tracts, muscles, bones, dims, voxs, 
					OutputForm -> "All", Method -> "tube", MaxTracts -> 10000]
			];

			MakeCheckFile[checkFile, Sort@Join[{"Check"->"seg"}, Normal@datType]];

			(*compress the nii files if compression during ExportNii -> False*)
			If[!compress, CompressNiiFiles[DirectoryName[outfile]]];

			(*-----*)AddToLog["Finished the tractograpy segmentation", 3, True];
		];
	];

	If[CheckFile[checkFile, "seg", verCheck],
		MakeCheckFile[checkFile, Sort@Join[{"Check"->"done"}, Normal@datType]];

		(*compress the nii files if compression during ExportNii -> False*)
		If[!compress, CompressNiiFiles[DirectoryName[outfile]]];
	];
]


(* ::Subsection:: *)
(*7. MuscleBidsAnalysis*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsAnalysis*)


Options[MuscleBidsAnalysis] = {ProcessSubjects->All, VersionCheck->False, BidsOutputImages->"All"};

SyntaxInformation[MuscleBidsAnalysis] = {"ArgumentsPattern" -> {_, _., _., OptionsPattern[]}};

MuscleBidsAnalysis[folder_?StringQ, opts:OptionsPattern[]] := MuscleBidsAnalysis[folder, GetConfig[folder], opts];


MuscleBidsAnalysis[folder_?StringQ, config_?AssociationQ, opts:OptionsPattern[]] := Block[{dir}, 
	debugBids["starting MuscleBidsAnalysis"];
	dir = Directory[]; SetDirectory[folder];
	MuscleBidsAnalysis[
		ConfigLookup[config, "folders", "mergeData"],(*the input folder for the data*)
		ConfigLookup[config, "folders", "analysis"],(*the output folder for analsys*)
		config["analysis"],(*what data for analysis*)
		opts];
	SetDirectory[dir];	
]


MuscleBidsAnalysis[datFol_?StringQ, anFol_?StringQ, datDis_?AssociationQ, opts:OptionsPattern[]] := Block[{data, name},
	(*loop over all folders*)
	BidsFolderLoop[datFol, anFol, datDis, Method->"MuscleBidsAnalysis", opts];

	(*processing for joining all generated datafiles*)
	data = Join @@ (Import /@ Select[FileNames["*.wxf", anFol, Infinity], 
		First[StringSplit[FileBaseName[#], "_"]] =!= "All" &]);
	name = FileNameJoin[{anFol, "All_"<>DateName[]}];

	(*export to summary data file*)
	Export[name <> ".xlsx", data];
	Export[name <> ".wxf", data];
]


(* ::Subsubsection::Closed:: *)
(*MuscleBidsAnalysisI*)


MuscleBidsAnalysisI[{folIn_, folOut_}, datDis_, verCheck_, imOut_] := Block[{
		maskErosion, tractWeighting, anaSeg, fol, parts, segfile, fileName, partsO, fileNameO, checkFileX, checkFileI,
		n, what, seg, vox, vol, musNr, musName, sideName, sideNr, dataLabs, anaType, densLab, str,
		densFile, trType, trMask, segT,	datfile, data, scale, tract, outFile, meanType, hasKey,
		quantIm, segIm, tractIm, imRef, ref, crp, refC, size, pos, sliceData, make3DImage, make2DImage,
		cols, cFun, ran, clip, type, imFile, imDat, voxi, voxs, segPl, imTrk, trkfile, reffile,
		addLabel, img, lab, label
	},

	debugBids["Starting MuscleBidsAnalysisI"];
	debugBids[{folIn, folOut}];

	(*Options*)
	maskErosion = True;
	tractWeighting = False;

	(*----------- make the xls files -------------*)

	(*get the segmentation settings*)
	hasKey = KeyExistsQ[datDis, "Key"];
	{fol, parts} = PartitionBidsFolderName[folIn];
	
	partsO = If[hasKey, Join[<|"stk"->StringStrip@datDis["Key"]|>, parts], parts];
	debugBids[{parts, partsO, hasKey}];

	If[hasKey,
		(*-----*)AddToLog[{"Multiple analysis - starting:", datDis["Key"]}, 2, True];
	];

	(*file name functions*)
	fileName = If[hasKey,
		GenerateBidsFileName[fol, <|parts, "stk" -> StringStrip@#[[1]], 
			"type" -> StringStrip@#[[2]], "suf" -> #[[3;;]]|>]&,
		GenerateBidsFileName[fol, <|parts, "type" -> First[#], "suf" -> Rest[#]|>]&
	];
	fileNameO = FileNameJoin[{GenerateBidsFolderName[folOut, #], GenerateBidsName[#]}]&;

	(*checkfiles image and xls*)
	partsO["suf"] = {"xls"}; 
	checkFileX = fileNameO[partsO];
	partsO["suf"] = {"img"}; 
	checkFileI = fileNameO[partsO];

	anaSeg = datDis["Segmentation", "Type"];
	{n, what} = datDis["Segmentation", "Labels"];
	(*-----*)AddToLog[{"Segmentation file used for analysis is:", StringRiffle[StringStrip/@anaSeg, "_"]}, 3];

	(*Perform the segmentation analysis, what are the label names and volumes*)
	debugBids[{"Segmentation to xls analysis", parts}];
	segfile = fileName[anaSeg]<>".nii";

	Which[
		(*segmentation is already done*)
		CheckFile[checkFileX, "done", verCheck],
		(*-----*)AddToLog[{"Skipping: the segmentation to xls analysis is already done "}, 4],

		(*no segmentation file exists*)
		!NiiFileExistQ[segfile],
		(*-----*)AddToLog[{"The segmentation file does not exist: ", segfile}, 4],

		(*segmentation file existes perform the analysis*)
		True,
		(*-----*)AddToLog[{"Importing and processing the needed segmentation"}, 4];
		{seg, vox} = ImportNii[segfile];
		{seg, musNr} = SelectSegmentations[seg, Range[n], False];

		(*-----*)AddToLog[{"Calculating the volume of the segmentation"}, 4];
		vol = SegmentationVolume[seg, vox];

		(*switch to the correct segmentation label*)
		Switch[what,
			"Legs",
			(*-----*)AddToLog[{"Using the Legs for muscle labeling"}, 4];
			musName = MuscleLabelToName[musNr, GetAssetLocation["MusclesLegLabels"]];
			{musName, sideName} = Transpose[(str = StringSplit[#, "_"];
				If[Last[str] == "Left" || Last[str] == "Right",
					{StringRiffle[Most@str, "_"], Last@str},
					{StringRiffle[str, "_"], "Both"}
				]) & /@ musName];
			sideNr = sideName /. Thread[{"Left", "Right", "Both"} -> {1, 2, 3}];
			musNr = MuscleNameToLabel[musName, GetAssetLocation["MusclesLegAllLabels"]];
			,
			_,(*unknown label type*)
			(*-----*)AddToLog[{"Unknown Label type: ", what}, 4];
		];

		(*summarize the data labels for export later*)
		dataLabs = Join[
			Thread[{"subject", "subjectID", "session", "sessionID"} -> Transpose@ConstantArray[{
				parts["sub"], ToExpression[Last@StringCases[parts["sub"], NumberString]],
				parts["ses"], ToExpression[Last@StringCases[parts["ses"], NumberString]]}, Length[musNr]
			]],
			{"muscle"->musName, "muscleID"->musNr, "side"->sideName, "sideID"->sideNr, "volume"->vol}
		];

		(*get the labels for analysis, see if and which need to be done using tract based analysis*)
		debugBids["data analysis"];
		(*labels to be analysed*)
		anaType = datDis["Analysis", "Types"];
		anaType = Flatten[Thread /@ anaType, 1];
		(*-----*)AddToLog[{"Analsysis will be performed for:", StringRiffle[StringStrip/@#, "_"]&/@anaType}, 3];

		(*Figure out the tract analysis*)
		debugBids["tract mask"];
		If[KeyExistsQ[datDis["Analysis"], "TractBased"],
			densLab = {If[hasKey, StringStrip@datDis["Analysis", "TractBased"][[1,1]], Nothing], "dwi", "dti", "trk", "dens"};
			densFile = fileName[densLab]<>".nii";
			trType = Flatten[Thread /@ datDis["Analysis", "TractBased"], 1];
			trType = Select[trType, MemberQ[anaType, #] &];
			(*-----*)AddToLog[{"The types with tract weighting will be:", StringRiffle[StringStrip/@#, "_"]&/@trType}, 3];
			(*-----*)AddToLog[{"Import tract mask:", StringRiffle[densLab, "_"]}, 4];
			trMask = ImportNii[densFile][[1]];
			trMask = If[tractWeighting, trMask, Unitize@trMask];
			,
			(*-----*)AddToLog[{"No tract bases analysis given"}, 4];
			trMask = 1;
		];

		(*perform the actual data analysis *)
		(*-----*)AddToLog[{"Starting the data analysis:"}, 3, True];
		debugBids[{"tract mask", Dimensions@seg, Dimensions@trMask}];
		(*make the correcet masks*)
		If[maskErosion,	seg = DilateMask[seg, -1]];
		segT = If[trMask=!=1, MaskSegmentation[seg, trMask], seg];

		(*loop over all datatypes and perform the mask analysis*)
		data = Flatten[Table[
			datfile = fileName[datType]<>".nii";
			Which[
				(*data does not exist so skip*)
				!NiiFileExistQ[datfile],
				(*-----*)AddToLog[{"The data does not exist: ", StringRiffle[datType, "_"]}, 4],

				(*data exists so perform the analysis*)
				True,
				debugBids[datType];
				{data, vox} = ImportNii[datfile];

				(*figure out how to handle this type *)
				tract = MemberQ[trType, datType];
				scale = Switch[datType[[-2;;]], {"dix", "fatfr"} | {"t2", "fatfr"}, 100, {"dix", "t2star"}, 1000, _, 1];
				meanType = (datType[[-2;;]] === {"trk", "seed"} || datType[[-2;;]] === {"trk", "dens"});
				(*-----*)AddToLog[{"Processing file "<>If[tract, "with", "without"]<>" tract weighting:", StringRiffle[StringStrip@datType, "_"]}, 4];

				(*mask based analysis*)
				label = StringRiffle[datType[[-2;;]], "_"];
				Thread[{label, label<>"_IQR"} -> Transpose[scale GetMaskData[data, If[tract, segT, seg], 
					GetMaskOutput -> If[meanType, "MeanSTD", "MedianIQR"],
					GetMaskOnly -> If[meanType, True, False]
				]]]
			]
		, {datType, anaType}], 1];

		(*merge the data and export*)
		partsO["suf"] = {};
		outFile = fileNameO[partsO];
		debugBids[{"exporting", outFile}];
		(*-----*)AddToLog[{"Data will be exported to:", DirectoryName@outFile}, 3, True];
		data = Dataset[Association /@ Transpose[Thread[#] & /@ Join[dataLabs, data]]];
		Export[outFile<>".xlsx", data];
		Export[outFile<>".wxf", data];

		MakeCheckFile[checkFileX, Sort@Join[{"Check"->"done"}, Normal@datDis]];

		(*compress the nii files if compression during ExportNii -> False*)
		If[!compress, CompressNiiFiles[DirectoryName[outfile]]];
	];

	(*----------- make the images -------------*)

	(*figure out which images to make based on setting*)
	{quantIm, segIm, tractIm} = Switch[imOut, 
		"All", {True, True, True},
		"Quantitative", {True, False, False},
		"Segmentation", {False, True, False},
		"Tractography", {False, False, True},
		_, {False, False, False}
	];
	debugBids[{"Image Analysis", {quantIm, segIm, tractIm}}];

	(*make images if needed*)
	Which[
		(*segmentation is already done*)
		CheckFile[checkFileI, "done", verCheck],
		(*-----*)AddToLog[{"Skipping: the iamges are already done"}, 4],

		(*No images need to be made*)
		!AnyTrue[{quantIm, segIm, tractIm}, # &],
		(*-----*)AddToLog[{"No images will be made since option is set to None:"}, 3],

		(*making the images*)
		True,
		(*-----*)AddToLog[{"Starting making the images:"}, 3];

		(*get the reference file and figure out image slice posisions*)
		imRef = datDis["Images", "Reference"];
		(*-----*)AddToLog[{"Checking the reference file for 2D images: ", StringRiffle[imRef, "_"]}, 4];
		reffile = fileName[imRef]<>".nii";
		debugBids[{reffile, NiiFileExistQ[reffile]}];

		(*quantIm and SegIm need refffile, check if there to get needed information.*)
		If[!NiiFileExistQ[reffile],
			(*-----*)AddToLog[{"No reference file skipping 2D quant and seg images."}, 4]; 
			quantIm = segIm = False;
			,
			(*get the ref data for the slice posisions and background of seg images*)
			{ref, vox} = ImportNii[reffile];
			crp = FindCrop[ref, CropPadding -> 10];
			refC = ApplyCrop[ref, crp];
			size = Dimensions[refC] vox;

			pos = GetSlicePositions[GaussianFilter[refC, 15], vox, MakeCheckPlot -> False, 
				DropSlices -> {1, 1, 1}, PeakNumber -> {0, 1, 2}];
			pos[[1]] = Reverse[Range[0., 1., 1/(Ceiling[Divide @@ size[[;; 2]]] + 1)][[2 ;; -2]] size[[1]]];

			(*Function to extract slice data for 2D images*)
			sliceData = Block[{slDat},
				slDat = GetSliceData[ApplyCrop[#, crp, {vox, voxi}], pos, voxi];
				{slDat[[1]], {slDat[[3, 1]], slDat[[2, 1]], Reverse[slDat[[3, 2]], 2]}, {}}
			] &;
		];

		(*3D image function needed for segmentation and tractography*)
		make3DImage = With[{gc = #, sc = 0.75}, 
			ImageResize[ImagePad[ImageCrop@Image[Graphics3D[Table[
				Translate[Rotate[(First@gc), -i 90 Degree, {0, 0, 1}, 0.5 Options[gc, PlotRange][[1, 2, All, 2]]], 
					{sc i Options[gc, PlotRange][[1, 2, 1, 2]], 0, 0}], 
				{i, 0, 3}], Background -> Lighter@Gray, ViewPoint -> {0, -2, .1}, ##] & @@ Join[{
					BoxRatios -> {sc 4, 1, 1} Options[gc, BoxRatios][[1, 2]], 
					PlotRange -> {sc 4, 1, 1} Options[gc, PlotRange][[1, 2]], 
					Options@gc
					}], ImageSize -> {Automatic, 2400}, ImageResolution -> 300], 
			{{60, 60}, {60, 60}}, Lighter@Gray], {Automatic, 2000}]
		]&;

		(*2D image function*)
		make2DImage = With[{di = Max[ImageDimensions[#][[2]]&/@#[[2]]]/4},
		ImagePad[ImageAssemble[ImageResize[#, {Automatic, di}] & /@ Join[
			{ImageAssemble[Transpose@{ImagePad[#, -5] & /@ #[[1]]}, Spacings -> 20, Background -> White]},
			ImagePad[#, -5] & /@ #[[2]]], Spacings -> 20, Background -> White, 
			ImageResolution -> 300], 20, White
		]]&;

		addLabel = ImageAssemble[{
			{ImageCrop[#2, ImageDimensions[#2] - {0, 20}, {Left, Bottom}]}, 
			{LegendImage[#1, First[ImageDimensions@#2], #3]}}
		]&;

		(*------------ quantiatavite images ------------*)

		If[!quantIm,
			(*-----*)AddToLog[{"Not making Quant images since setting is False."}, 4],
			(*-----*)AddToLog[{"Start making Quant images:"}, 4]; 

			debugBids["Making quantitative map images:"];
			Table[
				(*get the color and styling function for the image*)
				cols = Rest@im;
				{cFun, ran, lab} = Switch[Length@cols,
					0, {"BlackToWhite", Automatic, None},
					1, {cols[[1]], Automatic, None},
					2, {cols[[1]], cols[[2]], None},
					3, cols];
				clip = If[cFun === "BlackToWhite", Automatic, Black];

				(*get the filenames for import and export*)
				type = First@im;				
				imFile = fileName[type]<>".nii";
				partsO["suf"] = If[hasKey, type[[2;;]], type];

				(*check if the data file exist*)				
				If[!NiiFileExistQ[imFile],
					(*-----*)AddToLog[{"Cant make image for because data does not exist: ", StringRiffle[StringStrip/@type, "_"]}, 5],
					(*-----*)AddToLog[{"Making image for: ", StringRiffle[type, "_"]}, 5];

					(*import data and make image and export*)
					{imDat, voxi} = ImportNii[imFile];
					img = make2DImage@MakeSliceImages[sliceData@imDat, voxi, 
							ColorFunction -> cFun, PlotRange -> ran, ClippingStyle -> clip, ImageSize -> 2400];
					img = If[lab =!= None, addLabel[cFun, img, lab], img];
					Export[fileNameO[partsO]<>".jpg", img, ImageResolution -> 300];
				]
			, {im, datDis["Images", "QuantImages"]}];
		];

		(*------------ segmentation images ------------*)

		(*check if segmentation can be done*)
		debugBids[{segfile, NiiFileExistQ[segfile]}];
		If[!NiiFileExistQ[segfile], 
			(*-----*)AddToLog[{"Segmentation file does not exist."}, 4];
			segIm = False
		];

		If[!segIm,
			(*-----*)AddToLog[{"Not making Segment images since setting is False."}, 4],
			(*-----*)AddToLog[{"Start making segmentation images:"}, 4]; 
			debugBids["Making segment images:"];

			(*import the segmation*)
			{seg, voxi} = ImportNii[segfile];

			(*make the 2D segmentation image*)
			(*-----*)AddToLog[{"Making 2D Segment image"}, 5]; 
			partsO["suf"] = If[hasKey, anaSeg[[2;;4]], anaSeg[[;;3]] ];
			Export[fileNameO[partsO]<>".jpg", 
				make2DImage@MakeSliceImages[sliceData@ref, {sliceData@seg, GetSegmentationLabels[seg]}, vox,
					ColorFunction -> {"BlackToWhite","RomaO"}, PlotRange -> Automatic, ClippingStyle -> Automatic, ImageSize -> 2400]
			, ImageResolution -> 300];

			(*make the 3D segmentation image*)
			(*-----*)AddToLog[{"Making 3D Segment image"}, 5];
			partsO["suf"] = Join[partsO["suf"], {"vol"}];
			segPl = PlotSegmentations[SelectSegmentations[seg, Range[n]], SelectSegmentations[seg, Range[n+1, n+30]], 
				voxi, ContourResolution -> 2 voxi];
			Export[fileNameO[partsO]<>".jpg", make3DImage@segPl, ImageResolution -> 300];

			(*make the grid segmentation image*)
			(*-----*)AddToLog[{"Making 2D Segment grid image"}, 5];
			partsO["suf"] = If[hasKey, anaSeg[[2;;4]], anaSeg[[;;3]] ];
			partsO["suf"] = Join[partsO["suf"], {"grid"}];
			{ref, crp} = AutoCropData[ref];
			{segPl, lab} = SplitSegmentations[ApplyCrop[seg, crp]];
			SeedRandom[12345];
			segPl = MergeSegmentations[segPl, Join[RandomSample[Select[lab, # <= n &]], Select[lab, # > n &]]];
			Export[fileNameO[partsO]<>".jpg", 
				MakeChannelClassGrid[{ref}, segPl,
					Which[Length[ref] > 32, {4, 8}, Length[ref] > 18, {3, 6}, Length[ref] > 8, {2, 4}, True, {1, 3}]
				]
			, ImageResolution -> 300, ImageSize->{Automatic, 2000}];
		];

		(*------------ tractography images ------------*)

		(*check if tract image can be done*)
		imTrk = datDis["Images", "TractImages"];
		trkfile = fileName[imTrk]<>".wxf";
		debugBids[{trkfile, FileExistsQ[trkfile]}];
		If[!FileExistsQ[trkfile], 
			(*-----*)AddToLog[{"Tract file does not exist."}, 4];
			tractIm = False;
		];

		If[!tractIm,
			(*-----*)AddToLog[{"Not making Tract images since setting is False."}, 4],
			(*-----*)AddToLog[{"Start making tractography images:"}, 4]; 

			(*import the tractography, make the image and export*)
			(*-----*)AddToLog[{"Making 3D tract image"}, 5];
			debugBids["Making tract images:"];
			partsO["suf"] = Join[If[hasKey, imTrk[[2;;4]], imTrk[[;;3]]], {"vol"}];
			Export[fileNameO[partsO]<>".jpg", make3DImage@Import@trkfile, ImageResolution -> 300];
		];

		(*finalize image making*)
		(*-----*)AddToLog[{"Finished making the images"}, 3, True];
		MakeCheckFile[checkFileI, Sort@Join[{"Check"->"done"}, Normal@datDis]];

		(*compress the nii files if compression during ExportNii -> False*)
		If[!compress, CompressNiiFiles[DirectoryName[outfile]]];
	]
];


(* ::Section:: *)
(*End Package*)


End[]

EndPackage[]
