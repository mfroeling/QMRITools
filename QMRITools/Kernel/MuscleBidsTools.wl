(* ::Package:: *)

(* ::Title:: *)
(*QMRITools MuscleBidsTools*)


(* ::Subtitle:: *)
(*Written by: Martijn Froeling, PhD*)
(*m.froeling@gmail.com*)


(* ::Section:: *)
(*Begin Package*)


BeginPackage["QMRITools`MuscleBidsTools`", Join[{"Developer`"}, Complement[QMRITools`$Contexts, {"QMRITools`MuscleBidsTools`"}]]];


(* ::Section:: *)
(*Usage Notes*)


(* ::Subsection:: *)
(*Functions*)


ImportJSON::usage = 
"ImportJSON[file] impors a json file as rawJSON."

GetJSONPosition::usage = 
"GetJSONPosition[{json..}, {{key, value}..}] gets the position from a list of JSON association lists where keys have the given value.
GetJSONPosition[{json..}, {{key, value}..}, sortkey] same but finaly sorts the positions for the value of the sortkey."

MergeJSON::usage = 
"MergeJSON[{json..}] merges a list of JSON association lists where duplicate keys with same values are removed and duplicate keys with different values are merges."

AddToJson::usage = 
"AddToJson[json, <|key->value..|>] adds new keys and values to the JSON list where duplicte keys are eitehr removed or joined.
AddToJson[json, \"QMRITools\"] adds the QMRITools software version to the json."

ExtractFromJSON::usage = 
"ExtractFromJSON[keys] if the keys exist they are extracted from the json."


PartitionBidsName::usage = 
"PartitionBidsName[name] converts a Bids name to the a Bids labels as an association, i.e. {\"sub\",\"ses\",\"stk\",\"rep\",\"type\",\"suf\"}."

PartitionBidsFolderName::usage = 
"PartitionBidsFolderName[fol] partitions the Bids folder and file name. it retruns the bids root folder and the label parts using PartitionBidsName."

GenerateBidsName::usage = 
"GenerateBidsName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName."

GenerateBidsFolderName::usage = 
"GenerateBidsFolderName[parts] generates a Bids folder name from the Bids labels association which can be generated by PartitionBidsFolderName."

GenerateBidsFileName::usage = 
"GenerateBidsFileName[parts] generates a Bids file name from the Bids labels association which can be generated by PartitionBidsName.
GenerateBidsFileName[fol, parts] the same but with a custom root folder."

SelectBidsFolders::usage =
"SelectBidsFolders[fol, tag] Selects all folders in the fol with the name tag."

SelectBidsSubjects::usage =
"SelectBidsSubjects[fol] selects all subjects in the bids folder"

SelectBidsSessions::usage =
"SelectBidsSessions[fol] selects all sessions in the bids subject folder"


BidsDcmToNii::usage =
"BidsDcmToNii[sourceFolder, rawFolder] converts the bids sourceFolder with dicom files to raw nii files save in the rawFolder. The conversion directory is the current working Directory.
BidsDcmToNii[fol, sourceFolder, rawFolder] the same but the conversion directory is fol."


MuscleBidsConvert::usage =
"MuscleBidsConvert[niiFol, discription] converts all nii data in the niiFol subfolder \"raw\" to Muscle-Bids based on the data discription.

Example discription:
{\"Label\" -> \"DIXON\", \"Type\" -> \"megre\", \"Class\" -> \"Stacks\", \"Overlap\" -> 5}
{\"Label\" -> \"DIXON\", \"Type\" -> \"megre\", \"Class\" -> \"Stacks\"}
{\"Label\" -> \"DTI\", \"Type\" -> \"dwi\", \"Class\" -> \"Stacks\", \"Overlap\" -> 5, \"Suffix\" -> \"dti\"}
{\"Label\" -> \"DIXON\", \"Type\" -> \"megre\"}."


MuscleBidsProcess::usage = 
"MuscleBidsProcess[niiFol, discription]"


CheckDataDiscription::usage =
"CheckDataDiscription[discription] checks the data discription used in MuscleBidsConvert. For example {\"Label\"->\"DTI\",\"Type\"->\"dwi\",\"Class\"->\"Stacks\",\"Overlap\"->5,\"Suffix\"->\"dti\"},"


(* ::Subsection:: *)
(*Options*)


BidsIncludeSession::usage = 
"BidsIncludeSession is an option for BidsDcmToNii. If True session folders will be used in output even if they are not specified."


DeleteAfterConversion::usage = 
"DeleteAfterConversion is an option for MuscleBidsConvert. If set True all files that have been converted will be deleted."

SelectSubjects::usage = 
"SelectSubjects is an option for MuscleBidsConvert. Can be a list of bids subject names else it is All"


VersionCheck::usage = 
"VersionCheck is an option for MuscleBidsProcess. If set True data processed with an old version is reprocessed."


(* ::Subsection:: *)
(*Error Messages*)


Bids::type = "Unknown Muscle-BIDS type: `1`, using folder \"miss\".";

Bids::class = "Unknown Muscle-BIDS Class: `1`. Must be \"Volume\", \"Stacks\", \"Repetitions\".";

Bids::lab = "Invalid combination of Class and Label: `1` with `2` is not allowed.";

Bids::man = "Manditory values \"Lable\" and \"Type\" are not in the data discription.";

Bids::stk = "Class \"stacks\" is used but overlap is not defined, assuming overlap 0.";


(* ::Section:: *)
(*Functions*)


Begin["`Private`"] 


(* ::Subsection:: *)
(*BIDS name and select*)


(* ::Subsubsection::Closed:: *)
(*General Definitions*)


bidsTypes = <|
	(*anata types*)
	"T1w"->"anat", "T1w-FS"->"anat", "T2w"->"anat", "T2w-FS"->"anat",
	(*dixon*)
	"megre"->"dix", "mese"->"quant",
	(*quant types*)
	"T1"->"quant", "T2"->"quant", "wT2"->"quant",
	(*diff types*)
	"dwi"->"dwi"
|>;


bidsName = {"sub", "ses", "stk", "rep", "Type", "suf"};


bidsClass = {"Volume", "Stacks", "Repetitions"};


dataToLog =If[KeyExistsQ[#, $Failed], 
	"Wrong data dicription: " <> #[$Failed], 
	StringJoin[ToString[#[[1]]] <> ": " <> ToString[#[[2]]] <> "; " & /@ Normal[#]]
]&;


(* ::Subsubsection::Closed:: *)
(*PartitionBidsName*)


SyntaxInformation[PartitionBidsName] = {"ArgumentsPattern" -> {_}};

PartitionBidsName[list_?ListQ]:=PartitionBidsName/@list

PartitionBidsName[string_?StringQ]:=Block[{parts,labs,suf},
	parts=StringSplit[#,"-"]&/@StringSplit[string,"_"];
	labs=Rule@@#&/@Select[parts,Length[#]===2&];
	suf=Flatten[Select[parts,Length[#]=!=2&]];
	suf=If[suf=!={},If[MemberQ[Keys[bidsTypes],First@suf],{"Type"->First@suf,"suf"->Rest@suf},{"suf"->suf}],{"suf"->{}}];
	Association[Join[labs,suf]]
] 


(* ::Subsubsection::Closed:: *)
(*PartitionBidsFolderName*)


SyntaxInformation[PartitionBidsFolderName] = {"ArgumentsPattern" -> {_}};

PartitionBidsFolderName[fol_?ListQ]:=PartitionBidsFolderName/@fol

PartitionBidsFolderName[fol_?StringQ]:={
	First@StringSplit[fol,"sub-"],PartitionBidsName@StringJoin@Riffle[Select[FileNameSplit[fol],StringContainsQ[#,"-"]&],"_"]
} 


(* ::Subsubsection::Closed:: *)
(*GenerateBidsName*)


SyntaxInformation[GenerateBidsName] = {"ArgumentsPattern" -> {_}};

GenerateBidsName[list_?ListQ]:=GenerateBidsName/@list

GenerateBidsName[parts_?AssociationQ]:=StringJoin[Riffle[Select[Join[
	BidsString[parts,{"sub", "ses", "stk", "rep"}],BidsValue[parts,{"Type", "suf"}
]],#=!=""&],"_"]]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFolderName*)


SyntaxInformation[GenerateBidsFolderName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFolderName[fol_?StringQ, list_?ListQ]:=GenerateBidsFolderName[fol,#]&/@list

GenerateBidsFolderName[fol_?StringQ, parts_?AssociationQ]:=FileNameJoin[Select[{
	fol, BidsString[parts, "sub"], BidsString[parts, "ses"]
},#1=!=""&]]


(* ::Subsubsection::Closed:: *)
(*GenerateBidsFileName*)


SyntaxInformation[GenerateBidsFileName] = {"ArgumentsPattern" -> {_, _.}};

GenerateBidsFileName[list_?ListQ]:=GenerateBidsFileName["",#]&/@list

GenerateBidsFileName[fol_?StringQ, list_?ListQ]:=GenerateBidsFileName[fol,#]&/@list

GenerateBidsFileName[parts_?AssociationQ]:=GenerateBidsFileName["",parts]

GenerateBidsFileName[fol_?StringQ, parts_?AssociationQ]:=FileNameJoin[Select[{
	fol, BidsString[parts, "sub"], BidsString[parts, "ses"], BidsType[parts], GenerateBidsName[parts]
},#1=!=""&]]


(* ::Subsubsection::Closed:: *)
(*SelectBidsFolders*)


SyntaxInformation[SelectBidsFolders] = {"ArgumentsPattern" -> {_, _}};

SelectBidsFolders[fol_?ListQ, tag_] := Flatten[SelectBidsFolders[#, tag] & /@ fol]
SelectBidsFolders[fol_?StringQ, tag_] := Block[{folSel, done, cont},
	folSel = Select[FileNames[All, fol], (DirectoryQ[#] && (FileBaseName[#] === tag || StringTake[FileBaseName[#], 3] === "sub" || StringTake[FileBaseName[#], 3] === "ses")) &];
	done = Select[folSel, FileBaseName[#] === tag &];
	cont = Complement[folSel, done];
	Flatten[{done, If[cont =!= {}, SelectBidsFolders[cont, tag], Nothing]}]
]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSubjects*)


SyntaxInformation[SelectBidsSubjects] = {"ArgumentsPattern" -> {_}};

SelectBidsSubjects[fol_] := Select[FileNames[All, fol], (DirectoryQ[#] && StringTake[FileNameTake[#], 3] === "sub") &]


(* ::Subsubsection::Closed:: *)
(*SelectBidsSessions*)


SyntaxInformation[SelectBidsSessions] = {"ArgumentsPattern" -> {_}};

SelectBidsSessions[fol_?ListQ]:=Flatten[SelectBidsSessions/@fol]

SelectBidsSessions[fol_?StringQ] := Select[FileNames[All, fol], (DirectoryQ[#] && StringTake[FileNameTake[#], 3] === "ses") &]


(* ::Subsubsection::Closed:: *)
(*BidsType*)


BidsType[type_?StringQ]:= bidsTypes[type] /. {Missing[___]->"miss"} 

BidsType[parts_?AssociationQ]:= bidsTypes[parts["Type"]] /. {Missing[___]->"miss"} 


(* ::Subsubsection::Closed:: *)
(*BidsValue*)


BidsValue[parts_,val_?ListQ]:=Flatten[BidsValue[parts,#]&/@val]

BidsValue[parts_,val_?StringQ]:=parts[val] /. {Missing[___]->""} 


(* ::Subsubsection::Closed:: *)
(*CheckBidsTypes*)


CheckBidsTypes[type_]:=If[!MemberQ[Drop[Keys[bidsTypes],-1], type], Message[Bids::type,type]]


(* ::Subsubsection::Closed:: *)
(*BidsString*)


BidsString[parts_, val_?ListQ]:=BidsString[parts,#]&/@val

BidsString[parts_, val_?StringQ]:=Block[{str},
	str = BidsValue[parts, val];
	If[str==="", "", val<>"-"<>str]
]


(* ::Subsection::Closed:: *)
(*BidsDcmToNii*)


Options[BidsDcmToNii]={BidsIncludeSession->True}

SyntaxInformation[BidsDcmToNii] = {"ArgumentsPattern" -> {_, _, _., OptionsPattern[]}};

BidsDcmToNii[dcmFol_,niiFol_,opts:OptionsPattern[]]:=BidsDcmToNii[Directory[],dcmFol,niiFol,opts]
 
BidsDcmToNii[loc_,dcmFol_,niiFol_,OptionsPattern[]]:=Block[{logFile,fols,folsi,foli,keys,name,ses,bidsname,out},
	(*start logging*)
	ResetLog[];
	ShowLog[];
	logFile=FileNameJoin[{niiFol,"DcmToNii_"<>StringReplace[DateString[{"Day", "Month", "YearShort", "-", "Time"}],":"->""]<>".log"}];
	
	(*find all foders that need to be converted*)
	fols=FileNameJoin[{loc, #}]&/@Select[FileNames[All,dcmFol],DirectoryQ];
	
	(*loop over all dcm folders*)
	Table[
		(*----*)AddToLog[{"Converting: ",folsi},True,0];
		(*----*)AddToLog["Using Chris Rorden's dcm2niix.exe (https://github.com/rordenlab/dcm2niix)",0];
		
		(*get the names*)
		foli=PartitionBidsName[FileBaseName[folsi]];
		keys=Keys[foli];
		
		(*if bids take sub key else assume first suf is name*)
		name="sub"->If[MemberQ[keys,"sub"],foli["sub"],First[foli["suf"]]];
		
		(*if bids take ses key else assume last suf is session*)
		ses="ses"->If[MemberQ[keys,"ses"],
			(*session is present take session*)
			First[foli["ses"]],
			(*more than one suf last is session*)
			If[Length[foli["suf"]]>1,Last[foli["suf"]],
				(*no session, see if need to be forced*)
				If[OptionValue[BidsIncludeSession],"001", ""]
			]
		];
		(*create the output with the bidsname to which all is exported*)
		bidsname=GenerateBidsFileName[Association[{name,ses}]];
		out=FileNameJoin[{StringReplace[DirectoryName[folsi],{dcmFol->niiFol}],DirectoryName[DirectoryName[bidsname]],"raw"}];
		(*----*)AddToLog[{"Output folder: ",out},1];
		Quiet[CreateDirectory[out]];
		
		(*perform the conversions only when output folder is empty*)
		If[EmptyDirectoryQ[out],
			DcmToNii[{folsi,out}];
			(*----*)AddToLog["Folder was converted",1],
			(*----*)AddToLog["Folder was skipped since output folder already exists",1];
		];
		
	(*Close loop over folders*)	
	,{folsi,fols}];
	
	(*export the log file*)
	ExportLog[logFile, True];
]


(* ::Subsection:: *)
(*BidsSupport*)


(* ::Subsubsection::Closed:: *)
(*BidsFolderLoop*)


Options[BidsFolderLoop] = {DeleteAfterConversion->False, SelectSubjects->All, Method->"Convert", VersionCheck->False};

SyntaxInformation[BidsFolderLoop] = {"ArgumentsPattern" -> {_, _, OptionsPattern[]}};

BidsFolderLoop[inFol_?StringQ, datDis_?ListQ, ops:OptionsPattern[]]:=BidsFolderLoop[inFol, inFol, datDis, ops]

BidsFolderLoop[inFol_?StringQ, outFol_?StringQ, datDis_?ListQ, ops:OptionsPattern[]]:=Block[{
		met, datType, fols, subs, logFile, nam, filesSl, jsons, files, nTyp, pat, rfol
	},
	
	(*see which method*)
	met = OptionValue[Method];
	(*slect the subjects to be processed*)
	fols = SelectBidsSessions[SelectBidsSubjects[inFol]];
	subs = OptionValue[SelectSubjects];
	subs = If[subs===All, fols, Select[fols, MemberQ[subs, PartitionBidsFolderName[#][[-1]]["sub"]]&]];
	
	(*convert the nameType to valid input, will always be a list of associations*)
	datType = CheckDataDiscription[datDis, met];
	
	(*open log*)
	ShowLog[];
	
	(*loop over the subjects*)
	Table[
		nam = GenerateBidsName[PartitionBidsFolderName[fol][[-1]]];
		(*start method specific logging*)
		Switch[met,
			logFile = FileNameJoin[{fol, nam<>"_BIDSConvert.log"}];
			ImportLog[logFile];
			"Convert", (*MuscleBidsConvert*)
			(*----*)AddToLog[{"Starting bids conversion for directory: ", fol}, True, 0];
			(*----*)AddToLog["Perform conversion for: ",1],
			"Process", (*MuscleBidsProcess*)
			logFile = FileNameJoin[{GenerateBidsFolderName[outFol, Last[PartitionBidsFolderName[fol]]], nam<>"_BIDSProcess.log"}];
			ImportLog[logFile];
			(*----*)AddToLog[{"Starting bids processing for directory: ", fol}, True, 0],
			"Merge",
			""
		];
		
		(*loop over the datType*)
		Table[
			(*check if datType is valid*)
			If[KeyExistsQ[type, $Failed],
				(*----*)AddToLog[dataToLog@type, 2, True];
				(*----*)AddToLog["Skipping", 3],
				(*if valid perform conversion*)
				(*----*)AddToLog[dataToLog@type, 2, True];
				rfol = SelectBidsFolders[fol, type["InFolder"]];
				
				(*loop over all inFolders in subject folder*)
				Table[
					(*----*)AddToLog[{"Finding all JSON files in the directory", foli}, 2];
					files = FileNames["*.json", foli];
					(*----*)AddToLog[{"There were", Length[files], " JSON files found"}, 3];
					
					(*method specific scripts*)
					Switch[met,
						"Convert", (*MuscleBidsConvert*)
						MuscleBidsConvertI[foli, type, logFile, OptionValue[DeleteAfterConversion]]
						,
						"Process", (*MuscleBidsProcess*)
						MuscleBidsProcessI[foli, outFol, type, logFile, OptionValue[VersionCheck]]
						,
						"Merge",
						""
					];
					
					ExportLog[logFile];				
				(*Close sub folders loop*)
				, {foli, rfol}];		
			];
			
			ExportLog[logFile];	
		(*close datatype loop*)
		, {type, datType}];
		
		(*export the log files*)
		ExportLog[logFile, True];
	(*close subject loop*)
	, {fol, subs}];
] 


(* ::Subsubsection::Closed:: *)
(*CheckDataDiscription*)


SyntaxInformation[CheckDataDiscription] = {"ArgumentsPattern" -> {_, _}};

CheckDataDiscription[dis:{_List..}, met_]:= Flatten[CheckDataDiscription[#, met]&/@dis]

CheckDataDiscription[dis:{_Rule..}, met_]:=Block[{ass, key, man, cls, typ, fail},
	(*Get the data discription keys*)
	ass = Association[dis];
	key = Keys[ass];
	
	(*fail output*)
	fail = Association[$Failed->ToString[Normal[ass]]];
	
	(*Check if manditory keys are present*)
	man = ContainsAll[key, Switch[met,
		"Convert", {"Label", "Type"},
		"Process", {"Type"}
	]];
	
	If[!man,
		Return[Message[Bids::man]; fail],
		
		(*Check if type is valid*)
		If[!MemberQ[Keys[bidsTypes], ass["Type"]], Message[Bids::type, ass["Type"]]];
		
		(*Check if class is present*)
		If[KeyExistsQ[ass, "Class"],
			(*if present add check class is valid*)
			If[!MemberQ[bidsClass, ass["Class"]], Return[Message[Bids::class,ass["Class"]]; fail]],
			(*add class if not present*)
			ass = Association[ass, "Class"->"Volume"]
		];
		
		(*check if labels match class*)
		cls = Switch[ass["Class"],
			"Volume", StringQ[ass[["Label"]]],
			"Stacks"|"Repetitions", ListQ[ass["Label"] && Length[ass]>1]
		];
		If[!cls, Return[Message[Bids::lab, ass["Class"], ass["Label"]]; fail]];
		
		(*check suffic, in and out folder*)
		If[!KeyExistsQ[ass, "Suffix"], ass = Association[ass, "Suffix"->""]];
		Switch[met,
			"Convert",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->"raw"]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];
			,
			"Process",
			If[!KeyExistsQ[ass, "InFolder"], ass = Association[ass, "InFolder"->BidsType[ass["Type"]]]];
			ass = Association[ass, "OutFolder" -> BidsType[ass["Type"]]];
		];
		
		(*add overlap if class is stacks*)
		If[ass["Class"]==="Stacks"&&!KeyExistsQ[ass,"Overlap"], Message[Bids::stk]; ass = Association[ass, "Overlap"->0]];
		
		(*output the completed data discription*)
		{KeySort@ass}
	]
]


(* ::Subsection:: *)
(*MuscleBidsConvert*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsConvert*)


Options[MuscleBidsConvert] = {DeleteAfterConversion->False, SelectSubjects->All};

SyntaxInformation[MuscleBidsConvert] = {"ArgumentsPattern" -> {_, _, OptionsPattern[]}};

MuscleBidsConvert[niiFol_?StringQ, datDis_, ops:OptionsPattern[]]:= BidsFolderLoop[niiFol, datDis, Method->"Convert", ops]


(* ::Subsubsection:: *)
(*MuscleBidsConvertI*)


MuscleBidsConvertI[foli_, datType_, logFile_, del_]:=Block[{
		type, fol, parts, files, json, infoExtra, pos, posi, info, data, vox, grad, val, sufd, outFile
	},
	
	(*see if one label or session|repetion*)
	{fol, parts} = PartitionBidsFolderName[foli];
	type = datType["Type"];
	
	(*-----*)AddToLog[{"Processing", ToString[Length[datType["Label"]]], datType["Class"]}, 2, True];
	(*-----*)AddToLog[StringJoin@@Riffle[datType["Label"],", "], 3];
	
	(*loop over stac names*)
	Table[
		(*import the json belonging to name*)
		(*-----*)AddToLog[{"Processing", namei, "as", type,":"}, True, 3];
		files = FileNames["*"<>namei<>"*.json", foli];
		json = ImportJSON/@files;
		
		(*see which data type is expected*)
		Switch[datType["Type"],
		
			(*-------------------------------------------*)
			(*-------- DIXON conversion script ----------*)
			(*-------------------------------------------*)
			"megre",
			
			(*loop over dixon data types*)
			Table[
				(*get the posisiton of the files needed*)
				pos = GetJSONPosition[json, {{"SeriesDescription", namei}, {"ImageType", dixType}}, "EchoNumber"];
				(*-----*)AddToLog[{"Importing", Length[pos], "datasets with properties: ", {namei, dixType}}, 4];
				
				(*get the json and data*)
				info = MergeJSON[json[[pos]]];
				{data, vox} = Transpose[ImportNii[#]&/@ConvertExtension[files[[pos]], ".nii"]];
				data = Transpose[data];
				vox = First@vox;
				(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
				
				(*correct data for different types*)
				{data,sufd}=Switch[dixType,
					"Mixed",{1000.data/2047.,""},
					"Phase",{Pi (data-2047.)/2047,"ph"},
					"Real",{1000.(data-2047.)/2047.,"real"},
					"Imaginary",{1000.(data-2047.)/2047.,"imag"}
				];
				
				(*make the additional manditory bids json values*)
				infoExtra=<|
					"ForthDimension"->"EchoTime",
					"DataClass"->datType["Class"],
					If[datType["Class"]==="Repetitions", "Repetition"->namei, Nothing],
					If[datType["Class"]==="Stacks", "Stack"->namei, Nothing],
					If[datType["Class"]==="Stacks", "OverLap"->datType["Overlap"], Nothing]
				|>;
				
				(*export to the correct folder*)
				outFile = GenerateBidsFileName[fol, <|parts, "Type"->type, GetStackName[datType["Class"], namei], "suf"->Flatten@{datType["Suffix"], sufd}|>];
				(*-----*)AddToLog[{"Exporting to file:", outFile}, 4];
				ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
				Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];
				
				(*Delete used files*)
				Quiet@If[del,
					DeleteFile[ConvertExtension[files[[pos]],".nii"]];
					DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
					DeleteFile[ConvertExtension[files[[pos]],".json"]]
				];
				
				(*export log after each type*)
				ExportLog[logFile]			
			(*Closeloop over dixon data types*)
			,{dixType, {"Mixed", "Phase", "Real", "Imaginary"}}],
			
			(*-------------------------------------------*)
			(*---------- DWI processing script ----------*)
			(*-------------------------------------------*)
			"dwi",
			
			(*get the posisiton of the files needed*)
			pos = GetJSONPosition[json, {{"SeriesDescription", namei}}];
			(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", namei}, 4];
			
			(*get the json and data*)
			info = json[[First@pos]];
			{data, grad, val, vox} = ImportNiiDiff[ConvertExtension[files[[First@pos]],".nii"], FlipBvec->False];
			(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
			
			(*make the additional manditory bids json values*)
			infoExtra=<|
				"ForthDimension"->"Diffusion",
				"DataClass"->datType["Class"],
				If[datType["Class"]==="Repetitions", "Repetition"->namei, Nothing],
				If[datType["Class"]==="Stacks", "Stack"->namei, Nothing],
				If[datType["Class"]==="Stacks", "OverLap"->datType["Overlap"], Nothing]
			|>;
			
			(*export to the correct folder*)
			outFile = GenerateBidsFileName[fol, <|parts, "Type"->type, GetStackName[datType["Class"], namei], "suf"->{datType["Suffix"]}|>];
			(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
			ExportBval[val, ConvertExtension[outFile, ".bval"]];
			ExportBvec[grad, ConvertExtension[outFile, ".bvec"]];
			ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
			Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];
			
			Quiet@If[del,
				(*-----*)AddToLog[{"Deleting", Length[pos], type, "dataset with properties: ", namei}, 4];
				DeleteFile[ConvertExtension[files[[pos]],".nii"]];
				DeleteFile[ConvertExtension[files[[pos]],".nii.gz"]];
				DeleteFile[ConvertExtension[files[[pos]],".json"]];
				DeleteFile[ConvertExtension[files[[pos]],".bval"]];
				DeleteFile[ConvertExtension[files[[pos]],".bvec"]];
			],
			
			(*-------------------------------------------*)
			(*----------- T2 processing script ----------*)
			(*-------------------------------------------*)
			"mese",
			
			(*get the posisiton of the files needed*)
			pos = posi = GetJSONPosition[json, {{"SeriesDescription", namei}}, "EchoTime"];
			(*select only echos*)
			info = MergeJSON[json[[pos]]];
			pos = pos[[;; info["EchoTrainLength"]]];
			(*-----*)AddToLog[{"Importing ", Length[pos], "dataset with properties: ", namei}, 4];
			
			(*get the json and data*)
			AssociateTo[info, "EchoNumber" -> Range@info["EchoTrainLength"]];
			{data, vox} = Transpose[ImportNii /@ ConvertExtension[files[[pos]],".nii"]];
			data = Transpose[data];
			vox = First@vox;
			(*-----*)AddToLog[{"Dimensions:", Dimensions@data, "; Voxel size:", vox}, 4];
			
			(*make the additional manditory bids json values*)
			infoExtra=<|
				"ForthDimension"->"EchoTime",
				"DataClass"->datType["Class"],
				If[datType["Class"]==="Repetitions", "Repetition"->namei, Nothing],
				If[datType["Class"]==="Stacks", "Stack"->namei, Nothing],
				If[datType["Class"]==="Stacks", "OverLap"->datType["Overlap"], Nothing]
			|>;
			
			(*export to the correct folder*)
			outFile = GenerateBidsFileName[fol, <|parts, "Type"->type, GetStackName[datType["Class"], namei], "suf"->{datType["Suffix"]}|>];
			(*-----*)AddToLog[{"Exporting to file:", outFile}, 5];
			ExportNii[data, vox, ConvertExtension[outFile, ".nii"]];
			Export[ConvertExtension[outFile, ".json"], AddToJson[AddToJson[info, "QMRITools"], infoExtra]];
			
			(*Delete used files*)
			Quiet@If[del,
				(*-----*)AddToLog[{"Deleting", Length[posi], type, "datasets with properties: ", namei},4];
				DeleteFile[ConvertExtension[files[[posi]],".nii"]];
				DeleteFile[ConvertExtension[files[[posi]],".nii.gz"]];
				DeleteFile[ConvertExtension[files[[posi]],".json"]]
			],
			
			(*-------------------------------------------*)
			(*-------- Other processing script ----------*)
			(*-------------------------------------------*)
			_,Print["Unknow type for conversion"];
		
		(*Close Type switch*)
		];
		
		(*export the log after each name*)
		ExportLog[logFile]
	(*close loop over stac names*)
	,{namei, datType["Label"]}];
] 


(* ::Subsubsection:: *)
(*GetStackName*)


GetStackName[class_, namei_]:=Switch[class,
	"Volume", "",
	"Stacks"|"Repetitions",
	Switch[class, "Stacks", "stk", "Repetitions", "rep"] -> StringReplace[namei,{"-"->"","_"->"","."->""}]
]


(* ::Subsection:: *)
(*MuscleBidsProcess*)


(* ::Subsubsection::Closed:: *)
(*MuscleBidsProcess*)


Options[MuscleBidsProcess] = {SelectSubjects->All, VersionCheck->False};

SyntaxInformation[MuscleBidsProcess] = {"ArgumentsPattern" -> {_, _, OptionsPattern[]}};

MuscleBidsProcess[niiFol_?StringQ, outFol_?StringQ, datDis_?ListQ, ops:OptionsPattern[]]:= BidsFolderLoop[niiFol, outFol, datDis, Method->"Process", ops]


(* ::Subsubsection:: *)
(*MuscleBidsProcessI*)


MuscleBidsProcessI[foli_, folo_, datType_, logFile_, verCheck_]:=Block[{
		con, fol, parts, type, files, sets, dfile, nfile, process, keys, dfiles, jfile, nfiles,
		outfile, json, echos, mag, ph, real, imag, dvox, magM, B0mask, ph0i, pos, e1, e2, phasediff, hz, b0i,
		t2stari, watfr, fatfr, wat, fat , inph, outph, b0, t2star, r2star, phi, itt, res, outTypes, preProc, 
		nfilep, resi, data, grad, val, diffvox, mask, den, sig, snr, snr0, reg, valU, mean, fiti, s0i, fri, 
		adci, pD, tens, s0, out, l1, l2, l3, md, fa, rd, t2vox, t2w, t2f, b1, n, angle, ex, ref, thk
	},
	
	(*get the context for exporting*)
	con = Context[con];

	(*get the information needed for processing, e.g. session|repetion*)
	{fol, parts} = PartitionBidsFolderName[foli];
	type = datType["Type"];
	process = datType["Process"];
	keys = {"EchoTime", "ForthDimension", "DataClass", "Stack", "OverLap", "SliceThickness", "SpacingBetweenSlices"};

	(*see what needs to be processed*)
	files = Flatten[FileNames["*"<>StringReplace[#, {"-"->"","_"->"","."->""}]<>"*.json", foli]&/@datType["Label"]];
	sets = If[type==="megre",
		DeleteDuplicates[KeyDrop[#,"suf"]&/@PartitionBidsName[FileBaseName/@files]],
		DeleteDuplicates[PartitionBidsName[FileBaseName/@files]]];
	(*-----*)AddToLog[{"Found", ToString[Length[sets]], datType["Class"], "that will be processed:"}, 2];
	
	(*loop over sets*)
	Table[
		(*-----*)AddToLog[dataToLog@set,2 ];
		(*see which data type is expected*)
		Switch[type,
			
			"megre",
			(*-------------------------------------------*)
			(*-------- megre processing scripts ---------*)
			(*-------------------------------------------*)
			
			
			Switch[process["Method"],
				"Dixon",
				(*-------------------------------------------*)
				(*-------- Dixon processing scripts ---------*)
				(*-------------------------------------------*)
				
				(*input file names*)
				dfiles = GenerateBidsFileName[fol, <|set, "suf"->{datType["Suffix"], #}|>]&/@{"", "ph", "real", "imag"};
				jfile = ConvertExtension[First@dfiles, ".json"];
				nfiles = ConvertExtension[dfiles, ".nii"];
				
				(*ouput file names*)
				outfile = GenerateBidsFileName[folo, set];
		
				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[First@dfiles, 4];
					
					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*----*)AddToLog["Could not find the needed JSON file", 4];,
						(*Check if needed nii Exist*)
						If[!AllTrue[nfiles, NiiFileExistQ],
							(*----*)AddToLog[{"Could not find all the ", First@dfiles}, 4],
							(*----*)AddToLog["Importing the data", 4];
	
							(*import the data*)
							json = ImportJSON[jfile];
							echos = json["EchoTime"];
							{{mag, ph, real, imag}, dvox} = Transpose[ImportNii/@nfiles];
							dvox = First@dvox;
							
							(*Apply background mask*)
							magM = NormalizeData[Mean@Transpose@mag];
							B0mask = Dilation[Mask[magM, 15, MaskSmoothing->True, MaskComponents->2, MaskClosing->2], 1];
							{mag, ph, real, imag} = MaskData[#,B0mask]&/@{mag,ph,real,imag};
							
							(*see if there are dixon flips*)
							(*{{mag, ph, real, imag}, pos} = FixDixonFlips[{mag, ph, real, imag}];
							(*-----*)If[pos=!={}, AddToLog[{"Found complex flips in volumes: ", pos}, 4]];*)
							pos = {};
							
							(*calculated field maps*)
							(*-----*)AddToLog[{"Starting field map calcualtion"}, 4];
							{b0i, ph0i, t2stari, {e1, e2}, n} = DixonPhase[real, imag, echos, False];
							(*-----*)AddToLog[{"using echo ", ToString[e1], "(",1000echos[[e1]],"ms ) and", ToString[e2], "(", 1000 echos[[e2]]"ms )"},5];
							
							(*perform the IDEAL dixon fit*)
							(*-----*)AddToLog["Starting Dixon reconstruction",4];
							{{watfr, fatfr}, {wat, fat}, {inph, outph}, {b0, t2star, r2star, phi}, itt, res} = DixonReconstruct[real, imag, echos, b0i, t2stari, ph0i, DixonBipolar->True];
							
							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:",4];
							(*----*)AddToLog[outfile,5];
							outTypes = {"real", "imag", "mag", "ph", "b0i", "b0", "phi", "t2stari", "t2star", "r2star", 
								"inph", "outph", "wat", "fat", "watfr", "fatfr", "itt", "res"};
							ExportNii[ToExpression[con<>#], dvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
							
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "EchoTimes"->echos, "DixonFlips" -> pos, "DixonBipolar" -> True, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[keys]
							]];
						]
					]
				(*close dixon processing*)
				],
				
				_,
				(*-------------------------------------------*)
				(*-------------- Unknown megre --------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			
			(*close megre processing*)
			],
			
			
			"dwi",
			(*-------------------------------------------*)
			(*--------- dwi processing script -----------*)
			(*-------------------------------------------*)
			
			
			(*input file names*)
			dfile = GenerateBidsFileName[fol, set];
			jfile = ConvertExtension[dfile,".json"];
			nfile = ConvertExtension[dfile,".nii"];
			nfilep = ConvertExtension[GenerateBidsFileName[folo, <|set, "suf"->{datType["Suffix"], "reg"}|>],".nii"];
			
			(*ouput file names*)
			outfile = GenerateBidsFileName[folo, set];
			
			(*-------------------------------------------*)
			(*------- dwi pre -processing script --------*)
			(*-------------------------------------------*)
			
			(*check if pre-processin is already done*)
			preProc = False;
			If[CheckFile[outfile<>"_prep", "done", verCheck],
				(*if checkfile has label done and version is recent skip*)
				(*----*)AddToLog["Pre-processing already done for: ", True, 3];
				(*----*)AddToLog[outfile, 4],
				(*----*)AddToLog["Starting pre-processing for data:", 3, True];
				(*----*)AddToLog[dfile, 4];
				
				If[!FileExistsQ[jfile],
					(*----*)AddToLog["Could not find the needed JSON file",4],
					(*Check if needed nii Exist*)
					If[!(NiiFileExistQ[nfile]&&FileExistsQ[ConvertExtension[nfile,".bval"]]&&FileExistsQ[ConvertExtension[nfile,".bvec"]]),
						(*----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"},4],
						(*----*)AddToLog["Importing the data", 4];

						(*import the data*)
						json = ImportJSON[jfile];
						{data, grad, val, diffvox} = ImportNiiDiff[nfile, FlipBvec->False];
						{data, grad, val} = SortDiffusionData[NormalizeData[data], grad, val];
						
						(*Denoise*)
						(*-----*)AddToLog["Starting dwi denoising", 4];
						mask = Mask[NormalizeMeanData[data], 2, MaskSmoothing->True, MaskComponents->2, MaskDilation->1];
						{den, sig} = PCADeNoise[data, mask, PCAOutput->False, PCATollerance->0, PCAKernel->1.5];
						
						(*calculate SNR*)
						snr = SNRCalc[den, sig];
						snr0 = Mean@Transpose@First@SelectBvalueData[{snr, val}, {0, 2}];
						
						(*register data - each leg seperate*)
						(*-----*)AddToLog["Starting dwi motion and eddy correction", 4];
						reg = RegisterDiffusionDataSplit[{den, mask, diffvox}, Iterations->300, NumberSamples->5000, PrintTempDirectory->False];
						
						(*export all the calculated data*)
						(*----*)AddToLog["Exporting the calculated data to:",4];
						(*----*)AddToLog[outfile,5];
						outTypes = {"den", "reg", "sig", "snr0", "snr"};
						ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
						ExportBval[val, ConvertExtension[outfile <> "_reg", ".bval"]];
						ExportBvec[grad, ConvertExtension[outfile <> "_reg", ".bvec"]];
						
						(*export the checkfile*)
						MakeCheckFile[outfile<>"_prep", Sort@Join[
							{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, "Outputs" -> outTypes, "SetProperteis"->set},
							ExtractFromJSON[keys]
						]];
						
						(*Set preproc true, overrules checkfile for processing*)
						preProc = True;
					]
				]
			(*close preprocessing*)
			];
			
			Switch[process,
				
				"DTI",
				(*-------------------------------------------*)
				(*---------- dwi processing script ----------*)
				(*-------------------------------------------*)
										
				(*check if processin is already done, redo is prep is done*)					
				If[If[!preProc, CheckFile[outfile, "done", verCheck], False],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[nfilep, 4];				
					
					If[!FileExistsQ[jfile],
						(*----*)AddToLog["Could not find the needed JSON file", 4];,
						
						(*Check if needed nii Exist*)
						If[!(NiiFileExistQ[nfilep]&&FileExistsQ[ConvertExtension[nfilep,".bval"]]&&FileExistsQ[ConvertExtension[nfilep,".bvec"]]),
							(*----*)AddToLog[{"Skipping, could not find .nii, .bval and .bvec"}, 4],
							(*----*)AddToLog["Importing the data", 4];
	
							(*import the data*)
							json = ImportJSON[jfile];
							{data, grad, val, diffvox} = ImportNiiDiff[nfilep, FlipBvec->False];
							mask = Mask[NormalizeMeanData[data], 2, MaskSmoothing->True, MaskComponents->2, MaskClosing->2];
							data = MaskData[data, mask];
							(*get bvalues and mean data*)
							{mean, valU} = MeanBvalueSignal[data, val];
							
							(*initialize IVIM fit*)
							(*-----*)AddToLog["Starting ivim calculation", 4];
							fiti = IVIMCalc[MeanSignal[mean], valU, {1,.05,.003,.015}, IVIMFixed->True];
							(*perform IVIM correction*)
							{s0i, fri, adci, pD}= IVIMCalc[mean, valU, fiti, IVIMConstrained->False, Parallelize->True, MonitorIVIMCalc->False, IVIMFixed->True];
							fri = Clip[fri, {0,1}, {0,1}];
							adci = 1000 adci;
							resi = IVIMResiduals[mean, valU, {s0i, fri, adci, pD}];
							
							(*calculate tensor from corrected data*)
							(*-----*)AddToLog["Starting tensor calculation", 4];
							data = First@IVIMCorrectData[data, {s0i, fri, pD}, val, FilterMaps->False];
							{tens, s0, out, res} = Quiet@TensorCalc[data, grad, val, FullOutput->True, Method->"iWLLS", RobustFit->True, Parallelize->True, MonitorCalc->False];
							out = Total@Transpose@out;
							(*calculate tensor parameters*)
							{l1, l2, l3, md, fa} = ParameterCalc[tens];
							rd = Mean[{l2, l3}];
							tens = Transpose[tens];
							
							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:", 4];
							(*----*)AddToLog[outfile, 5];					
							outTypes = {"data", "mean", "tens", "res", "out", "s0", 
								"l1", "l1", "l3", "md",	"fa", "rd", "adci", "fri", "s0i"};
							ExportNii[ToExpression[con<>#], diffvox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
													
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "Bvalue" -> val, "Gradient" -> grad, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[keys]
							]];				
						]
					]
				(*close dti processing*)
				],
				
				_,
				(*-------------------------------------------*)
				(*--------------- Unknown dti ---------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			],
			
			(*-------------------------------------------*)
			(*-------- mese processing scripts ----------*)
			(*-------------------------------------------*)
			"mese",
			
			(*input file names*)
			dfile = GenerateBidsFileName[fol, set];
			jfile = ConvertExtension[dfile,".json"];
			nfile = ConvertExtension[dfile,".nii"];
			
			(*ouput file names*)
			outfile = GenerateBidsFileName[folo, set];
			
			Switch[process,
				
				"EPGT2",
				(*-------------------------------------------*)
				(*---------- EPG processing script ----------*)
				(*-------------------------------------------*)
				(*check if files are already done*)
				If[CheckFile[outfile, "done", verCheck],
					(*if checkfile has label done and version is recent skip*)
					(*----*)AddToLog["Processing already done for: ", True, 3];
					(*----*)AddToLog[outfile, 4],
					(*----*)AddToLog["Starting processing for data:", 3, True];
					(*----*)AddToLog[dfile, 4];
					
					(*Check if needed json Exist*)
					If[!FileExistsQ[jfile],
						(*----*)AddToLog[{"Could not find the needed JSON file of", jfile}, 4];,
						(*Check if needed nii Exist*)
						If[!NiiFileExistQ[nfile],
							(*----*)AddToLog[{"Could not find the data of", dfile}, 4],
							(*----*)AddToLog["Importing the data", 4];
							
							(*import the data*)
							json = ImportJSON[jfile];
							echos = json["EchoTime"];
							{data, t2vox} = ImportNii[nfile];
							
							(*mask the background*)		
							mask = Mask[NormalizeMeanData[data], 2, MaskSmoothing -> True, MaskComponents -> 2, MaskClosing -> 2];
							data = MaskData[data, mask];
							
							(*determine the pulse profiles*)
							(*-----*)AddToLog["Calculating the slice profiles", 4];							
							{ex, ref} = datType["Settings"];
							thk = 2 json["SliceThickness"];
							angle = GetPulseProfile[ex, ref, SliceRange -> thk, SliceRangeSamples -> thk][[1;;2]];
							
							(*caculate the water t2 map*)
							(*-----*)AddToLog["Starting EPG T2 calculation", 4];
							{{t2w, t2f, b1}, {wat, fat, fatfr}, res} = EPGT2Fit[data, 1000 echos, angle, 
								MonitorCalc -> False, DictT2IncludeWater -> True, DictT2fValue -> 200, DictT2fRange -> {150, 250, 5}, 
								DictB1Range -> {0.5, 1.4, 0.02}, DictT2Range -> {15, 45, 0.2}
							];
							
							(*export all the calculated data*)
							(*----*)AddToLog["Exporting the calculated data to:", 4];
							(*----*)AddToLog[outfile, 5];					
							outTypes = {"data", "t2w", "t2f", "b1", "wat", "fat", "fatfr", "res"};
							ExportNii[ToExpression[con<>#], t2vox, outfile<>"_"<>#<>".nii"] &/@ outTypes;
													
							(*export the checkfile*)
							MakeCheckFile[outfile, Sort@Join[
								{"Check"->"done", "EchoTimes" -> echos, "Outputs" -> outTypes, "SetProperteis"->set},
								ExtractFromJSON[keys]
							]];				
						]
					]
				(*close t2 processing*)
				],
				
				_,
				(*-------------------------------------------*)
				(*--------------- Unknown mese ---------------*)
				(*-------------------------------------------*)
				(*----*)AddToLog[{"Unkonwn processing ", process, "for datatype", type}, True, 3];
			],
			(*-------------------------------------------*)
			(*------------------ Other ------------------*)
			(*-------------------------------------------*)
			_,
			Print["Unknow type for conversion"];
		
		(*Close Type switch*)
		];
		
		(*export the log after each set*)
		ExportLog[logFile]
		
	(*close loop over sets*)
	, {set, sets}]
]


(* ::Subsection:: *)
(*JSON*)


(* ::Subsubsection::Closed:: *)
(*ImportJSON*)


ImportJSON[file_]:=Import[file,"RawJSON"]


(* ::Subsubsection::Closed:: *)
(*GetJSONPosition*)


GetJSONPosition[json_, selection_]:=GetJSONPosition[json, selection, ""]

GetJSONPosition[json_, selection_, sort_]:=Block[{seli, self, list, key, val, inds, pos},
	(*selection functions*)
	seli = ToLowerCase[Last[Flatten[{#1/.#3}]]]===ToLowerCase[#2]&;
	self = (
		list=#1;
		key=#2[[1]]; 
		val=#2[[2]]; 
		Select[list, seli[key,val,json[[#]]]&]
	)&;
	
	(*get the file positions*)
	pos = Fold[self, Range[Length[json]], selection];
	(*sort positions if needed*)
	If[sort==="", pos, pos[[Ordering[sort /. json[[pos]]]]]]
]


(* ::Subsubsection::Closed:: *)
(*MergeJSON*)


MergeJSON[json:{_?AssociationQ..}]:=Block[{keys},
	keys=DeleteDuplicates[Flatten[Keys /@ json]];
	
	Association[If[#[[2]]==={},Nothing,#]& /@ Thread[
			keys->(
				If[Length[#]===1,First@#,#]& /@ (
					(DeleteDuplicates /@ Transpose[(# /@ keys)& /@ json]) /. Missing[___]->Nothing
				)
			)
		]
	]
]


(* ::Subsubsection::Closed:: *)
(*ExtractFromJSON*)


ExtractFromJSON[keys_] := ((# -> json[#]) & /@ keys) /. {(_ -> Missing[___]) -> Nothing};


(* ::Subsubsection::Closed:: *)
(*AddToJson*)


AddToJson[json_, add_]:=MergeJSON[{json,
	Switch[add,
		"QMRITools",<|"ConversionSoftware"->"QMRITools.com", "ConversionSoftwareVersion"->QMRITools`$InstalledVersion|>,
		_,add]}
]


(* ::Section:: *)
(*End Package*)


End[]

EndPackage[]
